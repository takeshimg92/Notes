{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f19129dc",
   "metadata": {},
   "source": [
    "# The variance of the ROC AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba8c903",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df62aa53",
   "metadata": {},
   "source": [
    "## Recap: the probabilistic interpretation of the ROC AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac69d758",
   "metadata": {},
   "source": [
    "Let $(X,Y)$ be jointly distributed with $Y$ taking values in $\\{0,1\\}$. This is the standard binary classification problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ecb642",
   "metadata": {},
   "source": [
    "The ROC AUC measures the likelihood that a point in class 1 is scored higher than a point in class 0:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665f8bcf",
   "metadata": {},
   "source": [
    "$$\\boxed{A := \\mathbb P(f(X) \\geq f(X') | Y=1, Y'=0).}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a063d0d",
   "metadata": {},
   "source": [
    "If we write $P = \\; f(X)|Y=1$ and $Q = \\, f(X)|Y=0$, then one also sees \n",
    "\n",
    "$$A = \\mathbb P(P \\geq Q)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea22545b",
   "metadata": {},
   "source": [
    "\n",
    "### The Mann-Whitney-Wilcoxon estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8982f2f",
   "metadata": {},
   "source": [
    "This can be estimated via the Mann–Whitney–Wilcoxon statistic\n",
    "\n",
    "$$\\boxed{\\hat A = \\frac{1}{n_0 n_1} \\sum_{i=1}^{n_1} \\sum_{j=1}^{n_0} 1_{P_i \\geq Q_j}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aea4e17",
   "metadata": {},
   "source": [
    "where $P_i$ refers to the score of a point in class 1, and $Q_j$ of one in class 0: \n",
    "\n",
    "$$P_i \\equiv f(X_i)|Y_i=1,\\qquad Q_j \\equiv f(X_j)|Y_j=0$$\n",
    "\n",
    "via the fact that $\\mathbb E[\\hat A] = A$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312bf3da",
   "metadata": {},
   "source": [
    "### Example (to show that this is true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "535eb22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "58da31f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(2000, n_features=20, class_sep=0.6, \n",
    "                           weights=(0.8,),\n",
    "                           random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6dd87aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression().fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4489260b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As an area\n",
    "y_probs = model.predict_proba(X)[:,1]\n",
    "auc_area = roc_auc_score(y, y_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "177e2f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As a probability\n",
    "n0, n1 = np.bincount(y)\n",
    "total_sum = 0\n",
    "for pi in y_probs[y==1]:\n",
    "    for pj in y_probs[y==0]:\n",
    "        if pi >= pj:\n",
    "            total_sum += 1\n",
    "auc_estimator = total_sum/(n0*n1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ff8a93ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC calculated as an area: 0.93089\n",
      "ROC AUC calculated a statistic: 0.93089\n"
     ]
    }
   ],
   "source": [
    "print(\"ROC AUC calculated as an area:\", round(auc_area,5))\n",
    "print(\"ROC AUC calculated a statistic:\", round(auc_estimator,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36dd46be",
   "metadata": {},
   "source": [
    "Notice how both results are identical."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9962f50a",
   "metadata": {},
   "source": [
    "### Statistics of the ROC AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0153dd5",
   "metadata": {},
   "source": [
    "It is easily seen that $\\mathbb E[\\hat A] = A$, and thus one might ask what is the variance of this estimator. We will prove the following result (eq. (2) of [1] and eq. (6) of [2]):\n",
    "\n",
    "**Theorem**. Under tha hypothesis that all points in a given class are independent (ie. $P$'s are iid among themselves, as are the $Q$') then the variance of the Mann-Whitney-Wilcoxon statistic is\n",
    "\n",
    "$$\\boxed{\\mathrm{Var}\\; \\hat A = \\frac{A(1-A) + (n_0 - 1)(P_{XYY} - A^2) + (n_1 - 1)(P_{XXY} - A^2)}{n_0 n_1},}$$\n",
    "\n",
    "where \n",
    "\n",
    "$$P_{XXY} = \\mathbb P (P \\geq Q, P' \\geq Q)$$\n",
    "\n",
    "for any $P, P'$, and similarly \n",
    "\n",
    "$$P_{XYY} = \\mathbb P(P \\geq Q, P \\geq Q')$$\n",
    "\n",
    "for any $Q, Q'$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883b8c6b",
   "metadata": {},
   "source": [
    "### Proof:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f707b56e",
   "metadata": {},
   "source": [
    "In what follows, $1_{ij} \\equiv 1_{P_i \\geq Q_j}$ will be a shorthand notation.\n",
    "\n",
    "By definition,\n",
    "\n",
    "\\begin{align*}\n",
    "\\mathrm{Var}\\, (n_0 n_1 \\hat A) &= \\mathrm{Var}\\, \\left( \\sum_{ij} 1_{ij} \\right)\\\\\n",
    "&= \\sum_{ij} \\sum_{kl} \\mathrm{cov}\\,(1_{ij}, 1_{kl})\\\\\n",
    "&= \\sum_{ij} \\sum_{kl} \\mathrm{cov}\\,(1_{ij}, 1_{kl}) \\left[ 1_{i=k\\\\ j= l} + 1_{i=k\\\\ j \\neq l}+ 1_{i\\neq k\\\\ j= l}+ 1_{i\\neq k\\\\ j \\neq l} \\right]\\\\\n",
    "&= \\sum_{ij} \\mathrm{Var} (1_{ij}) + \\sum_i \\sum_{j\\neq l} \\mathrm{cov}\\,(1_{ij}, 1_{il}) + \\sum_j \\sum_{i\\neq k} \\mathrm{cov}\\,(1_{ij}, 1_{kj}) + \\sum_{i\\neq k} \\sum_{j\\neq l} \\mathrm{cov}\\,(1_{ij}, 1_{kl})\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61080db3",
   "metadata": {},
   "source": [
    "Now, we can simplify a bit by noting that \n",
    "\n",
    "\\begin{align*}\n",
    "\\mathrm{cov}\\,(1_{ij}, 1_{kl}) &\\equiv \\mathbb E[1_{ij} 1_{kl}] - \\mathbb E[1_{ij}] \\mathbb E[1_{kl}]\\\\\n",
    "&= \\mathbb E[1_{ij, kl}] - A^2\n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "where $1_{ij, kl}$ denotes $1_{P_i\\geq Q_j, P_k \\geq Q_l}$ and we see the AUC $A$ appear since $\\mathbb E[1_{ij}] = \\mathbb E[1_{P_i \\geq Q_j}] = \\mathbb P(P_i \\geq Q_j) = A$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c64dee",
   "metadata": {},
   "source": [
    "Hence,\n",
    "\n",
    "\\begin{align*}\n",
    "n_0^2 n_1^2 \\mathrm{Var}\\, \\hat A =  \\sum_{ij} \\mathrm{Var} (1_{ij}) +\n",
    "    \\sum_i \\sum_{j\\neq l} \\left( \\mathbb E[1_{ij, il}] - A^2 \\right) +\n",
    "    \\sum_j \\sum_{i\\neq k} \\left( \\mathbb E[1_{ij, kj}] - A^2 \\right) + \n",
    "    \\sum_{i \\neq k} \\sum_{j\\neq l} \\left( \\mathbb E[1_{ij, kl}] - A^2 \\right)\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6ccf7e",
   "metadata": {},
   "source": [
    "Now, the summand in the last term is (explicitly) $\\mathbb E[1_{P_i \\geq Q_j, P_k \\geq Q_l}]$. But since $i\\neq k$ and $j \\neq l$, the events $P_i \\geq Q_j$ is completely independent from $P_k \\geq Q_l$, and we can split the expectation into $\\mathbb E[1_{P_i \\geq Q_j}] \\mathbb E[1_{P_k \\geq Q_l}] = A^2$, which cancels the other $A^2$ term. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8c4c2a",
   "metadata": {},
   "source": [
    "Furthermore, it is easy to see that the term $\\mathbb E[1_{ij, il}]$ is exactly the $P_{XYY}$ term defined above: it is the probability that a single score in class 1 ($P_i$) is greater than two random scores from class 0 ($Q_j$ and $Q_l$). An analogous reasoning shows that $\\mathbb E[1_{ij, jk}] = \\mathbb P_{XXY}$.\n",
    "\n",
    "Putting these together, we are left with"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3486c5",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    " \\mathrm{Var}\\, \\hat A =  \\frac{1}{n_0^2 n_1^2} \\left[\n",
    " \\sum_{ij} \\mathrm{Var} (1_{ij}) +\n",
    "    \\sum_i \\sum_{j\\neq l} \\left( P_{XYY} - A^2 \\right) +\n",
    "    \\sum_j \\sum_{i\\neq k} \\left( P_{XXY} - A^2 \\right)\n",
    " \\right] \\qquad (*)\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c953a983",
   "metadata": {},
   "source": [
    "To go further, we need an intermediate result:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3c745c",
   "metadata": {},
   "source": [
    "**Lemma 1**: $\\boxed{\\mathrm{Var}\\, 1_{P\\geq Q} = A(1-A)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7da9d4e",
   "metadata": {},
   "source": [
    "*Proof*: we will need the expression for conditional variance: if $X, Y$ are random variables,\n",
    "\n",
    "$$\\mathrm{Var}\\, X = \\mathbb E[\\mathrm{Var}\\,(X|Y)] + \\mathrm{Var}\\,(\\mathbb E[X|Y])$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2526a3",
   "metadata": {},
   "source": [
    "For any $P$ and $Q$, it then follows that\n",
    "\n",
    "$$\\mathrm{Var}\\, 1_{P \\geq Q} = \\mathbb E[\\mathrm{Var}\\,(1_{P \\geq Q}|Q)] + \\mathrm{Var}\\,(\\mathbb E[1_{P\\geq Q}|Q])$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0669c175",
   "metadata": {},
   "source": [
    "Now, it is not too hard to see how the variable $1_{P\\geq Q}|Q$ is distributed. Since it takes values on $\\{0,1\\}$ is is in the Bernoulli familly; recall that $X \\sim \\mathrm{Bernoulli}(p)$ means that $\\mathbb P(X=1) = 1-\\mathbb P(X=0) = p$. In our case,\n",
    "\n",
    "\\begin{align*}\n",
    "\\mathbb P(1_{P\\geq Q} = 1|Q) &= \\mathbb P(P \\geq Q|Q)\\\\\n",
    "&= 1 - \\mathbb P(P \\leq Q|Q)\\\\\n",
    "&\\equiv 1 - F_P(Q)\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2d00d1",
   "metadata": {},
   "source": [
    "where $F_P$ is the CDF of $P$. Hence, \n",
    "\n",
    "$$1_{P\\geq Q}|Q \\,\\sim\\,\\mathrm{Bernoulli}(1 - F_P(Q))$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f199b3df",
   "metadata": {},
   "source": [
    "Now, a $\\mathrm{Bernoulli}(p)$ variable has expectation $p$ and variance $p(1-p)$. It follows that\n",
    "\n",
    "$$\\mathbb E[1_{P\\geq Q}|Q] = 1 - F_P(Q),\\qquad \\mathrm{Var}\\, (1_{P\\geq Q}|Q) = F_P(Q) (1 - F_P(Q))$$\n",
    "\n",
    "and plugging these into the original expression for the variance we get\n",
    "\n",
    "\\begin{align*}\n",
    "\\mathrm{Var}\\, 1_{P \\geq Q} &= \\mathbb E[\\mathrm{Var}\\,(1_{P \\geq Q}|Q)] + \\mathrm{Var}\\,(\\mathbb E[1_{P\\geq Q}|Q])\\\\\n",
    "&= \\mathbb E[F_P(Q) (1 - F_P(Q))] + \\mathrm{Var}\\,(1 - F_P(Q))\\\\\n",
    "&= \\mathbb E[F_P(Q)] - \\mathbb E[F_P^2(Q)] + \\mathrm{Var}\\,(F_P(Q));\\qquad \\mbox{ but } \\mathrm{Var}\\, X = \\mathbb E[X^2] - \\mathbb E[X]^2\\\\\n",
    "&= \\mathbb E[F_P(Q)] - \\mathbb E[F_P^2(Q)] + \\mathbb E[F_P^2(Q)]  - (\\mathbb E[F_P(Q)])^2\\\\\n",
    "&= \\mathbb E[F_P(Q)] (1 - \\mathbb E[F_P(Q)])\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd48a9af",
   "metadata": {},
   "source": [
    "How much is $\\mathbb E[F_P(Q)]$? This is indeed $\\mathbb E_Q[F_P(Q)]$; let $f_P, f_Q$ denote the respective PDFs of $P$ and $Q$. Then\n",
    "\n",
    "\\begin{align*}\n",
    "\\mathbb E[F_P(Q)] &= \\int_0^1 F_P(q) f_Q(q) dq\\\\\n",
    "&= \\int_0^1 dq\\;f_Q(q)  \\int_0^q dp \\;f_P(p)\\\\\n",
    "&= \\int_{[0,1]^2} f_P(p) f_Q(q) 1_{p \\leq q}\\, dp dq\\\\\n",
    "&= \\mathbb E[1_{P\\leq Q}] = 1 - \\mathbb P(P\\geq Q)\\\\\n",
    "&= 1- A.\n",
    "\\end{align*}\n",
    "\n",
    "Finally, \n",
    "$$\\mathrm{Var}\\, 1_{P \\geq Q} = A(1-A)\\qquad \\Box$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b79699",
   "metadata": {},
   "source": [
    "This means that, for any $i,j$, $\\mathrm{Var}\\, 1_{ij} = A(1-A)$. Thus the first term above will be simplified."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dba018b",
   "metadata": {},
   "source": [
    "Using this result in $(*)$ we get\n",
    "\n",
    "\\begin{align*}\n",
    " \\mathrm{Var}\\, \\hat A =  \\frac{1}{n_0^2 n_1^2} \\left[\n",
    " \\sum_{ij} A(1-A) +\n",
    "    \\sum_i \\sum_{j\\neq l} \\left( P_{XYY} - A^2 \\right) +\n",
    "    \\sum_j \\sum_{i\\neq k} \\left( P_{XXY} - A^2 \\right) \n",
    " \\right], \n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325bdf51",
   "metadata": {},
   "source": [
    "or, writing the sums explicitly,\n",
    "\n",
    "\\begin{align*}\n",
    " \\mathrm{Var}\\, \\hat A =  \\frac{1}{n_0^2 n_1^2} \\left[\n",
    " \\sum_{i=1}^{n_1} \\sum_{j=1}^{n_0} A(1-A) +\n",
    "    \\sum_{i=1}^{n_1} \\sum_{j=1}^{n_0} \\sum_{l=1\\\\ l \\neq j}^{n_0} \\left( P_{XYY} - A^2 \\right) +\n",
    "    \\sum_{j=1}^{n_0} \\sum_{i=1}^{n_1} \\sum_{k =1\\\\k\\neq i}^{n_1} \\left( P_{XXY} - A^2 \\right) \n",
    " \\right], \n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4805ab",
   "metadata": {},
   "source": [
    "None of the terms depend on the indices $i,j,k,l$ anymore. The first term will output a factor of $n_0 n_1$; the second one, $n_1 n_0 (n_0-1)$, and the third one $n_0 n_1 (n_1-1)$, hence\n",
    "\n",
    "$$\\mathrm{Var}\\, \\hat A = \\frac{1}{n_0 n_1} \\left[ A(1-A) + (n_0-1)(P_{XYY} - A^2) + (n_1 - 1)(P_{XXY} - A^2) \\right]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca62fbca",
   "metadata": {},
   "source": [
    "as we wanted to prove. $\\Box$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e12746",
   "metadata": {},
   "source": [
    "## Special case: random classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09177e27",
   "metadata": {},
   "source": [
    "In the case of a random classifier, ie. where $P \\sim \\mathrm{Unif}([0,1])$ and similarly for $Q$, we have $A = 1/2$ and \n",
    "\n",
    "$$P_{XXY} = P_{YXX} = \\frac 13,$$\n",
    "\n",
    "since\n",
    "\n",
    "\\begin{align*}\n",
    "P_{XXY} &= \\mathbb P(P_1 \\geq Q, P_2 \\geq Q)\\\\\n",
    "&= \\int_0^1 \\mathbb P(P_1 \\geq Q, P_2 \\geq Q | Q=q) p(q) dq\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd84300b",
   "metadata": {},
   "source": [
    "where $p(q) = 1$ is the uniform PDF. Now, conditioned on $Q$, the two events above are independent and we have\n",
    "\n",
    "\\begin{align*}\n",
    "P_{XXY} &= \\int_0^1 \\mathbb P(P_1 \\geq q) \\mathbb P(P_2 \\geq q) dq\\\\\n",
    "&= \\int_0^1 (1-q)^2 dq\\\\\n",
    "&= \\frac 13.\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b5dc22",
   "metadata": {},
   "source": [
    "Plugging this into the variance equation we get\n",
    "\n",
    "\\begin{align*}\n",
    "(\\mathrm{Var}\\, \\hat A)_\\mathrm{random\\, classifier} &= \\frac{1}{n_0 n_1} \\left[ \\frac 14 + (n_0-1 + n_1-1) \\left (\\frac 13 - \\frac 14\\right)\\right]\\\\\n",
    "&= \\frac{n_0+n_1+1}{12 n_0 n_1}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3dcfd1",
   "metadata": {},
   "source": [
    "If either $n_0$ or $n_1$ is sufficiently large, \n",
    "\n",
    "$$\\boxed{\\hat A _\\mathrm{random\\, classifier} \\approx \\mathcal N \\left( \\frac 12, \\frac{n_0+n_1+1}{12 n_0 n_1}\\right)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dccbbe1",
   "metadata": {},
   "source": [
    "as we have already seen！"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3458b4",
   "metadata": {},
   "source": [
    "### Experimental test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2b904c",
   "metadata": {},
   "source": [
    "Let us simulate a classification problem. We will:\n",
    "* Train a model on a training set\n",
    "* Create bootstrap samples of the test set and calculate the ROC AUC in each of them\n",
    "* Use these samples to compare to the theoretical results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3575953a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "24e1735e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(n_samples=5000, weights=(0.7,), \n",
    "                           class_sep=0.8, flip_y=0.1, random_state=2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "26495061",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=0.4,\n",
    "                                                    stratify=y, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8a3d6f00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=1)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(random_state=1)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf7b147",
   "metadata": {},
   "source": [
    "See if model is not too overfitted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dc55d137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train AUC: 0.876\n",
      "Test AUC: 0.869\n"
     ]
    }
   ],
   "source": [
    "print(\"Train AUC:\", round(roc_auc_score(y_train, model.predict_proba(X_train)[:,1]),3))\n",
    "print(\"Test AUC:\", round(roc_auc_score(y_test, model.predict_proba(X_test)[:,1]),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02974ef",
   "metadata": {},
   "source": [
    "#### Use theoretical formulas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1fce1860",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_pxxy(X, y, model, seed=None, n_samples=10000):\n",
    "    scores = model.predict_proba(X)[:,1]\n",
    "    \n",
    "    p, q = scores[y==1], scores[y==0]\n",
    "    \n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "\n",
    "    samples = [np.all(np.random.choice(p, size=2) >= np.random.choice(q, size=1))\n",
    "               for _ in range(n_samples)]\n",
    "    \n",
    "    return np.mean(samples)\n",
    "\n",
    "def calculate_pxyy(X, y, model, seed=None, n_samples=10000):\n",
    "    scores = model.predict_proba(X)[:,1]\n",
    "    \n",
    "    p, q = scores[y==1], scores[y==0]\n",
    "    \n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "\n",
    "    samples = [np.all(np.random.choice(p, size=1) >= np.random.choice(q, size=2))\n",
    "               for _ in range(n_samples)]\n",
    "    return np.mean(samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b22f67",
   "metadata": {},
   "source": [
    "Theoretical variance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5bf16d9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7883"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pxxy = calculate_pxxy(X_test, y_test, model, seed=1)\n",
    "pxxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "028b8ba1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7857"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pxyy = calculate_pxxy(X_test, y_test, model, seed=2)\n",
    "pxyy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "948f077c",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = roc_auc_score(y_test, model.predict_proba(X_test)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8b4956de",
   "metadata": {},
   "outputs": [],
   "source": [
    "n0, n1 = np.bincount(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ccaa94c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def variance(n0, n1, A, pxxy, pxyy):\n",
    "    return (1/(n0*n1)) * (A*(1-A) + (n0-1)*(pxyy-A**2) + (n1-1)*(pxxy - A**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "037b33a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theoretical variance: 7.21e-05\n"
     ]
    }
   ],
   "source": [
    "theoretical_var = variance(n0, n1, A, pxxy, pxyy)\n",
    "print(\"Theoretical variance:\", round(theoretical_var,7))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e956a76",
   "metadata": {},
   "source": [
    "#### Use bootstrapping:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e237c891",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_X_y(X, y, seed=None):\n",
    "    n = len(X)\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "        \n",
    "    indices = np.random.randint(0, high=len(X), size=len(X))\n",
    "    return X[indices], y[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f6b50d92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad37dd0db1d548a1b41988beed787cb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_samples = 10000\n",
    "aucs = []\n",
    "for seed in tqdm(range(n_samples)):\n",
    "    X_bs, y_bs = bootstrap_X_y(X_test, y_test, seed=seed)\n",
    "    auc = roc_auc_score(y_bs, model.predict_proba(X_bs)[:,1])\n",
    "    aucs.append(auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5b8eb5",
   "metadata": {},
   "source": [
    "Calculate variance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "01ac3e75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAATuElEQVR4nO3df4zcd53f8efrTBJCkl5Ms4kc2zkH5OPOQT0HrVyuqVBK6MWXq85QlcqRDlIEMiclVWiR2oRKBf6wxKkQ+scJJHOhZ12B1D1CcdPrFeNCKVKJ2eScYMfJ4cO+ZLEv3uNHA62Uq827f8zX3GCvd8Y7M97vfvf5kEbznc98PuP3jndf+5nP98emqpAkddfPLXUBkqTJMuglqeMMeknqOINekjrOoJekjnvFUhcAcN1119WGDRuWugxJWlaeeOKJv6yqqUH9WhH0GzZsYGZmZqnLkKRlJcmfD9PPpRtJ6jiDXpI6zqCXpI4z6CWp4wx6Seo4g16SOs6gl6SOM+glqeMMeknquFacGSvpfBse+C8/3T7+kd9Ywkq03Dmjl6SOM+glqeMMeknquIFBn+SVSQ4keSrJ4SQfbto/lOS7SQ42t7v6xjyY5GiS55LcOckvQJK0sGF2xr4MvLmqfpzkMuDrSf5r89zHq+qj/Z2TbAK2A7cANwJfTvKLVXVmnIVLkoYzcEZfPT9uHl7W3GqBIduAR6rq5ao6BhwFtoxcqSRpUYZao0+yKslB4BSwr6oeb566L8nTST6dZHXTthZ4oW/4bNN27mvuSDKTZGZubm7xX4EkaUFDBX1VnamqzcA6YEuS1wOfBF4LbAZOAh9rume+l5jnNXdV1XRVTU9NDfxLWJKkRbqoE6aq6odJvgps7V+bT/Ip4LHm4Sywvm/YOuDEiHVKneWJUZq0YY66mUpybbN9JfAW4Nkka/q6vQ041GzvBbYnuSLJzcBG4MBYq5YkDW2YGf0aYHeSVfR+MeypqseS/EGSzfSWZY4D7wWoqsNJ9gDPAKeBez3iRpoMPw1oGAODvqqeBm6dp/0dC4zZCewcrTRJ0jh4ZqwkdZxBL0kdZ9BLUscZ9JLUcQa9JHWcQS9JHeefEpQ6yOPr1c+gl5ZAfxAP0y6NwqCXOs7ZvVyjl6SOM+glqeNcupE6wvV9XYgzeknqOINekjrOoJekjnONXlpmRlmLP3esh1uuDAa9tAy4o1WjcOlGkjrOoJekjhsY9ElemeRAkqeSHE7y4ab91Un2Jfl2c7+6b8yDSY4meS7JnZP8AiRJCxtmRv8y8Oaq+hVgM7A1yRuBB4D9VbUR2N88JskmYDtwC7AV+ESSVROoXZI0hIFBXz0/bh5e1twK2Absbtp3A29ttrcBj1TVy1V1DDgKbBln0ZKk4Q21Rp9kVZKDwClgX1U9DtxQVScBmvvrm+5rgRf6hs82bZKkJTBU0FfVmaraDKwDtiR5/QLdM99LnNcp2ZFkJsnM3NzcUMVKki7eRR1HX1U/TPJVemvvLyZZU1Unk6yhN9uH3gx+fd+wdcCJeV5rF7ALYHp6+rxfBNJy5fXf1TbDHHUzleTaZvtK4C3As8Be4J6m2z3AF5vtvcD2JFckuRnYCBwYc92SpCENM6NfA+xujpz5OWBPVT2W5H8Be5K8G3geeDtAVR1Osgd4BjgN3FtVZyZTviRpkIFBX1VPA7fO0/494I4LjNkJ7By5OknSyDwzVpI6zqCXpI7z6pXSJeIVKLVUnNFLUscZ9JLUcS7dSCuYJ3etDM7oJanjDHpJ6jiXbqRFctlDy4UzeknqOINekjrOpRtpDDwZSm3mjF6SOs6gl6SOM+glqeMMeknqOINekjrOoJekjjPoJanjPI5e0nm8vEO3DJzRJ1mf5CtJjiQ5nOT+pv1DSb6b5GBzu6tvzINJjiZ5Lsmdk/wCJEkLG2ZGfxp4f1U9meQa4Ikk+5rnPl5VH+3vnGQTsB24BbgR+HKSX6yqM+MsXJI0nIEz+qo6WVVPNts/Ao4AaxcYsg14pKperqpjwFFgyziKlSRdvItao0+yAbgVeBy4DbgvyTuBGXqz/h/Q+yXwjb5hs8zziyHJDmAHwE033bSY2iWNkdfr6a6hj7pJcjXweeB9VfUS8EngtcBm4CTwsbNd5xle5zVU7aqq6aqanpqauti6JUlDGirok1xGL+Q/U1WPAlTVi1V1pqp+AnyKv16emQXW9w1fB5wYX8mSpIsxzFE3AR4GjlTVQ33ta/q6vQ041GzvBbYnuSLJzcBG4MD4SpYkXYxh1uhvA94BfCvJwabtA8DdSTbTW5Y5DrwXoKoOJ9kDPEPviJ17PeJGkpbOwKCvqq8z/7r7Hy0wZiewc4S6JElj4iUQJKnjDHpJ6jivdSNNkMemqw0MekkL8gJny59LN5LUcQa9JHWcQS9JHWfQS1LHGfSS1HEedSNpaB6Bszw5o5ekjnNGL10ET4DScuSMXpI6zqCXpI4z6CWp4wx6Seo4d8ZKjQsdOugOWC13zuglqeMMeknqOINekjpuYNAnWZ/kK0mOJDmc5P6m/dVJ9iX5dnO/um/Mg0mOJnkuyZ2T/AIkSQsbZkZ/Gnh/Vf0y8Ebg3iSbgAeA/VW1EdjfPKZ5bjtwC7AV+ESSVZMoXpI02MCgr6qTVfVks/0j4AiwFtgG7G667Qbe2mxvAx6pqper6hhwFNgy5rolSUO6qDX6JBuAW4HHgRuq6iT0fhkA1zfd1gIv9A2bbdrOfa0dSWaSzMzNzS2idEnSMIYO+iRXA58H3ldVLy3UdZ62Oq+haldVTVfV9NTU1LBlSJIu0lAnTCW5jF7If6aqHm2aX0yypqpOJlkDnGraZ4H1fcPXASfGVbCkdvDa9MvHwKBPEuBh4EhVPdT31F7gHuAjzf0X+9o/m+Qh4EZgI3BgnEVLk+bZsOqSYWb0twHvAL6V5GDT9gF6Ab8nybuB54G3A1TV4SR7gGfoHbFzb1WdGXfhkqThDAz6qvo686+7A9xxgTE7gZ0j1CVdEs7ctRJ4ZqwkdZxBL0kdZ9BLUscZ9JLUcQa9JHWcQS9JHWfQS1LHGfSS1HEGvSR1nEEvSR1n0EtSxxn0ktRxBr0kdZxBL0kdN9RfmJKkhfjXptrNGb0kdZxBL0kd59KNpIlxSacdnNFLUscNDPokn05yKsmhvrYPJflukoPN7a6+5x5McjTJc0nunFThkqThDDOj/31g6zztH6+qzc3tjwCSbAK2A7c0Yz6RZNW4ipUkXbyBQV9VXwO+P+TrbQMeqaqXq+oYcBTYMkJ9kqQRjbIz9r4k7wRmgPdX1Q+AtcA3+vrMNm3nSbID2AFw0003jVCGdHH6dxBKK8Fid8Z+EngtsBk4CXysac88fWu+F6iqXVU1XVXTU1NTiyxDkjTIooK+ql6sqjNV9RPgU/z18swssL6v6zrgxGglSpJGsailmyRrqupk8/BtwNkjcvYCn03yEHAjsBE4MHKVkpYNl8baZ2DQJ/kccDtwXZJZ4IPA7Uk201uWOQ68F6CqDifZAzwDnAburaozE6lcWsC5YePJOlrJBgZ9Vd09T/PDC/TfCewcpShp3JxlaiXzzFhJ6jiDXpI6zqCXpI4z6CWp4wx6Seo4g16SOs6gl6SO8y9MSbokLnQugyezTZ4zeknqOINekjrOoJekjjPoJanjDHpJ6jiPulFneIVKaX7O6CWp4wx6Seo4g16SOs41ei1rrstLgzmjl6SOM+glqeMGBn2STyc5leRQX9urk+xL8u3mfnXfcw8mOZrkuSR3TqpwSdJwhpnR/z6w9Zy2B4D9VbUR2N88JskmYDtwSzPmE0lWja1aSdJFGxj0VfU14PvnNG8Ddjfbu4G39rU/UlUvV9Ux4CiwZTylSpIWY7Fr9DdU1UmA5v76pn0t8EJfv9mm7TxJdiSZSTIzNze3yDIkSYOMe2ds5mmr+TpW1a6qmq6q6ampqTGXIUk6a7FB/2KSNQDN/ammfRZY39dvHXBi8eVJkka12KDfC9zTbN8DfLGvfXuSK5LcDGwEDoxWoiRpFAPPjE3yOeB24Loks8AHgY8Ae5K8G3geeDtAVR1Osgd4BjgN3FtVZyZUuyRpCAODvqruvsBTd1yg/05g5yhFSVo5/KPhk+eZsZLUcQa9JHWcV6/UsuMVK6WL44xekjrOoJekjjPoJanjDHpJ6jh3xmpZcAestHjO6CWp4wx6Seo4l24ktVL/cp2XQxiNM3pJ6jiDXpI6zqCXpI5zjV5S67lePxpn9JLUcQa9JHWcSzdqFT+iaxC/Ry6eQa/W8rIH0niMFPRJjgM/As4Ap6tqOsmrgf8AbACOA/+4qn4wWpmSpMUaxxr936uqzVU13Tx+ANhfVRuB/c1jSdISmcTSzTbg9mZ7N/BV4F9O4N/RMuY6q3TpjDqjL+BLSZ5IsqNpu6GqTgI099fPNzDJjiQzSWbm5uZGLEOSdCGjzuhvq6oTSa4H9iV5dtiBVbUL2AUwPT1dI9YhSbqAkWb0VXWiuT8FfAHYAryYZA1Ac39q1CIlSYu36KBPclWSa85uA78GHAL2Avc03e4BvjhqkZKkxRtl6eYG4AtJzr7OZ6vqj5N8E9iT5N3A88DbRy9TkrRYiw76qvoO8CvztH8PuGOUorSyeGKUFutCR295VNfP8lo3ktRxBr0kdZxBL0kdZ9BLUsd59UpdMu50lZaGQS+pE5xIXJhBr4nyh09aega9xs5wl9rFnbGS1HEGvSR1nEEvSR3nGr2kFWOlXgPHoJfUaR4cYNBrBCt1diQtNwa9xsJZk5ablTRRcWesJHWcQS9JHefSjX7qQssvF/rLPZKWB4N+BVpJa5PSMM6dwHTt58Kg10DO4rXSDPPpdjmZ2Bp9kq1JnktyNMkDk/p3JEkLS1WN/0WTVcCfAn8fmAW+CdxdVc/M1396erpmZmbGXsdKdKFlGWfl0qU3zM/gKJ8SkjxRVdOD+k1q6WYLcLSqvtMU8wiwDZg36Ec1iTXnUV5zmLAd5jVHDWfDXVpabfkZnNSM/h8BW6vqPc3jdwB/u6ru6+uzA9jRPHwd8BxwHfCXYy9ovKxxdG2vD9pfY9vrg/bX2Pb6YHCNv1BVU4NeZFIz+szT9jO/UapqF7DrZwYlM8N8DFlK1ji6ttcH7a+x7fVB+2tse30wvhontTN2Fljf93gdcGJC/5YkaQGTCvpvAhuT3JzkcmA7sHdC/5YkaQETWbqpqtNJ7gP+G7AK+HRVHR5i6K7BXZacNY6u7fVB+2tse33Q/hrbXh+MqcaJ7IyVJLWHFzWTpI4z6CWp4y5Z0A+6JEKSn0/yn5M8leRwknc17euTfCXJkab9/pbV98okB/raPzyJ+kapse/5VUn+JMljbawxyfEk30pyMMlETpUesb5rk/xhkmeb78dfbVONSV7XvHdnby8leV9b6mue+2dN26Ekn0vyynHXN4Ya72/qOzyJ92/I+lYn+UKSp5t8ef2wY+dVVRO/0dsh+2fAa4DLgaeATef0+QDwO832FPD9pu8a4A1N+zX0Lq2wqUX1Bbi6ab8MeBx4Y5vew77n/znwWeCxtv0/N4+PA9e18fuwebwbeE+zfTlwbdtqPOd1/oLeCTWtqA9YCxwDrmye2wP8kza9h8DrgUPAq+gdrPJlYOMS1PdvgA82278E7B927Hy3SzWj/+klEarqr4Czl0ToV8A1SQJcTe+NP11VJ6vqSYCq+hFwhN43TFvqq6r6cdPnsuY2iT3ci64RIMk64DeA35tAbWOp8RJYdH1J/gbwJuBhgKr6q6r6YZtqPKfPHcCfVdWft6y+VwBXJnkFvTCdxPk1o9T4y8A3qur/VtVp4H8Ab1uC+jYB+wGq6llgQ5Ibhhx7nksV9GuBF/oez3J+WP8uvTf5BPAt4P6q+kl/hyQbgFvpzZpbU1+zJHIQOAXsq6px1zdyjcC/Bf4F8BMmZ9QaC/hSkifSu0RGm+p7DTAH/Ltm+ev3klzVshr7bQc+16b6quq7wEeB54GTwP+uqi+1qUZ6s/k3JfmbSV4F3MXPnvx5qep7CviHAEm2AL9A78TTYcae51IF/cBLIgB3AgeBG4HNwO82s6jeCyRXA58H3ldVL7Wpvqo6U1Wb6f1HbOlfT2tDjUn+AXCqqp6YQF39Rv1/vq2q3gD8OnBvkje1qL5XAG8APllVtwL/B5jE5bfH8bNyOfCbwH9sU31JVtObfd7cPHdVkt9qU41VdQT4HWAf8Mf0AnfcnziHqe8jwOpmAvlPgT9p6hhm7HkuVdAPc0mEdwGPNkshR+mt5f0SQJLL6IX8Z6rq0bbVd1bzUf6rwNaW1Xgb8JtJjtP7qPfmJP++ZTVSVSea+1PAF+h9TG1LfbPAbN+ntT+kF/zjNo7vxV8HnqyqF1tW31uAY1U1V1X/D3gU+Dstq5Gqeriq3lBVb6K3pPPtS11fVb1UVe9qJpDvpLcf4dgwY+dzqYJ+mEsiPE9vXZFmLep1wHeaNbSHgSNV9VAL65tKcm3TfiW9b+Zn21RjVT1YVeuqakMz7r9X1SRmUqO8j1cluaZpvwr4NXofo1tRX1X9BfBCktc1/e5gMpfdXnSNfc/fzWSWbUat73ngjUle1fxc30Fvn1ubaiTJ9c39TfSWT8b9Xg6sL70jvC5vHr4H+FqzkrG4y8tcaC/tuG/01rr+lN4e43/VtP028NvN9o3Al+itlx0Cfqtp/7v0Ppo8Te+j1kHgrhbV97fofax6umn/1217D895jduZ0FE3I76Pr6H3Mfkp4PDZsW2pr3luMzDT/F//J2B1C2t8FfA94Ofb9n/cPPdhehOhQ8AfAFe0sMb/Se+X+FPAHUtU36/S+yTxLL1PPqsXGjvo5iUQJKnjPDNWkjrOoJekjjPoJanjDHpJ6jiDXpI6zqCXpI4z6CWp4/4/mST0cQBRdn0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(aucs, bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b61b852a",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_var = np.std(aucs)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c3432e84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theoretical variance: 7.21e-05\n",
      "Bootstrap variance: 7.85e-05\n"
     ]
    }
   ],
   "source": [
    "#Comparison:\n",
    "print(\"Theoretical variance:\", round(theoretical_var,7))\n",
    "print(\"Bootstrap variance:\", round(exp_var,7))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a723f0",
   "metadata": {},
   "source": [
    "## A practical example: finding backtest sample size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f0f4e5",
   "metadata": {},
   "source": [
    "Assume we run backtests of a specific credit model with clients. \n",
    "\n",
    "We need to ask them for a dataset to prove our product's performance. The dataset must:\n",
    "* not be too small (so we avoid small data issues)\n",
    "* not be too big (complex, might have legal issues to share)\n",
    "\n",
    "**What is an optimal range for the sample size?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3211fa",
   "metadata": {},
   "source": [
    "* Let us assume the population imbalance ratio is $\\alpha < 1$ \n",
    "\n",
    "* Assume we want the ROC AUC to be precise to $\\epsilon$, an absolute number such as 0.01 (ie. a variance of $10^{-4}$).\n",
    "\n",
    "From the formula for a (random) classifier's AUC,\n",
    "\n",
    "$$\\sigma^2 \\approx \\frac{n_1+n_0}{{12 n_1 n_0}}$$\n",
    "\n",
    "if we write $n_1 = \\alpha N$, $n_0 = (1-\\alpha) N$ we get"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe418f8",
   "metadata": {},
   "source": [
    "$$\\sigma^2 = \\frac{N}{12 N^2 \\alpha(1-\\alpha)} = \\frac{1}{12 N \\alpha(1-\\alpha)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e5d0a4",
   "metadata": {},
   "source": [
    "Setting $\\sigma \\leq \\epsilon$ we find $N$ to be\n",
    "\n",
    "$$\\boxed{N \\geq \\frac{1}{12 \\epsilon^2 \\alpha(1-\\alpha)}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4305cc",
   "metadata": {},
   "source": [
    "**Example**: for $\\alpha = 0.10$ and $\\epsilon = 0.01$, we find"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "deb987be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample size: 9259\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.10\n",
    "epsilon = 0.01\n",
    "print(\"Sample size:\",int(1/(12*alpha*(1-alpha)*epsilon**2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff4d094",
   "metadata": {},
   "source": [
    "Thus, it is reasonable to ask clients for a dataset with around 10,000 points for a backtest if we want to report AUC to 1 percentage point error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26067390",
   "metadata": {},
   "source": [
    "# The (beautiful & useless) extreme-imbalance, random classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478b0bf5",
   "metadata": {},
   "source": [
    "Lett us get the simplest possible estimator: a random one, where all scores are uniformly sampled from $[0,1]$. In this context, how likely are we to get a spuriously large AUC?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f454797",
   "metadata": {},
   "source": [
    "In particular, we want to consider an **extreme imbalance scenario** where\n",
    "\n",
    "1. $n$ is small (say, less than 100)\n",
    "\n",
    "2. The ratio $n/N$ is small: $n/N \\ll 1$ (say, 1% or less)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a8c2db",
   "metadata": {},
   "source": [
    "Our intuition tells us that this case should be more interesting than the big-data, balanced one: since one has only a few ($n$) points in class 1, if we are \"lucky\" to get high scores for all of them, the AUC will end up being high. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c298aa41",
   "metadata": {},
   "source": [
    "We will use the AUC estimator as defined above:\n",
    "\n",
    "$$\\hat A = \\frac{1}{n(N-n)} \\sum_{i=1}^{n} \\sum_{j=1}^{N-n} 1_{P_i \\geq Q_j}$$\n",
    "\n",
    "First, we have a trivial result: for all $i \\in I$, $j \\in J$, if $P_i, Q_j$ iid distributed as $\\mathrm{Uniform}([0,1])$ then\n",
    "\n",
    "$$1_{P_i \\geq Q_j} | P_i \\; \\sim \\;\\mathrm{Bernoulli}(P_i)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f4adad",
   "metadata": {},
   "source": [
    "Since a binomial variable is built from a sum of independent Bernoulli ones, we have a corollary: for all $i \\in I$, \n",
    "\n",
    "$$\\sum_{j \\in J}\\left. 1_{P_i \\geq Q_j} \\right| P_i \\; \\sim \\; \\mathrm{Binomial}(N-n, P_i)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9633a4",
   "metadata": {},
   "source": [
    "Now, for large $N-n$, we may use the normal approximation to the binomial, namely a $\\mathrm{Binomial}(n,p)$ variable converges to a $\\mathcal N(\\mu=np, \\sigma^2 = np(1-p))$ variable as $n$ grows. Hence\n",
    "\n",
    "$$\\sum_{j \\in J}\\left. 1_{P_i \\geq Q_j} \\right| P_i \\; \\sim \\; \\mathcal N\\left( (N-n)P_i,  (N-n)P_i (1-P_i) \\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63bc9617",
   "metadata": {},
   "source": [
    "It follows that, for all $i\\in I$,\n",
    "\n",
    "$$Z_i |P_i := \\frac{1}{N-n} \\sum_{j \\in J} \\left.1_{P_i \\geq Q_j}\\right| \\, P_i \\;\\sim \\; \\mathcal N \\left(P_i, \\frac{P_i (1-P_i)}{N-n}\\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44772db",
   "metadata": {},
   "source": [
    "This defines a set of $n$ variables $Z_i$. To obtain their marginal distribution, notice that for any $Z_i$ its PDF is given by\n",
    "\n",
    "$$p_{Z_i}(z) = \\int p(z|P_i=p) p(P_i=p) dp;$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2eaf2d6",
   "metadata": {},
   "source": [
    "but $P_i \\; \\sim \\; \\mathrm{Uniform}([0,1])$, and hence its PDF is just the identity on $[0,1]$. Letting\n",
    "\n",
    "$$f(x|\\mu,\\sigma^2) \\equiv \\frac{1}{\\sqrt{2\\pi \\sigma^2}} \\exp\\left\\{ - \\frac{(x-\\mu)^2}{2\\sigma^2} \\right\\}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25450303",
   "metadata": {},
   "source": [
    "be the Gaussian PDF, we obtain\n",
    "\n",
    "$$p_{Z_i}(z) = \\int_0^1 f \\left(\\left. z \\frac{}{} \\right|\\, p, \\frac{p(1-p)}{N-n} \\right) dp$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f18e6d8",
   "metadata": {},
   "source": [
    "For $N-n$ large (as is our hypothesis), the integrand (as a function of $p$) is basically a very sharp peak centered at $p=z$. In fact, we may approximate it as a Dirac delta function\n",
    "\n",
    "$$f\\left(z \\left. \\frac{}{} \\right|\\, p, \\frac{p(1-p)}{N-n} \\right) \\approx \\delta(z-p)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a97793a",
   "metadata": {},
   "source": [
    "to obtain\n",
    "\n",
    "$$p_{Z_i}(z) = 1_{z \\in [0,1]} \\quad \\Rightarrow \\quad Z_i \\; \\sim \\; \\mathrm{Uniform}([0,1])$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be15c30d",
   "metadata": {},
   "source": [
    "We have also tested this numerically - even for $n/N$ not that small this holds surprisingly well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283fb61b",
   "metadata": {},
   "source": [
    "**If we assume all $Z_i$'s are independent among themselves**, the it means that $n \\widehat{\\mathrm{AUC}}$ is the sum of $n$ independent uniform variables: it follows the so-called Irwin-Hall distribution, and we have our most important result below.\n",
    "\n",
    "Notice: we have not proven this independence assumption - it is **not obvious**, and we prove it below.\n",
    "\n",
    "**Theorem**. Let $\\widehat{\\mathrm{AUC}}_\\mathrm{random}$ denote the ROC AUC estimator for a *uniformly random scoring function*. Let there be $n$ instances of class 1 and $N-n$ instances of class 0, where $N\\geq n$. Then\n",
    "\n",
    "$$\\boxed{n \\widehat{\\mathrm{AUC}}_\\mathrm{random} \\; \\sim \\; \\mathrm{IrwinHall}(n)};$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2593ce0",
   "metadata": {},
   "source": [
    "notice that this result **does not depend on $N$ explicitly**; we've only used that $N$ is large and also much larger than $n$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c77d938",
   "metadata": {},
   "source": [
    "As Wikipedia can tell us, if $A \\sim \\mathrm{IrwinHall}(n)$ then\n",
    "\n",
    "$$\\mathbb E[A] = \\frac{n}{2};\\qquad \\mathrm{Var}(A) = \\frac{n}{12};$$\n",
    "\n",
    "for the AUC, this gives \n",
    "\n",
    "$$\\boxed{\\mathbb E[\\widehat{\\mathrm{AUC}}_\\mathrm{random}] = \\frac{1}{2};\\qquad \\mathrm{Var}[\\widehat{\\mathrm{AUC}}_\\mathrm{random}] = \\frac{1}{12 n}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983eb999",
   "metadata": {},
   "source": [
    "The first result is not surprising: we know that for a random scoring function the AUC should be 1/2. The second one is more surprising, and shows that as we increase $n$, we get an increasingly more precise AUC at 0.5 with a standard deviation that goes as $1/\\sqrt{n}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0ea155",
   "metadata": {},
   "source": [
    "We can now use this result to calculate how likely a statistical fluke is to happen: recall Chebyshev's inequality for any (square-integrable) random variable $X$:\n",
    "\n",
    "$$\\mathbb P(|X - \\mu| \\geq t) \\leq \\frac{\\mathrm{Var} \\, X}{t^2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b16591",
   "metadata": {},
   "source": [
    "for our random AUC, this gives\n",
    "\n",
    "$$\\boxed{\\mathbb P \\left(\\left|\\, \\widehat{\\mathrm{AUC}}_\\mathrm{random} - \\frac 12 \\right| \\geq t \\right) \\leq \\frac{1}{12 n t^2}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2f9c1c",
   "metadata": {},
   "source": [
    "**Examples**: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "55f8da56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n=20\n",
      "Probability of AUC > 0.6 is less than 41.67%\n",
      "Probability of AUC > 0.7 is less than 10.42%\n",
      "Probability of AUC > 0.8 is less than 4.63%\n",
      "Probability of AUC > 0.9 is less than 2.6%\n"
     ]
    }
   ],
   "source": [
    "n = 20\n",
    "print(f\"{n=}\")\n",
    "for t in [0.1, 0.2, 0.3, 0.4]:\n",
    "    print(f\"Probability of AUC > {0.5+t} is less than {round(100/(12*n*t**2), 2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39fc0153",
   "metadata": {},
   "source": [
    "## Proof that ROC AUC becomes the sum of scores for class 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe94e9f0",
   "metadata": {},
   "source": [
    "Recall that, above, we defined $Z_i$ as\n",
    "$$\\hat A = \\frac{1}{n(N-n)} \\sum_{i=1}^{n} \\sum_{j=1}^{N-n} 1_{P_i \\geq Q_j} = \\frac{1}{n} \\sum_{i=1}^n Z_i$$\n",
    "\n",
    "where\n",
    "$$Z_i \\equiv Z_i^{(N)} = \\frac{1}{N-n} \\sum_{j\\in J} 1_{P_i \\geq Q_j}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5ee9df",
   "metadata": {},
   "source": [
    "We have shown that as $N$ grows this variable becomes uniform. We can actually prove something stronger: that **$Z_i$ essentially becomes $P_i$ itself!**\n",
    "\n",
    "The intuition here is that, as $N$ grows large, the $Q_j$'s basically cover the whole $[0,1]$ interval, and since $Z_i$ cares only about their aggregated values, it essencially becomes independent of them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b517d81",
   "metadata": {},
   "source": [
    "More precisely: let $Q_J \\equiv \\{Q_j: j \\in J\\}$ be a shorthand for all the scores in class 0. We will show three results:\n",
    "\n",
    "* **Proposition 1:** $Z_i|Q_J$ converges on the mean to $P_i$, ie. \n",
    "\n",
    "  $$\\lim_{N\\to\\infty} \\mathbb E\\left[\\left.Z_i^{(N)} - P_i \\;\\right| Q_J\\right] = 0$$\n",
    "  \n",
    "* **Corollary**: $Z_i|Q_J$ converges in probability to $P_i$, ie. \n",
    "\n",
    "  $$\\lim_{N\\to\\infty} \\mathbb P\\left(\\left.|Z_i^{(N)} - P_i| \\geq a \\;\\right| Q_J\\right) = 0,\\qquad \\forall a > 0$$\n",
    "  \n",
    "* **Proposition 2:** $Z_i|Q_J$ converges in the mean-squared sense to $P_i$, ie. \n",
    "\n",
    "  $$\\boxed{\\lim_{N\\to\\infty} \\mathbb E\\left[\\left. \\left(Z_i^{(N)} - P_i \\right)^2\\;\\right| Q_J\\right] = 0}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be3c475",
   "metadata": {},
   "source": [
    "Since $P_i$ is independent of $Q_J$, this shows that the (conditional on $Q_J$) variable $Z_i$ converges to the (unconditional on $Q_J$) variable $P_i$. The problem is so unbalanced that the probabilities of the majority class are essentially \"integrated out\", and only the scores of the minority class remain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7009c24",
   "metadata": {},
   "source": [
    "In practice, this means that\n",
    "\n",
    "$$\\boxed{\\widehat{\\mathrm{AUC}} \\approx \\frac{1}{n} \\sum_{i: y_i=1} P_i} \\quad \\mbox{(very high imbalance, random scoring)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4da982",
   "metadata": {},
   "source": [
    "In what follows, we write $N-n \\equiv M$ to unclutter notation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6fe86e",
   "metadata": {},
   "source": [
    "**Proof of Proposition 1**: by direct evaluation, using that the variable $1_{P_i \\geq Q_j}\\,|Q_j$ is Bernoulli with parameter $1-Q_j$, we get\n",
    "\n",
    "\\begin{align*}\n",
    "\\mathbb E\\left[\\left.Z_i^{(N)} - P_i \\;\\right| Q_J\\right] &= \\frac{1}{M} \\sum_j \\mathbb E[1_{P_i \\geq Q_j}\\,|Q_j]- \\mathbb E[P_i]\\\\\n",
    "&=\\frac 1M \\sum_j (1-Q_j) - \\frac 12\\\\\n",
    "&= \\frac 12 - \\frac 1M \\sum_{j\\in J} Q_j\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80648b88",
   "metadata": {},
   "source": [
    "As $M$ (thus $N$) grows larger, intuitively, the $Q_j$ cover $[0,1]$ and so the sum above becomes a Riemann sum. We get\n",
    "\n",
    "\\begin{align*}\n",
    "\\lim_{N\\to\\infty}\\mathbb E\\left[\\left.Z_i^{(N)} - P_i \\;\\right| Q_J\\right] &= \\frac 12 - \\int_0^1 q\\, dq \\\\\n",
    "&=\\frac 12 - \\frac 12\\\\\n",
    "&= 0\n",
    "\\end{align*}\n",
    "\n",
    "as we wanted to prove."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ff9c99",
   "metadata": {},
   "source": [
    "**Proof of Corollary**. Recall Markov's inequality: if $X$ is an integrable, non-negative random variable, then\n",
    "\n",
    "$$\\mathbb P(X \\geq t) \\leq \\frac{\\mathbb E[X]}{t}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6955292",
   "metadata": {},
   "source": [
    "Setting $X = (\\left.Z_i^{(N)} - P_i )\\;\\right| Q_J$ and taking the limit gives the proof."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a246f5",
   "metadata": {},
   "source": [
    "**Proof of Proposition 2**: we want to prove that \n",
    "\n",
    "$$\\lim_{N\\to\\infty} \\mathbb E\\left[\\left. \\left(Z_i^{(N)} - P_i \\right)^2\\;\\right| Q_J\\right] = 0.$$\n",
    "\n",
    "To do that, we compute the square\n",
    "\n",
    "$$\\mathbb E\\left[\\left. \\left(Z_i^{(N)} - P_i \\right)^2\\;\\right| Q_J\\right] = \\underbrace{\\mathbb E\\left[\\left.(Z_i^{(N)})^2\\,\\right|Q_J\\right]}_{(*)} - 2 \\underbrace{\\mathbb E\\left[\\left. P_i Z_i^{(N)} \\,\\right|Q_J\\right]}_{(**)} + \\underbrace{\\mathbb E\\left[\\left.P_i^2\\,\\right|Q_J\\right]}_{(***)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3bd8987",
   "metadata": {},
   "source": [
    "We compute one term at a time. ${(***)}$ is the easiest: since $P_i \\,\\sim\\,\\mathrm{Uniform}([0,1])$ is independent of $Q_J$, this is just \n",
    "\n",
    "$$\\mathbb E\\left[\\left.P_i^2\\,\\right|Q_J\\right] = \\frac 13$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a1a628",
   "metadata": {},
   "source": [
    "For $(**)$, we need to explicitly compute the expectation; then, taking the limit, we will find a Riemann sum. We have\n",
    "\n",
    "\\begin{align*}\n",
    "\\mathbb E\\left[\\left. P_i Z_i^{(N)} \\,\\right|Q_J\\right] &= \\frac 1M \\sum_j \\mathbb E\\left[\\left. P_i 1_{P_i \\geq Q_j}\\,\\right|Q_j\\right] \\\\\n",
    "&= \\frac 1M \\sum_j \\int_0^1 p 1_{p \\geq Q_j} \\, dp = \\frac 1M \\sum_j \\int_{Q_j}^1 p\\, dp \\\\\n",
    "&= \\frac 1M \\sum_j \\left( \\frac{1-Q_j^2}{2}\\right)\\\\\n",
    "&\\xrightarrow[N \\to \\infty]{} \\int_0^1 \\frac{1 - q^2}{2} dq\\\\\n",
    "&= \\frac 13\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408f9492",
   "metadata": {},
   "source": [
    "Finally, for $(*)$, the procedure is technically more involved but basically identical:\n",
    "\n",
    "\\begin{align*}\n",
    "\\mathbb E\\left[\\left.(Z_i^{(N)})^2\\,\\right|Q_J\\right] &= \\mathbb E \\left[\\left. \\frac{1}{M^2} \\sum_{j \\in J} \\sum_{k\\in J} 1_{P_i \\geq Q_j} 1_{P_i \\geq Q_k} \\;\\right|Q_J\\right]\\\\\n",
    "&=\\frac{1}{M^2}  \\mathbb E \\left[\\left.\\sum_{j \\in J}  1_{P_i \\geq Q_j} + 2 \\sum_j \\sum_{k < j} 1_{P_i \\geq Q_j} 1_{P_i \\geq Q_k} \\;\\right|Q_J\\right]\\\\\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e883f49",
   "metadata": {},
   "source": [
    "With no loss of generality, order the $Q_j$'s in an ascending order, so that $Q_j \\geq Q_k$ if $j > k$. We can then simplify the second sum by considering that $P_i$ must be larger than $\\max(Q_j, Q_k) = Q_j$. Hence\n",
    "\n",
    "\\begin{align*}\n",
    "\\mathbb E\\left[\\left.(Z_i^{(N)})^2\\,\\right|Q_J\\right] &= \\frac{1}{M^2}\\left\\{\n",
    "    \\sum_j \\mathbb E\\left[\\left.1_{P_i \\geq Q_j}\\,\\right|Q_j\\right] +\n",
    "    2 \\sum_j \\sum_{k < j} \\mathbb E\\left[\\left.1_{P_i \\geq Q_j}\\,\\right|Q_j\\right]\n",
    "    \\right\\}\\\\\n",
    "&= \\frac{1}{M^2}\\left\\{\\sum_j (1-Q_j) + 2 \\sum_j \\sum_{k < j} (1-Q_j)\\right\\}\\\\\n",
    "&= \\frac{1}{M} \\left[\\frac{1}{M}\\sum_j (1-Q_j)\\right] + \\frac{2}{M^2} \\sum_j \\sum_{k < j} (1-Q_j)\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3017383a",
   "metadata": {},
   "source": [
    "Upon taking the limit, the first term will be killed by the excess $1/M$ term in front; the second one becomes the double sum\n",
    "\n",
    "\\begin{align*}\n",
    "\\mathbb E\\left[\\left.(Z_i^{(N)})^2\\,\\right|Q_J\\right] &\\xrightarrow[N \\to \\infty]{} 0 + 2 \\int_0^1 dq \\int_0^q dx \\, (1-q)\\\\\n",
    "&= 2 \\int_0^1 dq \\, q(1-q)\\\\\n",
    "&= \\frac 13.\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90571f62",
   "metadata": {},
   "source": [
    "Hence, putting all results $(*)$ to $(***)$ together, we get\n",
    "\n",
    "$$\\lim_{N\\to\\infty} \\mathbb E\\left[\\left. \\left(Z_i^{(N)} - P_i \\right)^2\\;\\right| Q_J\\right] = \\frac 13 - 2 \\cdot \\frac 13 + \\frac 13 = 0$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1b2be6",
   "metadata": {},
   "source": [
    "This proves Proposition 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9442f560",
   "metadata": {},
   "source": [
    "## Simulating this result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b806e5b1",
   "metadata": {},
   "source": [
    "Below, we test\n",
    "\n",
    "$$\\widehat{\\mathrm{AUC}} \\approx \\frac{1}{n} \\sum_{i: y_i=1} P_i \\quad \\mbox{(very high imbalance, random scoring)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2b8596",
   "metadata": {},
   "source": [
    "basically by creating a highly imbalanced dataset with only 15 points of class 1, and comparing the ROC AUC calculation with the average of the scores predicted for class 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "89e20b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "86afb276",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixed_imbalanced_dataset(total_samples=20000, \n",
    "                            class_1_samples=15):\n",
    "    import pandas as pd\n",
    "    from sklearn.datasets import make_classification\n",
    "    \n",
    "    X, y = make_classification(n_samples=total_samples,\n",
    "                               weights=(0.8,),\n",
    "                               random_state=4)\n",
    "\n",
    "    df = pd.DataFrame(X)\n",
    "    df['y'] = y\n",
    "    df0 = df[df['y']==0]\n",
    "    df1 = df[df['y']==1]\n",
    "\n",
    "    df1_red = df1.sample(n=class_1_samples)\n",
    "\n",
    "    df_new = pd.concat([df1_red, df0]).sample(frac=1)\n",
    "    X, y = df_new.drop('y', axis=1).values, df_new['y'].values\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b57eebd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = fixed_imbalanced_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "73f805a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([15947,    15])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c7ea3404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1:\n",
      "  - ROC AUC           : 0.594\n",
      "  - Mean score class 1: 0.593\n",
      "Trial 2:\n",
      "  - ROC AUC           : 0.557\n",
      "  - Mean score class 1: 0.558\n",
      "Trial 3:\n",
      "  - ROC AUC           : 0.549\n",
      "  - Mean score class 1: 0.551\n",
      "Trial 4:\n",
      "  - ROC AUC           : 0.457\n",
      "  - Mean score class 1: 0.456\n"
     ]
    }
   ],
   "source": [
    "# create random prediction\n",
    "for i, seed in enumerate([12,51,25,62]):\n",
    "    np.random.seed(seed)\n",
    "    y_pred = np.random.rand(*y.shape)\n",
    "    \n",
    "    roc_auc = roc_auc_score(y, y_pred)\n",
    "    mean_prediction = y_pred[y==1].mean()\n",
    "    print(f\"Trial {i+1}:\")\n",
    "    print(f\"  - ROC AUC           : {round(roc_auc,3)}\")\n",
    "    print(f\"  - Mean score class 1: {round(mean_prediction,3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44fb25e5",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4b23a1",
   "metadata": {},
   "source": [
    "[1] Cortes, Corinna and Mohri, Mehryar, *Confidence Intervals for the Area Under the ROC Curve*. Advances in Neural Information Processing Systems, 17 (2004).\n",
    "Available at https://proceedings.neurips.cc/paper/2004/file/a7789ef88d599b8df86bbee632b2994d-Paper.pdf\n",
    "\n",
    "[2] S. Shirahata, *Estimate of variance of Wilcoxon-Mann-Whitney statistic.* J. Japanese Soc. Comp. Statist. 6.2(1993), 1-10. Available at: https://www.jstage.jst.go.jp/article/jjscs1988/6/2/6_2_1/_pdf/-char/en\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
