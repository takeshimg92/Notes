{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41f61b51",
   "metadata": {},
   "source": [
    "# The Practical Man's Guide to Binary Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f444e1f5",
   "metadata": {},
   "source": [
    "The objective of this book is to guide you through the steps of solving the most common type of problem in applied machine learning: binary classification.\n",
    "\n",
    "It assumes you have a basic understanding of how machine learning works - i.e. you have split a dataset into train/test and trained a model in `sklearn` before - but does not assume you know much about binary classification, the metrics we can use to model it, or the common pitfalls. That is our job to teach you. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a6718a",
   "metadata": {},
   "source": [
    "### Warning: how much math do I need for this book?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90982c9c",
   "metadata": {},
   "source": [
    "To do machine learning, you don't need to know a lot of math. But to do machine learning *well* you certainly need it, and this book assumes you have enough mathematical maturity to understand the notation and logic we employ.\n",
    "\n",
    "You can still profit from the discussion without much math - just focus on the takeaways. However, it is obvious that the reader who has taken mathematical probability or statistics and undergraduate calculus will be able to appreciate the more technical aspects of the explanation. If you can understand the definitions below:\n",
    "* $\\displaystyle \\mathbb P (A|B) = \\frac{\\mathbb P(A \\cap B)}{\\mathbb P (B)}$\n",
    "* $\\displaystyle \\mathbb E[g(X)] = \\int_{-\\infty}^\\infty g(x) f(x) dx$\n",
    "* $F(x) := \\mathbb P (X \\leq x)$\n",
    "* $\\displaystyle f(x) = \\frac{d F(x)}{dx}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963ed7e9",
   "metadata": {},
   "source": [
    "then you are probably good to go. If you need a refresher, http://cs229.stanford.edu/section/cs229-prob.pdf might be a good reference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b942ee3b",
   "metadata": {},
   "source": [
    "### Version compatibility"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc62e72",
   "metadata": {},
   "source": [
    "We use `scikit-learn` version 1.0.2. The code here should be replicable with versions 1.0.2 or higher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4931dae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.2\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac2dd41",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0bbe01c",
   "metadata": {},
   "source": [
    "## The standard classification setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48cd4c16",
   "metadata": {},
   "source": [
    "Binary classification is the task of predicting whether a thing belongs to one class or another. For the sake of simplicity, we will call one of them 1 (the **positive class**) and the other one 0 (the **negative class**); sometimes, especially when we discuss imbalanced datasets, class 1 will also be called the **minority class**. We avoid the convention (mostly used when discussing support vector machines) of labelling the classes 1 and -1, although that convention could be used here with simple adaptations of most formulas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2d978b",
   "metadata": {},
   "source": [
    "The most common situation is that where we have a set of datapoints $\\{x_i,y_i\\}_{i\\in 1:N}$ (where we denote as $1:N$ the set of integers between 1 and N). Here, the **features** $x_i$ are assumed to live in some $d$-dimensional space $\\mathcal{X}$ (which may contain discrete inputs, images, etc) and the **target** $y_i$ (also called **label**) assumes the values 0 or 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025fa29a",
   "metadata": {},
   "source": [
    "Our goal is to train a function which can predict, for a new sample $x$, whether its label should be 0 or 1. \n",
    "> Note on notation: we don't write the features as $\\vec{x}_i$ or $\\mathbf{x}_i$ to explicitly denote they are vectors - the discussion here independs on whether there are 1 or 1000 features and will not depend on the specific vectorial nature of the feature space."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a3b77d",
   "metadata": {},
   "source": [
    "## Where does classification go wrong?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220c5c12",
   "metadata": {},
   "source": [
    "Binary classification should be the easiest problem in machine learning. It is. But it is also one of the most important as well as one where people make most mistakes. In fact, it is my belief that knowledge on linear regression and classification problems correlates with data science capability. \n",
    "\n",
    "There are three points people often get wrong in classification models:\n",
    "\n",
    "1. **Class imbalance**: when one of the classes is much less represented than the other. For example, in a standard problem in fraud detection, maybe 0.5% of the total points will be labeled as fraudulent ($y=1$) whereas all the others are not frauds $(y=0)$. Class imbalance nearsights most metrics, and makes it hard to say which model is better.\n",
    "\n",
    "2. **Bad choice of metric(s)**. You can find thousands of Medium articles going over all the important classification metrics. This book here is no different. Yet, too many choices usually lead us to make bad choices. It is surprising how hard it can be to choose and interpret metrics in classification problems.\n",
    "\n",
    "3. **Bad problem definition**. In real business problems, the class $y$ is not given to you. You must define a policy or set of rules to establish when a point will be considered a 1 and when it will be considered a 0. This definition might work for a while, but might also be fluid in time. Understanding your choice of target and making sure it is the \"right\" one is a complex business issue."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebdf89eb",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3bf515",
   "metadata": {},
   "source": [
    "# Classification model theory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceee3818",
   "metadata": {},
   "source": [
    "## The probabilistic point of view"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c707ea",
   "metadata": {},
   "source": [
    "Most (if not all) machine learning problems can be written, and better understood, in the language of probability theory. Since this will be our main language in this document too, we will briefly present the main ingredients, to the necessary degree of mathematical rigor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a86de66",
   "metadata": {},
   "source": [
    "We assume there exist some (unobserved, theoretical) random variables $(X, Y)$ which are jointly distributed (we follow the convention of writing random variables with uppercase letters, and their instances / observations in lowercase), with $Y$ taking values in $\\{0,1\\}$.\n",
    "\n",
    "Our goal is to estimate the so-called **score** of an observation $x$:\n",
    "\n",
    "$$\\boxed{p(x) := \\mathbb{P}(Y=1|X=x)},$$\n",
    "\n",
    "or, translating into words:\n",
    "\n",
    "> Given a set of features $x$, what is the probability that we measure $Y$ to be 1? \n",
    "\n",
    "Notice that $p(x)$ tells the whole story about the distribution of $Y$ given $X$, since $\\mathbb{P}(Y=0|X=x) = 1-p(x)$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ff3750",
   "metadata": {},
   "source": [
    "### Bernoulli variables : mathematical coin tosses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9086a9b5",
   "metadata": {},
   "source": [
    "An equivalent, rigorous description of the above is that variable $Y|X=x$ (read as \"$Y$ given that $X$ equals $x$\") follows a **Bernoulli distribution** with parameter $p(x)$, which we write\n",
    "$$\n",
    "\\boxed{(Y|X=x) \\sim \\mathrm{Bernoulli}(p(x))}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0597b8e",
   "metadata": {},
   "source": [
    "This equation is the basis for everything we do in binary classification (which really amounts to finding $p(x)$ via several methods), so remember it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41582c60",
   "metadata": {},
   "source": [
    "> Notice how the rather cumbersome notation \"$Y|X=x$\" denotes a perfectly well-defined random variable: it is the values we observe for $Y$ provided that $X$ has been measured to be $x$. Notationally, if we call $Z \\equiv Y|X=x$, then the statement $\\mathbb{P}(Z=y)$ is equivalent to $\\mathbb{P}(Y=y|X=x)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26c9142",
   "metadata": {},
   "source": [
    "A variable $Z$ follows a Bernoulli distribution with parameter $p$ (between 0 and 1), which we write as $Z \\sim \\mathrm{Bernoulli}(p)$, if $Z$ takes values in $\\{0,1\\}$ and \n",
    "\n",
    "$$\\mathbb{P}(Z=1) = p,\\qquad \\mathbb{P}(Z=0) = 1-p$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b320018d",
   "metadata": {},
   "source": [
    "or more succinctly,\n",
    "$$\\mathbb{P}(Z=k) = p^k (1-p)^{1-k}, \\qquad k \\in \\{0,1\\}.$$\n",
    "\n",
    "(it is also common to write $\\mathbb{P}(Z=k;p)$ to make explicit that we are using $p$ as a parameter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da04fc03",
   "metadata": {},
   "source": [
    "A Bernoulli trial (which is how a sample from a Bernoulli variable is called) is the equivalent to a coin toss. Letting heads = 1 and tails = 0, then $p$ is the probability of seeing a heads, and $1-p$ is that of seeing a tail.\n",
    "A fair coin has $p=1/2$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc161e8c",
   "metadata": {},
   "source": [
    "Notice how, in our case, $Z(x)\\equiv (Y|X=x)$ is a function of $x$ - that is why we see $p(x)$ entering a parameter. This means that our \"coin\" has a parameter which is not constant, and it changes from point to point in the feature space. That makes sense - consider the problem of predicting if someone has (1) or does not have (0) a car, given their income. Then one would expect $p(\\mbox{high income}) > p(\\mbox{low income})$, for example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba60b97",
   "metadata": {},
   "source": [
    "### Binary classification is not really that binary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543be426",
   "metadata": {},
   "source": [
    "In binary classification we try to predict a score, which is a number $p(x)$ between 0 and 1. It is, for most inputs $x$, neither 0 or 1, but something in between. \n",
    "\n",
    "This means that even though our labels $y$ must be either 0 or 1, what we calculate is a continuous score. If we want to \"binarize\" this output, we need to choose a **threshold** (which we'll write as $\\lambda$) to create a rule:\n",
    "\n",
    "$$\\hat{y}(x) = \\begin{cases}\n",
    "1 & \\mbox{if } f(x) \\geq \\lambda \\\\\n",
    "0 & \\mbox{if } f(x) < \\lambda\n",
    "\\end{cases}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37101c57",
   "metadata": {},
   "source": [
    "Here, $\\hat{y}(x)$ is the **estimator** for $(Y|X=x)$ - it is the value we predict, and this one only takes the value of 0 or 1. What the equation above really means is: if the score is larger than the threshold, set the prediction to 1, otherwise set it to 0.\n",
    "\n",
    "More precisely, we could write $\\hat{y}(x)$ as $\\hat{y}_\\lambda(x)$ since it depends on the choice of the threshold. We will sometimes use this notation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95fabed7",
   "metadata": {},
   "source": [
    "### Wrap-up of our ingredients\n",
    "\n",
    "* **Data**: dataset $\\{x_i, y_i\\}_{i\\in 1:N}$ of features and labels, where all labels $y_i$ take values in $\\{0,1\\}$\n",
    "* **Model**: we assume there exists a function $p$ such that $(Y|X=x) \\sim \\mathrm{Bernoulli}(p(x))$. To fully solve the classification problem, we must choose:\n",
    "  * The score function $p(x)$\n",
    "  * The threshold $\\lambda$ to create the estimator $\\hat{y}_\\lambda(x)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b956c3a",
   "metadata": {},
   "source": [
    "In the next chapters, we focus on methods to find and assess score functions, as well as choosing the best threshold (in some sense)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f69d1fd",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5cedcd8",
   "metadata": {},
   "source": [
    "# The loss function: binary cross-entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c628d18",
   "metadata": {},
   "source": [
    "Not any random score $p(x)$ will do. We want to find the \"best\" score function, but first we must define what that means in the first place.\n",
    "\n",
    "Intuitively, the picture should be clear. Suppose we have a random point in our dataset $(x_{23}, y_{23})$ with $y_{23}=1$. One would expect a good function $p$ to provide a high score for this point, eg. $p(x_{23}) = 0.97$, that is, there is a very high probability that $y_{23}$ is 1. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b4a485",
   "metadata": {},
   "source": [
    "Similarly, for another instance $(x_{8}, y_8)$ with $y_8=0$, one would expect a low score, maybe $p(x_8) = 0.04$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728eed04",
   "metadata": {},
   "source": [
    "In machine learning, the process of **training** a model requires us to choose a **loss function**: a function which takes high values for bad models that make lots of mistakes, and takes low values for good models. Then, we can deal with the task of choosing a model that minimizes the loss (I am ignoring matters of model regularization here)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381e243a",
   "metadata": {},
   "source": [
    "> (**Review - loss functions & regularization**) *Loss functions* are a common ingredient in machine learning. Basically, they are a means to estimate how far away from a perfect solution we are. More precisely, if we are trying to find a function $f$ (which will be the ground truth), and we estimate that a function $g$ might be a good approximant, then the loss is a function $L[g]$ which is positive, and is minimized for $g=f$. \n",
    "> If one is given a training set $\\{x_i, y_i\\}_{i\\in 1:N}$, the expression for the loss is usually broken down into $N$ separate components: $\\displaystyle L[g] = \\frac{1}{N} \\sum_{i=1}^N l(y_i, g(x_i))$, where $l(y, g(x))$ calculates the error between point $y$ and its estimate $\\hat y = g(x)$. The choice of $l$ is such that $l(y,\\hat y)=0$ if $\\hat y = y$, ie. the model perfectly replicates the training data, and $>0$ otherwise. \n",
    "\n",
    "> In practice, one usually introduces *regularization* to avoid overfitting: this comes from considering a penalized version of the loss which penalizes exceedingly complex function approximants $g$: $$L_\\mathrm{reg}[g] = \\frac{1}{N} \\sum_{i=1}^N l(y_i, g(x_i)) + \\lambda R[g],$$\n",
    "where $R > 0$ is the regularization term and $\\lambda > 0$ is a weight. More explicitly, let $g = g_\\theta$ actually depend on a set of parameters $\\theta$ (which could be the coefficients of a logistic regression, for example). Then one usually sets $R[g]$ to some power of (the norm of) $\\theta$, thus penalizing large values of the parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ca4eca",
   "metadata": {},
   "source": [
    "#### Simple case: Bernoulli variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5750e6",
   "metadata": {},
   "source": [
    "Forget about features for a second. Suppose we have a sequence of 23 observations \n",
    "\n",
    "$$11011010100010010010111$$ \n",
    "\n",
    "for a Bernoulii variable (eg. a sequence of coin tosses). How can we best estimate $p$ (which here is just a parameter)? More intuitively: given a sequence of heads and tails, how to best estimate the bias of the coin?\n",
    "\n",
    "The solution comes from inferential statistics, via the method of **maximum likelihood estimation** (MLE). The idea is simple: find the parameter which makes it most likely to see this set of observations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8194103",
   "metadata": {},
   "source": [
    "> (**Review - Maximum likelihood estimation**) In statistics, MLE is a method used in the following situation: we are given a set of observations - data - for which we have a hypothesis of the generating distribution. For instance, we might believe that a set of points has come as samples from a normal distribution. Remember: a normal distribution is fully specified by two parameters $\\mu$ and $\\sigma^2$, which describe its mean and variance. In our case, we wish to find which normal distribution - hence which values of $\\mu$ and $\\sigma^2$ - are most appropriate for the data we observe. MLE, as shown below, allows us to find a function (the likelihood) which, when maximized over all possible parameters, give those which best fit our data. Mathematically, if we observe points $x_1, \\ldots, x_n$ which are taken to be iid, and want to fit a distribution $f_\\theta(x)$ to them, then the likelihood is the function $\\ell(\\theta) = \\sum_{i=1}^n \\log f_\\theta(x_i)$; one then finds the maximum likelihood estimate via $\\hat \\theta_{\\mathrm{MLE}} = \\mathrm{arg} \\max_\\theta \\ell(\\theta)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27fd43df",
   "metadata": {},
   "source": [
    "Let's give some names to things. Let $N=23$, and let $Y_i$, for $i \\in 1:N$, be a set of identical and independently distributed (iid) Bernoulli variables with parameter $p$, that is\n",
    "\n",
    "$$Y_i \\sim \\mathrm{Bernoulli}(p)\\qquad\\mbox{ for all $i$, with $Y_i$ independent of $Y_j$ for $i\\neq j$}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5faef775",
   "metadata": {},
   "source": [
    "Also call $y_1, y_2,\\ldots, y_{23}$ the observed values for each of the $Y_i$, meaning \n",
    "\n",
    "$$y_1 = 1,\\quad y_2 = 1, \\quad y_3=0,\\ldots$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f509a0",
   "metadata": {},
   "source": [
    "Then, the probability of obtaining the observed sequence is\n",
    "\n",
    "$$\\begin{align}\n",
    "\\mathbb{P}(Y_1=y_1, Y_2=y_2,\\ldots, Y_n=y_n) &= \\mathbb{P}(Y_1=y_1) \\mathbb{P}(Y_2=y_2)\\cdots \\mathbb{P}(Y_N=y_N)\\quad\\mbox{due to independence}\\\\\n",
    "&= \\prod_{i=1}^N \\mathbb{P}(Y_i=y_i)\\quad \\mbox{ simplifying notation}\\\\\n",
    "&= \\prod_{i=1}^N p^{y_i}(1-p)^{1-y_i} =: \\mathrm{likelihood}(p)\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b120cbb",
   "metadata": {},
   "source": [
    "where we have defined the **likelihood function** of $p$ in the last line. Indeed, notice that since the $y_i$ are fixed, the likelihood is just a function of $p$.\n",
    "\n",
    "A common trick to simplify equations (and to induce convexity) is to take the log of both sides, defining the **log-likelihood**. Then the product simplifies to a sum, and we have\n",
    "\n",
    "$$\\ell(p) \\equiv \\log \\mathrm{likelihood}(p) = \\sum_{i=1}^N \\left[y_i \\log p + (1-y_i) \\log(1-p)\\right]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e80315",
   "metadata": {},
   "source": [
    "The MLE method proposes to maximize this quantity. But we can just as well take its negative sign and propose to *minimize* it instead, and name it our loss function!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d034c689",
   "metadata": {},
   "source": [
    "$$L(p) = - \\sum_{i=1}^N \\left[y_i \\log p + (1-y_i) \\log(1-p)\\right]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88c30d1",
   "metadata": {},
   "source": [
    "Our problem then becomes: find $p$ such that the loss function above is minimized. This can be done via some calculus:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb5c817",
   "metadata": {},
   "source": [
    "$$L'(p) = - \\sum_{i=1}^N \\left[ \\frac{y_i}{p} - \\frac{1-y_i}{1-p}\\right] = 0 \\Rightarrow \\boxed{\\hat{p} = \\frac{1}{N} \\sum_{i=1}^N y_i}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c157735",
   "metadata": {},
   "source": [
    "Thus, the MLE estimator for the Bernoulli problem is extremely simple: just the arithmetic average of the observations. This is indeed what we could intuitively expect. $p$ measures the proportion of times we got a 1 instead of a 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c252248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p_MLE = 0.52\n"
     ]
    }
   ],
   "source": [
    "# Estimate p via MLE for our case\n",
    "import numpy as np\n",
    "\n",
    "y = np.array([1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1])\n",
    "print(\"p_MLE = %.2f\" % y.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd8fe93",
   "metadata": {},
   "source": [
    "### Generalizing the Bernoulli result: binary cross-entropy "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b6c22b",
   "metadata": {},
   "source": [
    "We can take the reasoning above beyond the \"no-features\" Bernoulli model, simply because the line of thought is exactly the same, changing $p$ for $p(x_i)$ and $Y_i$ for $Y_i|X_i = x_i$. The loss we get this time is\n",
    "\n",
    "$$\\boxed{L = - \\sum_{i=1}^N \\left[y_i \\log p(x_i) + (1-y_i) \\log(1-p(x_i))\\right]}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b38d4f6",
   "metadata": {},
   "source": [
    "which is called by the fancy name **binary cross-entropy** or simply **log-loss**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2574f8b0",
   "metadata": {},
   "source": [
    "Two important questions appear immediately:\n",
    "  - 1) What is the log-loss a function *of*? With respect to what should we minimize it?\n",
    "\n",
    "  - 2) How good is the log-loss as a choice of a loss function for binary classification?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b7df40",
   "metadata": {},
   "source": [
    "#### Answer to 1: Parametric models\n",
    "\n",
    "In 99% of the cases, we model the score function $p$ with some set of parameters, which we will collectively denote by $\\theta$, and write as $p_\\theta(x)$. A few examples:\n",
    "\n",
    "* In logistic regression, we explicitly write\n",
    "$$p_\\theta(x) = \\frac{1}{1 + \\exp(-\\theta_0 - \\sum_{a=1}^M \\theta_a x_a)}.$$\n",
    "Here, $\\theta$ is the set of coefficients $\\theta_0, \\theta_1, \\ldots, \\theta_M$.\n",
    "\n",
    "* In a classification tree, we separate the feature space in hypercubes. $\\theta$  are the set of splitting variables and thresholds chosen.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fceeed9d",
   "metadata": {},
   "source": [
    "In this scenario, one writes $L = L(\\theta)$ and finds (numerically, if needed) the solution to\n",
    "\n",
    "\n",
    "$$\\frac{\\partial L}{\\partial \\theta_a} = 0 \\quad \\mbox{ for all $a$}.$$\n",
    "\n",
    "Once the optimal $\\hat{\\theta}$ has been found via this method, we can explicitly insert them in $p_\\theta$ and our job is done. Some methods to solve equations such as the one above include Newton's method and gradient descent (and its variations)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc87811",
   "metadata": {},
   "source": [
    "#### Answer to 2: weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a736c2",
   "metadata": {},
   "source": [
    "The standard log-loss equation weighs all samples $i$ equally. It might happen that one wants to penalize a subset of points more than others; this is usually the case in imbalanced learning, where the number of points with $y=1$ is much smaller than that of $y=0$ (we call $y=1$ the minority class here). Then, one might choose to add more weight to errors in that class, since it is a harder class to predict.\n",
    "\n",
    "The equation gets then modified to\n",
    "\n",
    "$$L = - \\frac{\\sum_{i=1}^N w_i \\left[y_i \\log p(x_i) + (1-y_i) \\log(1-p(x_i))\\right]}{\\sum_{i=1}^N w_i}$$\n",
    "\n",
    "for some set of pre-determined weights $w_i$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17445bef",
   "metadata": {},
   "source": [
    "In `scikit-learn`, when choosing to use the log-loss, one can explicitly pass weights via the `sample_weight` attribute (similarly in other libraries, eg. LightGBM has an option `scale_pos_weight` to choose the weight of the positive class). \n",
    "\n",
    "To illustrate this, given our ground truths, suppose that we have built a model with some predictions (for $p(x_i)$!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29b206ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "y      = np.array([1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1])    # true values\n",
    "y_pred = np.array([0.90, 0.10, 0.05, 0.80, 0.85, 0.03, 0.01, 0.08, 0.88, 0.98, 0.12, 0.20, \n",
    "                   0.10, 0.20, 0.11, 0.79, 0.25, 0.98, 0.16, 0.10, 0.78, 0.98, 0.01])       # our predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f782a9",
   "metadata": {},
   "source": [
    "Now we can calculate the standard log-loss, with equal weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4adb9482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard log-loss: 1.12\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "\n",
    "print(\"Standard log-loss: %.2f\" % log_loss(y_true=y, y_pred=y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a634a1b",
   "metadata": {},
   "source": [
    "If we choose to weigh the $y=1$ class twice as much as the $y=0$ class, we can pass that as an optional argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84e54216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighed log-loss: 1.22\n"
     ]
    }
   ],
   "source": [
    "weights = np.where(y==1, 2, 1)  # weight = 2 for y=1, and weight = 1 for y=0\n",
    "print(\"Weighed log-loss: %.2f\" % log_loss(y_true=y, y_pred=y_pred, sample_weight=weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd47986",
   "metadata": {},
   "source": [
    "The value is now higher: our model does a slightly worse job at predicting class 1 than class 0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83c52ee",
   "metadata": {},
   "source": [
    "### Is log-loss the only loss?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30faaa5",
   "metadata": {},
   "source": [
    "In practice, **yes** - the classification algorithms you see out there all minimize (weighted) cross-entropy during training.\n",
    "\n",
    "It is not, however, the only *metric*. There are several metrics (ROC AUC, Precision / Recall, $F_1$ to name a few) which can be used to assess how good a model is. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7ada4f",
   "metadata": {},
   "source": [
    "### Why do we call $p(x)$ the \"score\"?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19151a3",
   "metadata": {},
   "source": [
    "It would be more intuitive, perhaps, to call $p(x)$ a probability. Indeed, it is a type of probability: the probability that $Y=1$ given that $X=x$.\n",
    "\n",
    "The main reason we call it a score is that most algorithms **do not estimate the probability $p(x)$ directly**. Logistic regression is one of the few algorithms which do, but most of the useful ones - random forests, gradient boosted trees, neural networks - do not. In this case, we are actually predicting a modified version of $p(x)$. To make the discussion simpler, we will call everything a score, and leave the discussion of actually estimating probabilities to the chapter on calibration.\n",
    "> Indeed, for many use cases (such as credit scoring, product recommendations, or fraud detection) actual probababilities are not that important; rather, their *ordering* is. So it wouldn't matter that my probability of defaulting on a payment is 15%; what matters is that it is 15% while my friend Bob's is 30%, hence mine is *lower* (by how much, we don't know). This is not the case for insurance, for example, where actual expected values need to be calculated. We will discuss this later.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e50a81b",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d100072f",
   "metadata": {},
   "source": [
    "# Classification metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601027a4",
   "metadata": {},
   "source": [
    "Recall that the threshold is the number $\\lambda$ such that we set the model's prediction to 1 if the score is greater than $\\lambda$, and 0 otherwise.\n",
    "\n",
    "Why do we split our discussion between threshold dependent and independent metrics?\n",
    "\n",
    "There are two reasons:\n",
    "\n",
    "1. In the modelling pipeline, finding a continuous score model comes first - only after that comes defining a threshold. Usually, one picks the best model in a threshold-independent way. If the application requires them to define a binary output (which is not always the case), then one tries to find a good threshold *after* the model has been chosen.\n",
    "\n",
    "2. There is no \"best\" threshold - it will be found as the result of a calculation including trade-offs (between false positives vs false negatives, for example). Because of this, it is better to keep the discussion of how to find a threshold to later.\n",
    "\n",
    "Thus, we start with a good understanding of threshold-independent metrics. These are *usually* the most important, the ones you see published, and that make an actual business impact.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef130d6f",
   "metadata": {},
   "source": [
    "## Our sample data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4174e93",
   "metadata": {},
   "source": [
    "Throughout this section, we will use the following simulated data with 10 features and 1000 data points, out of which only 8 are meaningful:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a39ca529",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# create dummy classification problem\n",
    "X, y = make_classification(n_samples=5000, n_features=10, n_informative=8, n_redundant=1, n_repeated=1, \n",
    "                           random_state=10) # for reproducibility\n",
    "\n",
    "# split train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ecfd53d",
   "metadata": {},
   "source": [
    "## The base ingredient: confusion matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960d8993",
   "metadata": {},
   "source": [
    "All metrics will be build from a single fundamental element: the confusion matrix.\n",
    "\n",
    "Basically, assume for a second you have an estimator $\\hat y(x)$. This supposes you have created a score function and chosen a threshold, so that $\\hat y(x)$ will give 1's and 0's. \n",
    "\n",
    "Now, given an observation $(x, y)$ (with $y$ equal to 0 or 1) there are **four possible outcomes** when we compare the real $y$ to the prediction $\\hat y(x)$:\n",
    "\n",
    "1. $y=0$ and $\\hat y = 0$: right prediction. This is called a **true negative (TN)** (since we also call the class 0 the \"negative class\")\n",
    "2. $y=0$ and $\\hat y = 1$: wrong prediction. This is called a **false positive (FP)** (since we falsely predicted the class 1, also known as the positive class)\n",
    "3. $y=1$ and $\\hat y = 0$: wrong prediction. This is called a **false negative (FN)**.\n",
    "4. $y=1$ and $\\hat y = 1$: right prediction. This is called a **true positive (TP)**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57549203",
   "metadata": {},
   "source": [
    "These 4 possibilities can be stored in a 2x2 matrix called the **confusion matrix**. We illustrate below how to build one in `scikit-learn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8422622",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAASwAAAEKCAYAAACoiGheAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAU6ElEQVR4nO3deZAedZ3H8fdnJglDDiAhARLOIAgbUA5HFFiVSzmkdHWxFkSttdwF8cADsLRqFRfX3a1y2VUXFWfBY0VQgaCikEBxGLAQSEKAHERYwCQENoRDcpI5vvvH07MMYeaZ7uTpdP8mnxfVNd3P08c3CfOt3+/Xv0MRgZlZCtqqDsDMLC8nLDNLhhOWmSXDCcvMkuGEZWbJcMIys2Q4YZlZZSR9TtIiSQslXSOpo9n5TlhmVglJewLnA50RcSjQDpzZ7BonLDOr0ihgR0mjgLHAyuFOro328eNi1KRJVYdhBeywfF3VIVgBG1nHpnhZW3OPk48fF88935vr3HkPvbwI2Djgo66I6AKIiKck/RuwDNgA3BIRtzS7X60S1qhJk5h2wWerDsMKOOBzf6g6BCvg3rhtq+/x3PO93Dd7n1zntk99dGNEdA72naSJwHuB6cCLwLWSPhQRVw11P1cJzayQAPpy/jeMk4AnIuLZiOgGZgLHNLugViUsM6u/IOiOfFXCYSwD3ippLI0q4YnA3GYXOGGZWWE5Sk/Dioh7JV0HzAd6gAeArmbXOGGZWSFB0Nuiaaki4mLg4rznO2GZWWF9VDOPnhOWmRUSQK8TlpmlwiUsM0tCAN0VTa3uhGVmhQThKqGZJSKgt6K1a5ywzKyQRk/3ajhhmVlBopetGj+9xZywzKyQRqO7E5aZJaDRD8sJy8wS0ecSlpmlwCUsM0tGIHormkrPCcvMCnOV0MySEIhN0V7Js52wzKyQRsdRVwnNLBFudDezJESI3nAJy8wS0ecSlpmloNHoXk3qcMIys0Lc6G5mSel1PywzS4F7uptZUvr8ltDMUtAY/OyEZWYJCES3h+aYWQoiqKzjaDVPNbOEib6cW9O7SAdJWjBge0nSZ5td4xKWmRUStKaEFRFLgcMBJLUDTwE3NLvGCcvMCiuh0f1E4H8i4k/NTnLCMrNCApUxgd+ZwDXDneSEZWaFNJb5yp06JkuaO+C4KyK6Bp4gaQzwHuBLw93MCcvMCiq0kOrqiOgc5pxTgfkR8b/D3cwJy8wKCVre0/0sclQHwQnLzLZAq2YclTQWeCdwbp7znbDMrJAItayEFRHrgV3znu+EZWaFNBrdPTTHzJLgOd3NLBGNRndP4GdmifD0MmaWhJJ6uufihGVmhXkRCjNLQgR09zlhmVkCGlVCJywzS0SreroX5YRVsn0vmU9fRztIRJtYccEbqg7JhjBl2iYu+tYyJu7WQ/TBTVftyi+vnFJ1WLUzYrs1SDoF+BbQDlwREf9a5vPq6qlPzKBv/Oiqw7Bh9PaIrkum8djDY9lxXC+Xzfoj8+dMYNmjHVWHVjPVVQlLe2o25el3aEwdMQM4S9KMsp5ntrWeXzWaxx4eC8CGde0sf6yDyVO7K46qnloxp/uWKLOEdRTwWEQ8DiDpZ8B7gcUlPrN+JKZdvgQkXjp6N146ZveqI7Icdt9rE687dAOPzB9bdSi103hLOPLGEu4JLB9wvAJ4y+YnSToHOAegfeLEEsOpxorzD6F35zG0r+lm2uVL2LT7jmx83U5Vh2VNdIzt5ctXPMnlX5nG+rXV/GLWWZUdR8usiA72J4rXfBDRFRGdEdHZPn5cieFUo3fnMY2fE0az7g0T6Vi2tuKIrJn2UcGXr3iS22dO5Pc371J1OLVVVZWwzIS1Ath7wPFewMoSn1c7erkXbez9//0dl/6ZTXu4ilFfwecvXc7yRzuY2eW3g0Ppf0uYZ2u1MquE9wMHSppOY72xM4EPlvi82mlf083UH/6xcdAbrH3TZNb/xS6VxmRDO+SodZz0gRd4fHEH3711KQA//Jep3H+7q/CbG3EdRyOiR9KngNk0ujX8ICIWlfW8OuqZ3MHyi95YdRiW06L7xnPytMOqDqP2IkTPSEtYABFxE3BTmc8ws21vRHYcNbORZ8T2dDezkckJy8yS4An8zCwpZfSxysMJy8wKiYAeT+BnZqlwldDMkuA2LDNLSjhhmVkqqmp0r6blzMySFdG6wc+SdpF0naRHJC2RdHSz813CMrOCRG/r3hJ+C5gVEWdIGgM0nc7ECcvMCmtFG5aknYC3A3/buGdsAjY1u8ZVQjMrpOB8WJMlzR2wnTPgVvsDzwI/lPSApCskNZ3F0wnLzIqJRjtWng1Y3T+jcLZ1DbjTKOBI4HsRcQSwDvhis0c7YZlZYS2aInkFsCIi7s2Or6ORwIbkNiwzKyRa1OgeEc9IWi7poIhYCpzIMKtqOWGZWWHxmuVkttingZ9mbwgfBz7a7GQnLDMrrFU93SNiAdCZ93wnLDMrpNGg7qE5ZpYID342s2S0sA2rECcsMyskEH2ewM/MUlFRAcsJy8wKcqO7mSXFbVhmloralbAk/SdN8mhEnF9KRGZWawH09dUsYQFzt1kUZpaOAOpWwoqIHw88ljQuItaVH5KZ1V1V/bCG7Uwh6WhJi4El2fFhkr5bemRmVl+Rc2uxPL2/vgmcDDwHEBEP0pjW1My2SyIi39Zqud4SRsRy6VUP7215JGaWjhp3a1gu6RggsjlrzierHprZdiggKnpLmKdK+HHgk8CewFPA4dmxmW23lHNrrWFLWBGxGji75U82s3TV+C3h/pJulPSspFWSfiVp/20RnJnVVI3fEl4N/AKYCkwDrgWuaX0oZpaE/o6jebYWy5OwFBE/iYiebLuK6maXMLMaKLAuYUs1G0s4Kdu9Q9IXgZ/RSFR/A/y29aGYWTJqOJZwHo0E1R/ZuQO+C+BrZQVlZvWmuvXDiojp2zIQM0tESQ3qeeTq6S7pUGAG0NH/WUT8d1lBmVmdldOgnsewCUvSxcBxNBLWTcCpwN2AE5bZ9qqu/bCAM2isef9MRHwUOAzYodSozKze+nJuLZanSrghIvok9UjaCVgFuOOo2faqjhP4DTBX0i7Af9F4c7gWuK/MoMys3lr1llDSk8AaGjPA9EREZ7Pz84wl/ES2e7mkWcBOEfHQ1gZqZglrbRvW8dmY5WE16zh6ZLPvImL+lkRmZralmpWwLm3yXQAntDgWdni+jwN+vr7Vt7USzV65oOoQrICjTm7N71eBKuFkSQMXtOmKiK4BxwHcIimA72/23Ws06zh6fO6QzGz7ERQZmrN6mHapYyNipaTdgFslPRIRc4Y6OU+3BjOzV2vR9DIRsTL7uQq4ATiq2flOWGZWmCLf1vQe0jhJE/r3gXcBC5td46Xqzay41rwl3B24IVvgZhRwdUTManZBnqE5ojFF8v4RcYmkfYA9IsJ9scy2Vy1IWBHxOI2RM7nlqRJ+FzgaOCs7XgN8p1hoZjZS5K0OljEFTZ4q4Vsi4khJDwBExAvZcl9mtr2q4QR+/boltZMVAiVNoZRhjWaWiqom8MtTJfw2jdeNu0n6Oo2pZf651KjMrN4qWjUnz1jCn0qaR2OKGQF/FRFe+dlse1VS+1Qeed4S7gOsB24c+FlELCszMDOrsbomLBor5PQvRtEBTAeWAoeUGJeZ1ZgqasXOUyV8w8DjbBaHc4c43cysNIV7ukfEfElvLiMYM0tEXauEkj4/4LANOBJ4trSIzKze6tzoDkwYsN9Do03r+nLCMbMk1DFhZR1Gx0fERdsoHjNLQd0SlqRREdHTbKpkM9v+iHq+JbyPRnvVAkm/Bq4F1vV/GREzS47NzOqo5m1Yk4DnaMzh3t8fKwAnLLPtVQ0T1m7ZG8KFvJKo+lUUrpnVQg0TVjswnlcnqn5OWGbbsTpWCZ+OiEu2WSRmlo4aJqxqZugys3qLer4lPHGbRWFmaalbCSsint+WgZhZOurYhmVmNjgnLDNLQknTH+fhhGVmhQhXCc0sIU5YZpYOJywzS0aN1yU0M3tFi5eql9Qu6QFJvxnuXCcsMyuutQupfgbItdapE5aZFaa+fNuw95H2At4NXJHnuW7DMrPCCrwlnCxp7oDjrojoGnD8TeALvHrtiCE5YZlZMcWqe6sjonOwLySdDqyKiHmSjstzMycsMyuuNW8JjwXeI+k0GqvK7yTpqoj40FAXuA3LzArp7+m+tW8JI+JLEbFXROwHnAnc3ixZgUtYZrYF1FdNRywnLDMrpoTBzxFxJ3DncOc5YZlZYR5LaGbpcMIys1S4hGVm6XDCMrMk1HTVHDOz1/CMo2aWlnA/LDNLhEtYI8zo0b1c+k+zGT26j/a2Pu66Z19+8vPDqg7LhjGzawo3Xz0JCaYfvJEL/mMZYzoq+u2sqwpXzSltLKGkH0haJWlhWc+os+7uNr5w8Ts57/Onc94Fp9N5xFMc/Ppnqw7Lmlj99Gh+eeVkLrv5j3TdsZTePrjzVxOrDquWWjUfVlFlDn7+EXBKifevObFx42gARrX30T4qqqr2WwG9PeLljW309sDLG9rYdffuqkOqpaoSVmlVwoiYI2m/su6fgra2Pi77xk1M22MNN846iKWPTqk6JGti8tRuzjhvFR9+8wx26AiOfMdLvOm4NVWHVT9BZY3ulU8vI+kcSXMlze3uXld1OC3V19fGJy44nbP//q856IDV7LvPC1WHZE2sebGde2bvzI/vXczVDyxk4/p2brveVcLBtHIRiiIqT1gR0RURnRHROXr0uKrDKcW69WN4cNHuvPmIlVWHYk08cNd49th7E7vs2suo0XDsaS+yeO7I/H9yq7V2EYrcKk9YI9XOO21k3NhNAIwZ08ORb3yG5St2rjgqa2a3PbtZMn8sG9eLCFhw9wT2OWBj1WHVTqsm8NsS7tZQkkkTN3Dhp39PW1vQ1hbM+f1+3Dtvr6rDsiYOPnI9b3v3n/nkyQfRPio44NANnPqh56oOq34iRt4EfpKuAY6jsWrGCuDiiLiyrOfVzRN/msgnLzy96jCsoI9c9AwfueiZqsOov5HWcTQizirr3mZWLfd0N7M0BDDSqoRmNoK5hGVmqXCV0MySMeLeEprZCFXhbA1OWGZWSKPjqEtYZpYKz+luZqlwCcvM0uA2LDNLR2vGEkrqAOYAO9DIRddFxMXNrnHCMrPiWlMlfBk4ISLWShoN3C3p5oj4w1AXOGGZWTEtWkg1IgJYmx2OzrammdDzYZlZcRH5tmFIape0AFgF3BoR9zY73wnLzIrLP+Po5P4p0LPtnFfdJqI3Ig4H9gKOknRos8e6Smhmhakvd51wdUR0DndSRLwo6U4aK20NuTSgS1hmVkzQ6DiaZ2tC0hRJu2T7OwInAY80u8YlLDMrRESrOo5OBX4sqZ1G4ekXEfGbZhc4YZlZcS1IWBHxEHBEkWucsMysOA/NMbMk9LdhVcAJy8wKK/CWsKWcsMysoHydQsvghGVmxQROWGaWELdhmVkqPIGfmaXDCcvMkhABvX5LaGapcAnLzJLhhGVmSQjAKz+bWRoCwm1YZpaCwI3uZpYQt2GZWTKcsMwsDR78bGapCMDTy5hZMlzCMrM0eGiOmaUiINwPy8yS4Z7uZpYMt2GZWRIi/JbQzBLiEpaZpSGI3t5KnuyEZWbFeHoZM0tKRd0a2ip5qpklK4Doi1xbM5L2lnSHpCWSFkn6zHDPdgnLzIqJlk3g1wNcEBHzJU0A5km6NSIWD3WBE5aZFdaKRveIeBp4OttfI2kJsCcwZMJSVPR6cjCSngX+VHUcJZgMrK46CCtkpP6b7RsRU7bmBpJm0fj7yaMD2DjguCsiuga5537AHODQiHhpyGfXKWGNVJLmRkRn1XFYfv4323YkjQd+B3w9ImY2O9eN7mZWGUmjgeuBnw6XrMAJy8wqIknAlcCSiPj3PNc4YW0br6mzW+3536x8xwIfBk6QtCDbTmt2gduwzCwZLmGZWTKcsMwsGU5YJZJ0iqSlkh6T9MWq47HhSfqBpFWSFlYdi72WE1ZJJLUD3wFOBWYAZ0maUW1UlsOPgFOqDsIG54RVnqOAxyLi8YjYBPwMeG/FMdkwImIO8HzVcdjgnLDKsyewfMDxiuwzM9tCTljl0SCfuQ+J2VZwwirPCmDvAcd7ASsrisVsRHDCKs/9wIGSpksaA5wJ/LrimMyS5oRVkojoAT4FzAaWAL+IiEXVRmXDkXQNcA9wkKQVkj5WdUz2Cg/NMbNkuIRlZslwwjKzZDhhmVkynLDMLBlOWGaWDCeshEjqzWZlXCjpWkljt+JeP5J0RrZ/RbOB2ZKOk3TMFjzjSUmvWV1lqM83O2dtwWd9VdKFRWO0tDhhpWVDRBweEYcCm4CPD/wymyGisIj4u2aLVwLHAYUTllmrOWGl6y7ggKz0c4ekq4GHJbVL+oak+yU9JOlcaEz4L+kySYsl/RbYrf9Gku6U1JntnyJpvqQHJd2WrRf3ceBzWenubZKmSLo+e8b9ko7Nrt1V0i2SHpD0fQYfT/kqkn4paV62VPk5m313aRbLbZKmZJ+9TtKs7Jq7JB3ckr9NS0NEeEtkA9ZmP0cBvwLOo1H6WQdMz747B/iHbH8HYC4wHXg/cCvQDkwDXgTOyM67E+gEptCYYaL/XpOyn18FLhwQx9XAX2b7+9BY9QTg28BXsv130xjsPXmQP8eT/Z8PeMaOwEJg1+w4gLOz/a8Al2X7twEHZvtvAW4fLEZvI3PzUvVp2VHSgmz/LhpLJB0D3BcRT2Sfvwt4Y3/7FLAzcCDwduCaiOgFVkq6fZD7vxWY03+viBhqXqiTgBmNVZoA2EnShOwZ78+u/a2kF3L8mc6X9L5sf+8s1ueAPuDn2edXATOzBTePAa4d8OwdcjzDRggnrLRsiIjDB36Q/eKuG/gR8OmImL3Zeacx/PQ2ynEONJoSjo6IDYPEknusl6TjaCS/oyNivaQ7aSxtPpjInvvi5n8Htv1wG9bIMxs4L1tRF0mvlzQOmAOcmbVxTQWOH+Tae4B3SJqeXTsp+3wNMGHAebfQGNhNdt7h2e4c4Ozss1OBicPEujPwQpasDqZRwuvXBvSXEj8I3B0RLwFPSPpA9gxJOmyYZ9gI4oQ18lwBLAbmZwspfJ9GSfoG4FHgYeB7wO82vzAinqXRBjZT0oO8UiW7EXhff6M7cD7QmTXqL+aVt5X/CLxd0nwaVdNlw8Q6Cxgl6SHga8AfBny3DjhE0jzgBOCS7POzgY9l8S3C005vVzxbg5klwyUsM0uGE5aZJcMJy8yS4YRlZslwwjKzZDhhmVkynLDMLBn/B2VrsS3/W45GAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "# assume we have a series of observed and predicted labels\n",
    "y_real = [1,1,1,1,0,0,1,0,1,0,1,0,1,1,1,1,0,0]\n",
    "y_pred = [1,1,0,1,0,1,1,0,1,0,1,1,1,0,0,1,0,0]\n",
    "\n",
    "# first we build a confusion matrix object...\n",
    "matrix = confusion_matrix(y_real, y_pred)\n",
    "\n",
    "#... which we then plot\n",
    "ConfusionMatrixDisplay(matrix).plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d982c9",
   "metadata": {},
   "source": [
    "#### --- Mathematical interlude ---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62eea29b",
   "metadata": {},
   "source": [
    "Assume we have $N$ iid observations $\\{x_i, y_i\\}_{i\\in1:N}$. We can define a *normalized estimator* of true positives as\n",
    "\n",
    "$$\\frac{\\mathrm{\\widehat{TP}}}{N} := \\frac{1}{N} \\sum_{i=1}^N \\mathbf{1}_{\\hat{y} (x_i) = 1 \\cap y_i=1}$$\n",
    "\n",
    "where the indicator variable $\\mathbf{1}_A$ is 1 if $A$ is true and 0 if it is false. Here, it will be one if both $y_i$ and the estimate $\\hat{y}(x_i)$ are 1.\n",
    "\n",
    "Why normalized? Because in practice the total amount of true positives (or any other cell of the confusion matrix for that matter) doesn't really matter. What matters are their ratios, and this should stay true as $N$ grows larger. Thus, even though you will see expressions such as $\\mathrm{TP/(TP+FN)}$ below and in many other sources, you should really take them to be $\\mathrm{\\widehat{TP}}/N/(\\mathrm{\\widehat{TP}}/N + \\mathrm{\\widehat{FN}}/N)$.\n",
    "\n",
    "**Proposition**. $\\mathrm{\\widehat{TP}}/N$ is an unbiased estimator of $\\mathbb{P}(\\hat y(x)=1 \\cap y = 1)$.\n",
    "> Proof: taking the expectation, and using that $\\mathbb{E}[\\mathbf{1}_A] = \\mathbb{P}(A)$, we get\n",
    "$$\\mathbb{E} \\left[\\frac{\\mathrm{\\widehat{TP}}}{N} \\right] = \\frac 1N \\sum_{i=1}^N \\mathbb{E}[\\mathbf{1}_{\\hat y(x_i) = 1 \\cap y_i = 1}] = \\frac NN \\mathbb{P} (\\hat y(x_i) = 1 \\cap y_i = 1) = \\mathbb{P} (\\hat y(x_i) = 1 \\cap y_i = 1),$$\n",
    "where we were able to break the sum into $N$ copies of the summand from the hypothesis of independence between the samples.\n",
    "\n",
    "These results will be important when creating metrics from the confusion matrix, in particular in the discussion about ROC AUC.\n",
    "\n",
    "**--- end of interlude ---**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cea86cb",
   "metadata": {},
   "source": [
    "### A quick disclaimer: `predict` vs. `predict_proba`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3f685b",
   "metadata": {},
   "source": [
    "In `scikit-learn` (and `scikit-learn`-friendly libraries such as XGBoost and LightGBM) all classifiers contain at last two methods: `predict` and `predict_proba`. \n",
    "\n",
    "Their difference is straightforward: `predict` returns the predicted classes (0 or 1 in the binary case) whereas `predict_proba` returns a float between 0 and 1, with the score.\n",
    "> For most models, the output of `predict_proba` is **not** a probability, but simply a score. We will discuss this better in the calibration section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e94d86",
   "metadata": {},
   "source": [
    "To exemplify this, let's use a simple logistic regression model and see how it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "555e98ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3120a5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = X_train[25,:].reshape(1,-1) # take one training sample for us to predict\n",
    "model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ca517fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.12682433, 0.87317567]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36f9741",
   "metadata": {},
   "source": [
    "What `predict_proba` does is output two values: the probability that the $y=0$ given $x$ (12.7% here), and the probability of $y=1$ given $x$ (87.3%). In other words, it outputs $(1-\\mbox{score}, \\mbox{score})$. \n",
    "> Since we are in a binary case, we can just extract the last component via `model.predict_proba(x)[:,1]`, since the 0th component will be fully determined by it. In the multiclass case (with more than two classes) then it is important to have all components given."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb96a4b5",
   "metadata": {},
   "source": [
    "What `predict` does is to take the result of `predict_proba` and binarize it - essentially by just **applying a threshold of 0.5**! In order to keep things within our control, we recommend to simply use the predicted score via `predict_proba` and then feed it to different metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43045d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = model.predict_proba(X_train)[:,1]\n",
    "y_test_pred = model.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09f4266",
   "metadata": {},
   "source": [
    "### How well did our model do?\n",
    "\n",
    "Looking into the documentation, you might be tempted to use the model's `.score` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e07115d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Don't use this function\n",
      "Train score: 0.6762857142857143\n",
      "Test score: 0.668\n"
     ]
    }
   ],
   "source": [
    "print(\">> Don't use this function\")\n",
    "print(\"Train score: {}\".format(model.score(X_train, y_train)))\n",
    "print(\"Test score: {}\".format(model.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7c60e8",
   "metadata": {},
   "source": [
    "But we recommend you to never use the `score` function - since under the hood it calculates accuracies with the `predict` function, which we don't recommend."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8b9eef",
   "metadata": {},
   "source": [
    "Instead, we will present you with three useful threshold-independent metrics in what follows: the ROC AUC, average precision, and lift/delinquency curves.\n",
    "> We recommend you always use them all for your model assessments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f8b04f",
   "metadata": {},
   "source": [
    "### Ratios of the confusion matrix\n",
    "\n",
    "For now, fix a confusion matrix (this amounts to fixing an estimator $\\hat y(x)$, or equivalently, to training a score function $p(x)$ and fixing a threshold). One could ask questions such as: out of all the real positives, how many did we get right? Or, out of all the positives that we predicted, how many were actually positive? \n",
    "\n",
    "In most references, you will see these *rates* defined in terms of elements of the confusion matrix. Here, in order to keep up with the probabilistic language we have been using, we will define them a bit differently."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7dca84",
   "metadata": {},
   "source": [
    "[**True positive rate / sensitivity / TPR**] The TPR of an estimator is $$\\mathbb{P}(\\hat y(x) = 1 | y = 1),$$ that is, the probability that we predict a positive if that was indeed an element of the positive class.\n",
    "\n",
    "[**False positive rate, FPR**] The FPR of an estimator is $$\\mathbb{P}(\\hat y(x) = 1 | y = 0),$$ that is, the probability that we predict a positive for a member of the negative class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f4a407",
   "metadata": {},
   "source": [
    "Similar definitions can be made for the true negative rate and false negative rate, although these tend to be less commonly used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4062df5f",
   "metadata": {},
   "source": [
    "[**Calculating TPR from the confusion matrix**] TPR can be approximated from the confusion matrix via\n",
    "\n",
    "$$\\widehat{\\mathrm{TPR}} = \\frac{\\mathrm{\\widehat{TP}}}{\\mathrm{\\widehat{TP}+\\widehat{FN}}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472357be",
   "metadata": {},
   "source": [
    "> Proof: from the definition of conditional probability,\n",
    "$$\\mathrm{TPR} = \\mathbb{P}(\\hat y(x) = 1 | y = 1) = \\frac{\\mathbb{P}(\\hat y(x) = 1 \\cap y = 1)}{\\mathbb{P}(y=1)}.$$ We can break the denominator into $$\\mathbb{P}(y=1) = \\mathbb{P}(\\hat y(x) = 1 \\cap y =1) + \\mathbb{P}(\\hat y(x)=0 \\cap y=1).$$ (see note below on why) Then $$\\mathrm{TPR} = \\mathbb{P}(\\hat y(x) = 1 | y = 1) = \\frac{\\mathbb{P}(\\hat y(x) = 1 \\cap y = 1)}{\\mathbb{P}(\\hat y(x) = 1 \\cap y =1) + \\mathbb{P}(\\hat y(x)=0 \\cap y=1)} = \\mathrm{\\frac{TP}{TP+FN}}.$$ But we have seen before that $\\mathrm{\\widehat{TP}}/N$ is an unbiased estimator for $\\mathbb{P}(\\hat y(x) = 1 \\cap y = 1)$, and similarly for false negatives, so \"plugging hats\" on all estimators on the right-hand side yields the final result.  <font color='red'> TODO:  is not obvious that the ratio of estimators willalso be unbiased? consistent? etc. I could not find any references on this. </font>\n",
    "\n",
    "\n",
    "\n",
    "> Note: this comes from the general identity $\\mathbb{P}(A) = \\sum_i \\mathbb{P}(A \\cap B_i)$ where each $B_i$ is independent of the others, and together \"reconstruct\" $A$ in the sense that $A = \\cup_i (A \\cap B_i)$. Convince yourself of that drawing a few Venn diagrams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c2ef22",
   "metadata": {},
   "source": [
    "[**Calculating FPR from the confusion matrix**] Similar to TPR, one can calculate\n",
    "\n",
    "$$\\mathrm{\\widehat{FPR} = \\frac{\\widehat{FP}}{\\widehat{FP} + \\widehat{TN}}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a2c68b",
   "metadata": {},
   "source": [
    "## Number 1: The ROC curve and the ROC AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fbbfd60",
   "metadata": {},
   "source": [
    "The area under the ROC curve (ROC AUC) is, perhaps surprisingly, both the most used and the least understood metric in machine learning. In what follows we give a mathematically sound treatment of it. The main results will be highlighted, in case you want to skip the heavy math."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a3313a",
   "metadata": {},
   "source": [
    "`scikit-learn` makes everything seem like it is easy. It is literally just one line in order to calculate the ROC AUC of our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c05ad9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train ROC AUC: 0.7614\n",
      "Test ROC AUC: 0.7458\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "print(\"Train ROC AUC: {0:.4f}\".format(roc_auc_score(y_train, y_train_pred)))\n",
    "print(\"Test ROC AUC: {0:.4f}\".format(roc_auc_score(y_test, y_test_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f22e8a",
   "metadata": {},
   "source": [
    "But it is another thing to understand what is going on under the hood. We explain this below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c71c052",
   "metadata": {},
   "source": [
    "### Constructing the ROC curve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416354f2",
   "metadata": {},
   "source": [
    "From now on, we drop the hats on $\\widehat{\\mathrm{FPR}}, \\widehat{\\mathrm{TPR}}$ etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4300894",
   "metadata": {},
   "source": [
    "Notice that the whole discussion so far has considered a fixed estimator $\\hat y$, which in turn means we have a fixed threshold $\\lambda$ such that $\\hat y(x)=1$ if $f(x) \\geq \\lambda$ and 0 otherwise.\n",
    "\n",
    "Now, we **let $\\lambda$ vary from low to high**, and consider what happens to the $(x=\\mathrm{FPR}, y=\\mathrm{TPR})$ plane as $\\lambda$ changes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23ed7c6",
   "metadata": {},
   "source": [
    "[**Definition**] Let $\\mathrm{FPR}(\\lambda)$, $\\mathrm{TPR}(\\lambda)$ denote the false & true positive rates at threshold $\\lambda$. Then, the curve $\\lambda \\mapsto (\\mathrm{FPR}(\\lambda), \\mathrm{TPR}(\\lambda))$ obtained when $\\lambda$ varies between $]-\\infty, \\infty[$ is called the **receiver operating characteristic (ROC) curve**.\n",
    "> This name is historical. I bet 9 out of 10 of your data scientist friends won't know precisely what \"ROC\" stands for. I had to Google it too."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c2ac11",
   "metadata": {},
   "source": [
    "Before we use `scikit-learn` to plot it, let us intuitively understand what behaviors to expect from this curve. Consider the expression\n",
    "\n",
    "$$\\hat{y}(x) = \\begin{cases}\n",
    "1 & \\mbox{if } f(x) \\geq \\lambda \\\\\n",
    "0 & \\mbox{if } f(x) < \\lambda\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "When $\\lambda = - \\infty$ (or just super small), there is no way that $f(x) < \\lambda$, and so we never predict 0's. In other words, our estimator is just $\\hat y(x) \\equiv 1$ for all $x$. This estimator:\n",
    "* Gets all members of the positive class $(y=1)$ correctly, so the true positive rate is maximal\n",
    "* But it gets all members of the negative class $(y=0)$ wrongly. There are no true negatives nor false negatives.\n",
    "\n",
    "Hence it is easy to check that $\\mathrm{FPR} = \\mathrm{TPR} = 1$. This marks the point $(1,1)$ in the $\\mathrm{FPR-TPR}$ plane.\n",
    "\n",
    "Now go to the other extremum when $\\lambda = +\\infty$. Now the situation is reversed: $\\hat y(x) \\equiv 0$ for all $x$. Now there are no true nor false positives, so the numerators of both $\\mathrm{TPR, FPR}$ are 0, and we get the point $(0,0)$. For intermediate values of $\\lambda$, the curve will live inside the unit square:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c2500299",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUoAAAE9CAYAAABtDit8AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAA13UlEQVR4nO3dd3hUZfbA8e8hEEJHOlIkKl0RMcKCDWwLgoKKYsHuItZ1XRXEXtayuhYURVQWERFsKCrib3VBLEgVqYKstCAggjRpKef3x3uTTJJJ5qZMpp3P8+SZW947c+6EHN5771tEVTHGGFO0SpEOwBhjop0lSmOMCcESpTHGhGCJ0hhjQrBEaYwxIViiNMaYECpHOoCSatCggbZq1SrSYRhj4syCBQt+U9WGwfbFXKJs1aoV8+fPj3QYxpg4IyLritpnl97GGBOCJUpjjAnBEqUxxoQQc/cog8nIyCA9PZ39+/dHOpS4kJKSQvPmzalSpUqkQzEmKsRFokxPT6dWrVq0atUKEYl0ODFNVdm2bRvp6emkpqZGOhxjokJcXHrv37+f+vXrW5IsByJC/fr1rXZuTIC4SJSAJclyZN+lMfmFLVGKyFgR+VVElhaxX0RkpIisFpHFItIlXLGE27Zt2+jcuTOdO3emSZMmNGvWLHf94MGDIY+fOXMm3377bdB948aNo2HDhnTu3Jl27drxzDPP5Ns/ZswY2rVrR7t27ejatStff/117r6MjAyGDx9O69atOeqoo+jatSuffvpp2U7WmAQUznuU44AXgPFF7O8DtPZ+ugEvea8xp379+ixatAiABx54gJo1a3L77bf7Pn7mzJnUrFmTHj16BN0/aNAgXnjhBbZt20bbtm0ZOHAgLVq04OOPP+bll1/m66+/pkGDBixcuJABAwYwd+5cmjRpwr333sumTZtYunQpVatWZcuWLXz55ZflccrGJJSwJUpVnSUirYop0h8Yr26I9e9EpK6INFXVTeGKqSItWLCA2267jT179tCgQQPGjRtH06ZNGTlyJKNHj6Zy5cp06NCBxx9/nNGjR5OUlMSECRN4/vnnOemkk4K+Z/369TnyyCPZtGkTLVq04IknnuDJJ5+kQYMGAHTp0oUrrriCUaNGcdddd/HKK6+wZs0aqlatCkDjxo258MILK+w7MCbQxDnr+XDRRqpn76Ga7s3dXjfrd5plrqcKGSjld9vnj5a9uO38XuXyXpF86t0M2BCwnu5tK5QoRWQIMASgZcuWFRJcWagqN998Mx9++CENGzZk8uTJ3H333YwdO5bHH388N3nt2LGDunXrMnToUF+10PXr17N//346deoEwLJlyzjuuOPylUlLS+P1119n9erVtGzZktq1a4ftPE0M27cD1s+GX1cwb1MGi9N35O4SoPXBFexMqpvvkAZZW6mRvYcDUtX3x7TIXEfjrM0ADNQkLpGsssfu0xv7y6/VRiQTZbD/OoJO4KOqY4AxAGlpacVO8vPgR8tY/suuskcXoMOhtbn/7I6+yx84cIClS5dyxhlnAJCVlUXTpk0B6NSpE5deeikDBgxgwIABvt5v8uTJzJgxg5UrV/LKK6+QkpJSZFlVtYcxiSI7CzQb1syCrAwAZq7aytyft5Ka8T+OzFhJJc2iReY66mVvK/Jtjvd+gtkr1XOXK2smyRxkQ+WWZOKvje1eqcGuSnVYX7kVP1VpR5vGtejYsArUagLV63ulFKpUh4btoHo9X+/rx2XVyu+9Ipko04EWAevNgV8iFEu5UlU6duzI7NmzC+375JNPmDVrFlOnTuXhhx9m2bJlId8v5x7l7Nmz6du3L3369KFJkyZ06NCBBQsWcOqpp+aWXbhwIR06dODII49k/fr17N69m1q1apXr+ZmKN3HOej78Pp0bdv6LBllb6HhwSdByPb2fQD9VaYsi/FzlSNZVOSJ3e2XNYG7KCWxNakzvo5py/nHN8w6qVBmq1aU6hbUIsi2Uo7yfWBXJRDkVuElEJuEe4uwsj/uTJan5hUvVqlXZunUrs2fPpnv37mRkZLBq1Srat2/Phg0b6NWrFyeeeCITJ05kz5491KpVi127QteCu3fvzmWXXcZzzz3HY489xp133smwYcOYPn167gOlcePGMWfOHKpXr84111zDLbfcwssvv0xycjKbNm3iiy++YPDgwRXwLRi/cu7dFSUley9Pb76CS2R37raVVdpTJ3sHc1N6kKwH+bZaTzK8Wt4pbRvR++hmULcFVK1D60qucUt9CtccB5TzucSrsCVKEXkL959bAxFJB+4H95tU1dHANOAsYDWwF7gqXLFUtEqVKvHuu+9yyy23sHPnTjIzM7n11ltp06YNgwcPZufOnagqf/vb36hbty5nn302AwcO5MMPPyz2YQ7AsGHD6NKlCyNGjOCcc85h48aN9OjRAxGhVq1aTJgwIfcy/5FHHuGee+6hQ4cOpKSkUKNGDR566KGK+hpMEQomxjlrtgPQLdVdKtbI3s2f9n9Ft31fc8zBha5Qzt2Udv1gwIu0TakDwDne5t4VEXgCk1ib1zstLU0Ljke5YsUK2rdvH6GI4pN9p+Excc56Rkxxl83dUutRSbM4Y+8nnF3pGxrWqwc/zwhylEDXv8Bp90PVmhUbcAIRkQWqmhZsX1z09TYmGgW7pJ6zZjt/SfqYaxuvovGmAgNQ7wCq1XPJsPvNcPgp0LBthcVrimaJ0phyFJgcAy+pkzSDE/bN5KXq/6Ze9nbYDtRp6ZJik05w2n1Qp1kEIzfFsURpTDnISZCBybFbaj36d27GJfoJTB+e/4BzX4ZjLopApKY0LFEaU0YF7zv279yMS7q1hIXjYdq5kLnPFaxUBYZ+BY3s3m+ssURpTBkEJslHBxzFJUuuhk/nQ8GxR/qPgmOtWVasskRpTCkFJsmJXdfSY/oleTubdIK6LeHkO+DQzpEJ0JQbS5TlYNu2bZx22mkAbN68maSkJBo2dNMDz507l+Tk5CKPnT9/PuPHj2fkyJG+P69Vq1bUqlULEeGQQw5h/PjxHHbYYYAb7f3GG29k+fLlZGdn069fP5588sncGObOncvtt9/Oli1bEBFOPPFERo4cSfXqwfpgmKLkJMna7GFxyhBY7O2odgjcutSa8cSZuBm4N5JyesUsWrSIoUOH8re//S13PTk5mczMzCKPTUtLK1GSzDFjxgwWL15Mz549eeSRRwDXdfK8885jwIAB/PTTT6xatYo9e/Zw9913A7BlyxYuuOACnnjiCVauXMmKFSvo3bs3u3fvLu6jTAET56xnwgcf8VjlV1ySzHHdLBi21pJkHLJEGSZXXnklt912G7169WLYsGHMnTuXHj16cOyxx9KjRw9WrlwJuLEo+/XrB7ixLK+++mp69uzJ4Ycf7iuBdu/enY0bXXOU//73v6SkpHDVVa6TU1JSEs888wxjx45l7969jBo1iiuuuILu3bsDbiTzgQMH0rhx43B8BfFFFdIXwAvHc+ZnpzKt6gguruw1Dq9SA+7fAU2PiWiIJnzs0juMVq1axeeff05SUhK7du1i1qxZVK5cmc8//5wRI0bw3nvvFTrmxx9/ZMaMGezevZu2bdty/fXXFzsb4vTp03NHIQo27Frt2rVp2bIlq1evZunSpVxxxRXleo4J4fVzYE3egMcNgD+kBjX6PAidL4Vku20R7+IvUX46HDYHH1ml1JocDX0eL/FhF1xwAUlJSQDs3LmTK664gp9++gkRISMjI+gxffv2pWrVqlStWpVGjRqxZcsWmjdvXqhcr1692LJlC40aNcp36R1siDUbeq2U0ufDq6flri7MPpLnM89lb8tT6X9scy7pGv1jo5ryYZfeYVSjRo3c5XvvvZdevXqxdOlSPvrooyJnOcwZjRzcpXNR9zdnzJjBunXr6NixI/fddx8AHTt2pGA/+F27drFhwwaOOOIIOnbsyIIFC8p6WvFv1y/w0on5kuTx+0dx3sGHOKP/5Uwe2sO1kzQJI/5qlKWo+VWEnTt30qyZ66I2bty4cnnPatWq8eyzz3L00Udzzz33cNpppzF8+HDGjx/P5ZdfTlZWFn//+9+58sorqV69OjfddBNdu3alb9++dOvmpieaMGECp59+Ok2aNCmXmGLe7+vguU55691vYtDafmxds51Hzz3aEmSCshplBbnzzju56667OOGEE8jKKr/h8Js2bcrFF1/MqFGjEBGmTJnCO++8Q+vWrWnTpg0pKSk8+uijgJszZ9KkSdx+++20bduW9u3b89VXX9l0ETnevSZfkpzYezGD1vZj+aZddEutZ0kygdkwayaohPpO/+8e+Pb5vNXq/Xit9o3MWfs7UKBboolbNsyaMUXZvDQvSbY6iRG7B/LRtqZ0qCOWIE0uS5QmManCD2/BB9cDsKD9MP65oxfLt+2iQ9PaTL6ue4QDNNHEEqVJPHu3wz/zpjLdX+UQBn5/NMr23FqkMYHiJlFaW8HyE2v3rUskOytfkryn/tNM2Oie+NtTbVOUuEiUKSkpbNu2jfr161uyLCNVZdu2bcXOHR7TxpySu9hq/5uw0e5FmtDiIlE2b96c9PR0tm7dGulQ4kJKSkrQ3kAx76f/5PbaurrxO7Auw2qRxpe4SJRVqlQhNTU1dEGTsCbOWc8lnw4E4P+q92XeFrW2kca3uEiUxoSS/NVjucuv1bmZDnWwhzbGN0uUJv5lZzFwz0S3fOl7TG5tTX9MyVgXRhPX3v7mR3ioHgDLkjtB69MjHJGJRZYoTVyr/u0TucvLT34xgpGYWGaX3iY+ZeyH96+l3x8fufU7/scFNRpENiYTsyxRmvgzfQR8Nyp39bXaN3KNJUlTBpYoTVxZ+e+htF33FgD/yTqOj5vcQLe0rhGOysQ6S5QmfkwYSNt1/wHgmbojaNz9Yp6zdpKmHPhKlCJSCTgGOBTYByxT1S3hDMwYX1ThqTbwx6+5m56pO4K/3TosgkGZeFNsohSRI4BhwOnAT8BWIAVoIyJ7gZeB11U1O9yBGlPIgT3wWF6j8S+yjuWxzIu5unufCAZl4lGoGuUjwEvAdVpgSBkRaQRcAlwGvB6e8IwpxjMdcxeP3z+KrRxifbdNWBSbKFX14mL2/Qo8W94BGePH7PdfoPv+HYA3ChBiSdKETakf5ojIGar6n/IMxhhfpt1J98UvA/D4IQ/SLaW+DZNmwqosT71fA+xfpqlYWRkw1yXJ12sNYfhfb41sPCYhhHqYM7WoXUD98g/HmGL8sih34N2V2c2ZVvM8rohsRCZBhKpRngQMBvYU2C6AteI1FWfmEzDz0dzVfgcf5UEbJs1UkFCJ8jtgr6p+WXCHiKwMT0jG5LdkwnCOXv0SAHOz23LhwfvtwY2pUKGeehfZIE1VTy7/cIzJ74c37+EYL0k+dsjDLEo5nkftwY2pYGHtwigivYHngCTgVVV9vMD+OsAE3EOhysBTqvrvcMZkYsPEOetZ990U7vr9eQA+7zqWu846P8JRmUQVtvEoRSQJGAX0AToAF4tIhwLFbgSWq+oxQE/gXyKSHK6YTOz4fOGP3PX7fQDM6Xgfp1uSNBEUzoF7uwKrVfVnVT0ITAL6FyijQC1xc8zWBLYDmWGMycSIsVsuyF3uNvC2CEZiTHgTZTNgQ8B6urct0AtAe+AXYAnwV+s3nuCyMuCBOgBkUwke2Ak2V7uJMN+JUkQeKG492CFBtmmB9T8Di3CjEnUGXhCR2kE+e4iIzBeR+TZ3dxxThYfzBtiddtKUCAZjTJ6S1CgXhFgvKB1oEbDeHFdzDHQV8L46q4E1QLuCb6SqY1Q1TVXTGjZsWIKQTayY+N1aeLBu7vqlTabS77SekQrHmHx8J0pV/ai49SDmAa1FJNV7QHMRULCnz3rgNAARaQy0BX72G5OJH5u+eyd3+erG79D32NQIRmNMfqG6MD5P4cvlXKp6SzH7MkXkJuAzXPOgsaq6TESGevtHAw8D40RkCe5SfZiq/lby0zAx7ct/8vcd/3DLQ79mbJOjIxuPMQWEakc5vyxvrqrTgGkFto0OWP4FOLMsn2HiwAyXJN+veRHnNT4qwsEYU1ionjn5BuQVkRqq+kd4QzIJZVfebev9J91tT7hNVPJ1j1JEuovIcmCFt36MiNhs8qbsnm4PwMc1zrNuiSZq+X2Y8yyuKc82AFX9AbC+3qZsxg/IXXyj1l8iF4cxIfju662qGyT/ZVFW+YdjEsK81+CTvN42Jx54jhuObR7BgIwpnt9EuUFEegDqNfW5Be8y3JgSyc7KTZJbtQ63ZtzADQNOtctuE9X8JsqhuFGAmgEbcU1+bgxXUCYOqcJrZ0L6XACWcASPHDrK5roxMcFXovTaNl4a5lhMPBvfPzdJ/pzdhEcPHcnk67pHOChj/PH71PtwEflIRLaKyK8i8qGIHB7u4EycyMqENW6Q/Pb7x3Lqwac5+1irRZrY4fep90TgbaApbgCLd4C3whWUiSMH98LDbh66Jdmt2EeKTeNgYo7fRCmq+oaqZno/Eyima6MxAKz9Bh5tmrt64cH7LEmamBSqr3c9b3GGiAzHDb6rwCDgkzDHZmJZ5gEYd1buaur+CXRNbWBJ0sSkUA9zFuASY04DyusC9iluUAtjCvvk7wBkSWWO2DcegP42vayJUaH6ettYV6bkDuyG798AoPW+cQB2yW1imu+eOSJyFG6SsJScbao6PhxBmRi2dRWMOh5wD2+OT21gbSVNzPOVKEXkftwsiR1ww6b1Ab4GLFGaPPNezb3kBlhy1lQm/+mwCAZkTPnw+9R7IG4k8s2qehVwDFA1bFGZ2JOdlZskR2Wew6Cm07nEkqSJE34T5T5vdsRMb/KvXwFrcG7yPN8ld/HJzIvswY2JK37vUc4XkbrAK7gn4XuAueEKysSIjH3w3rWw8lNQN5jUtY0m0S2prt2TNHHFb1/vG7zF0SIyHaitqovDF5aJeqrwjyZ560lVmd7tdT7/bzbdrK2EiTOhGpx3KW6fqi4s/5BMTFjybt7y7T8xcdl+RkxZAlh7SRN/QtUo/1XMPgVOLcdYTKzIyoT3r3XLN86Dmo34cNFswNpLmvgUqsF5r4oKxMSQsX/OW27QOnexW2o9S5ImLvl96m0MZGXAA3VgozeL8fD1IMLEOeuZs2Z7ZGMzJowsURp/VOHhBnnr138LKXUA+HDRRsDuTZr45bsLo0lw0+7IW753GyTl/6djl90mnvkd4VxEZLCI3OettxSRruENzUSVA7vd69+WF0qSxsQ7v5feLwLdgYu99d3AqLBEZKLT4klQswnUsctrk3j8JspuqnojsB9AVX8HksMWlYku7/3Fve7ZXGiXPcgxicBvoswQkSS86R9EpCGQHbaoTHRZ8rZ7vWFOoV32IMckAr+JciQwBWgkIv/ADbH2aNiiMtFj+VT32vrP0Khdvl05tUl7kGPind++3m+KyALcUGsCDFDVFWGNzESeKrx9mVtuf3ah3VabNInC78C9zwGTVdUe4CSSB+u61yo1oMtluZsnzlnPh4s2snzTLqtNmoTgt53HQuAeEWmDuwSfrKrzwxeWibjPH8xbvuOn3MWJc9bnDn7RLbWe1SZNQvB76f068Lo3fe35wBMi0lJVW4c41MSifTvg66fd8uVTIblG7q6cy20b/MIkkpJ2YTwSaAe0An4s92hMdFjsPeVu0xsOPyV3sz28MYnKb8+cJ0TkJ+AhYBlwnKoWvrtvYp8qfOp1VzzrqXy77OGNSVR+71GuAbqr6m/hDMZE2Ht/yWszCVC3BWAPb4wJNcJ5O1X9ETc/TksRyfcXYiOcxwnVvCfcAIceC5dNyU2QOT1v7OGNSVShapS3AUMIPtK5jXAeDzYvgdEn5q3ftAAaHBn06bbVJE2iCjXC+RBvsY+q7g/cJyIpYYvKVIwdG/InyRG/QHKNfEnSnm4b4/+p97c+t+UjIr1FZKWIrBaR4UWU6Skii0RkmYh86TMeU1Z7tsKzR7nlRh3h/h2WJI0pQqh7lE2AZkA1ETkW130RoDZQPcSxSbih2M4A0oF5IjJVVZcHlKmLG8Ktt6quF5FGpT0RU0Ivn+xepRJc/03ulA6WJI0pLNQ9yj8DVwLNgacDtu8GRoQ4tiuwWlV/BhCRSUB/YHlAmUuA91V1PYCq/uo7clN6e7fD7l/c8v2/5262xuTGBBfqHmVOj5zzVfW9Er53M2BDwHo60K1AmTZAFRGZCdQCnlPV8SX8HFMSnw6HOS+55aPOz91sjcmNKVqoS+/BqjoBaCUitxXcr6pPBzks9/Ag2zTI5x+HG5WoGjBbRL5T1VUF4hiCe/pOy5b2R1wmOUmy6xA485HczdaY3Jiihbr0zunkW7MU750OtAhYbw78EqTMb6r6B/CHiMwCjgHyJUpVHQOMAUhLSyuYbI1fGfvca52WcNaThXZbbdKY4EJder/svT5YXLkizANai0gqsBG4CHdPMtCHwAsiUhk3tUQ34JlSfJYJ5cAeeMyrLbY6IXdzYK+bDk1rRyg4Y6Kb377e/xSR2iJSRUS+EJHfRGRwcceoaiZwE/AZsAJ4W1WXichQERnqlVkBTAcW43r/vKqqS8tyQqYIjwVcUvfPG1Y0MEnaZbcxwfnt632mqt4pIufiLpcvAGYAE4o7SFWnAdMKbBtdYP1JoPB1oCk/v63OW75/B0j+28cdmtZm8nXdKzYmY2KI3wbnVbzXs4C3VNWm3YslLxznXs9/rVCSNMaE5jdRfiQiPwJpwBfeLIz7QxxjosGaWXnLAc2BwKaaNcYvX4lSVYcD3YE0Vc0A/sA1HjfRLCsDXveGDR38Xr7aZGAvHLs3aUzx/E4uVgW4DDhZ3B/bl8DoYg8ykbXph7xuigCHu4GeCg6dZr1wjAnN78Ocl3D3KV/01i/ztl0bjqBMOfj6WfdavzXcNK9QX24bOs0Y//wmyuNV9ZiA9f+KyA/hCMiU0R/b4MnD89av/zb3ktv6chtTOn4f5mSJyBE5KyJyOJAVnpBMqanmT5JnPQWVkwHry21MWfitUd4BzBCRn3F9uA8DrgpbVKZ0fp6Zt/zAzny7rC+3MaUXMlF6TYF24oZNa4RLlD+q6oEwx2ZKYsd6eGOAW740/0BPVps0pmyKvfQWkWtx09M+DywCWqnqD5Yko8y2/8GzR+etH3lavt1WmzSmbELdo7wV6Kiq3YEewF1hj8iUzK8r4PkubrlGQ3fJHaT3jdUmjSm9UInyoKpuBfBGKq8a/pBMiaz7xr026gC3/1Rot/W+MabsQt2jbC4iI4taV9VbwhOW8eXlU2DTIrd86btBa5J22W1M2YVKlHcUWF8QrkBMCf2xLS9Jnvsy1CmcCO0hjjHlw8+cOSbafP8mfHiDW27TG465qFAR68ttTPkJ9dR7jIgcVcS+GiJytYhcGp7QTFAH9+YlycNOhIsnFSpi084aU75CXXq/CNwnIkcDS4GtQArQGje391jgzbBGaPL7rzchWLPj4KpPghaxrorGlK9Ql96LgAtFpCZuLMqmwD5ghaquDH94Jp9Ni+E7bxqHi94KWsTuSxpT/nx1YVTVPcDM8IZiirV5Cbx8kltu2QNqNQ5azJ5yG1P+/A6KYSJp/04YfaJbbnUSXP1pscWtNmlM+fI7KIaJpG+8pqutToIrPw5axKadNSZ8SlSjFJEa4QrEFGPZ++510BtFFrFpZ40JH79TQfQAXgVqAi1F5BjgOlW9IZzBGeCV02D7z2652iHFFrVpZ40JD781ymeAPwPbAFT1B+DkYo8wZXdgD2yc75aHfhO0yMQ56xn08myWb9pVgYEZk1h8X3qr6oYCm2yE83DLmRysbV9oErTdv11yG1MB/D7M2eBdfquIJAO3ACvCF5bhm5Gw/X9uedCEoEUC20zaJbcx4eO3RjkUuBFoBqQDnQG7Pxkum5fAf+51y92uh0rBf03WZtKYiuG3RtlWVfP16RaRE4DgN85M6R3Yk9dmsuN50OfxoMWsB44xFcdvjfJ5n9tMWezdDo95tcOUunDBv4MWs5GBjKlYxdYoRSRnCoiGInJbwK7aQFI4A0s4v/4IL3bLWx+2tsiiNuiFMRUr1KV3Mq7tZGWgVsD2XcDAcAWVcPbtyEuSNRrB7auCjlYOdsltTCSEGj3oS+BLERmnqusqKKbE86b3f44kwR2F573JYZfcxkSG34c5e0XkSaAjbjxKAFT11LBElWh2/eJe795cbDG75DYmMvw+zHkT+BFIBR4E1gLzwhRTYlk+FXZthFqHQuXkIovZJbcxkeO3RllfVV8Tkb8GXI5/Gc7AEsbbl7nXXsGnTM8ZFShnylm75Dam4vlNlBne6yYR6Qv8AjQPT0gJ5J2r8pa7XB60SE4XxW6p9ejfuZnVJo2JAL+J8hERqQP8Hdd+sjZwa7iCSggH/wgYPs26KBoTzfxOBZEzWuxOoBfk9swxpfWDN3ti95ug/dlBi1gXRWOiQ6gG50nAhbg+3tNVdamI9ANGANWAY8MfYhzasR4+8drvd7kiaBF7eGNM9AhVo3wNaAHMBUaKyDqgOzBcVT8Ic2zxad8OePZot1ypMjRsU6iItZc0JrqESpRpQCdVzRaRFOA34EhVLb7BnynaE4e51+RaMCI9aBFrL2lMdAnVjvKgqmYDqOp+YFVJkqSI9BaRlSKyWkSGF1PueBHJEpH47haZPj9vuYgkaZfcxkSfUDXKdiKy2FsW4AhvXQBV1U5FHejd3xwFnIEbw3KeiExV1eVByj0BfFbKc4gNqvDvPm65/4tBi9gltzHRKVSibF+G9+4KrFbVnwFEZBLQH1heoNzNwHvA8WX4rOi3bTVkHXTLnS4MWsQuuY2JTqEGxSjLQBjNgMB5dtKBboEFRKQZcC5wKvGeKD+8yb32/RckVSmymF1yGxN9SjSvdwkFGydMC6w/CwxT1WInKhORISIyX0Tmb926tbziqzizX4QN37nlYy4JWiTn3qQxJvr47ZlTGum4pkU5muO6PgZKAyaJG3uxAXCWiGQWbHqkqmOAMQBpaWkFk210U4XPvH7cfZ+G5OpBi1njcmOil+9EKSLVgJaqutLnIfOA1iKSCmwELgLyVadUNTXg/ccBH8dd+8wf3nKvrU6C468ptDtn0Iuc/tx22W1M9PF16S0iZwOLgOneemcRmVrcMaqaCdyEe5q9AnhbVZeJyFARGVqmqGPFwT/gg+vd8ukPFNqd85R7zprtNi+3MVHMb43yAdxT7JkAqrpIRFqFOkhVpwHTCmwbXUTZK33GEht2psMzHd1yk07QPK1QEXvKbUxs8PswJ1NVd4Y1kngze5R7lUowpPDQndaw3JjY4bdGuVRELgGSRKQ1cAvwbfjCinG/rYbvvEbld/wPKhX+/8ge3hgTO/zWKG/GzZdzAJiIG27t1jDFFPteOM69Ht4TqtcrspjVJo2JDX5rlG1V9W7g7nAGExfeCniwf/mHQYsEXnYbY6Kf3xrl0yLyo4g8LCIdwxpRLPt1Baz8xC3furTIYnbZbUxs8ZUoVbUX0BPYCowRkSUick84A4spmQfg1dPhxT+59Q4DoG6LoEXtIY4xscd3F0ZV3ayqI4GhuDaV94UrqJjzSCNI92bv7TQILnw9aDEbHciY2OTrHqWItAcGAQOBbcAk3ERjZn9Aq6n7fg/6hDuHtZs0Jjb5fZjzb+At4ExVLdhfO7FNvcW99ryryCRp3RSNiW1+Z2H8U7gDiUlZmbD8A7ecVrgfN+S/3M6Zm9sYE1tCzcL4tqpeKCJLyD9EWsgRzhPC+9e613pHQM2G+Xbl1CJzhk6zy21jYleoGuVfvdd+4Q4kJi2b4l6HzCi0K/BSu3/nZpYkjYlhoUY43+Qt3qCqwwL3icgTwLDCRyWIze5ympqNIaVOvl2BTYAmX9c9AsEZY8qT3+ZBZwTZ1qc8A4k5n3gP/U8p/H+FNSg3Jr6Eukd5PXADcHjAbIwAtYBvwhlYVNu/CzbMcctHnZ9vlzUoNyb+hLpHORH4FHgMCJyXe7eqJuYEL3u3wz+9gdm7DoFqdXN3WYNyY+JTqESpqrpWRG4suENE6iVcslTNS5IAvR/Pt9salBsTn/zUKPsBC3DNgwJnVlTg8DDFFZ2mBMxgcf8OkMITTdoltzHxJ9RT737ea2px5RLG4knu9W/LgyZJY0x88ju52AkiUsNbHiwiT4tIYlWbAmuTdQrff7R5uY2JX36bB70E7BWRY4A7gXXAG2GLKtpkZ+VNO3vV9KBFrEmQMfGrJJOLKdAfeE5Vn8M1EUoMb1/uXrtdD4cVbkBuTYKMiW9+Rw/aLSJ3AZcBJ4lIElAlfGFFkeUfwo8fu+VuQ4IWsdqkMfHNb41yEG5isatVdTPQDHgybFFFk3eudK+nDId6RT/kt9qkMfHL71QQm4E3gToi0g/Yr6rjwxpZNPhtNWi2W+45PGgRe4hjTPzz+9T7QmAucAFwITBHRAaGM7CokNMc6KynimwOZJfdxsQ/v/co7waOV9VfAUSkIfA58G64AosKe72aYqdBhXbZqOXGJA6/9ygr5SRJz7YSHBu75r/mXlNqF9qVkyQ7NK1ttUlj4pzfGuV0EfkMN28OuIc708ITUpT4+ln3WrVwkrTxJo1JLH7nzLlDRM4DTsT19x6jqlPCGlmkffOcez3vlXybbYQgYxJPqPEoWwNPAUcAS4DbVXVjRQQWUZuXwr7t0Ow4aNs7d3NgkrQRgoxJHKHuM44FPgbOx40g9HzYI4oG87xaZIv8k0/aMGrGJKZQl961VDXn2nOliCwMd0BR4bef3GvvR3M3WTdFYxJXqESZIiLHkjcOZbXAdVWNz8S5q/DdBWsvaUziCpUoNwFPB6xvDlhX4NRwBBVR816D39dC9fq5m6w2aUxiCzVwb6+KCiRqLPHa0F8wLneT1SaNSWzx32i8JFRh/bduOfVkwGqTxhj/Dc4TQ84o5vWPzO2imDPghdUmjUlcligDbf0RgPeOeS23vWS31Hr079zMapPGJDBfiVJEBLgUOFxVH/Lmy2miqnPDGl1F27SI3+p24u/TrL2kMSaP33uULwLdgYu99d3AqFAHiUhvEVkpIqtFpNCAjiJyqYgs9n6+9ebkiYzNSwHYu30TYEnSGJPH76V3N1XtIiLfA6jq7yKSXNwB3nQRo4AzgHRgnohMVdXlAcXWAKd479cHGAN0K/FZlIfRJwDwcOZlliSNMfn4rVFmeIlPIXc8yuwQx3QFVqvqz6p6EJiEm5wsl6p+q6q/e6vfAc19R16eZj6eu7ir5RmWJI0x+fhNlCOBKUAjEfkH8DXwaPGH0AzYELCe7m0ryjXApz7jKV8zHwOgL88VOZK5MSZx+R1m7U0RWQCchuu+OEBVV4Q4LFjG0aAFRXrhEuWJRewfAgwBaNmyfGt7k7/5kUFAujag5qFtrRmQMaYQv0+9WwJ7gY8Ct6nq+mIOSwdaBKw3B34J8t6dgFeBPqq6LdgbqeoY3P1L0tLSgibb0vryh5UMAn5vPZDJg20QXmNMYX4f5nyCqw0KkAKkAiuBjsUcMw9oLSKpwEbgIuCSwAJeAn4fuExVV5Us9PJxwr6ZABx9ZGokPt4YEwP8XnofHbguIl2A60IckykiNwGfAUnAWFVdJiJDvf2jgfuA+sCLrqkmmaqaVuKzKIOBu990C4f3rMiPNcbEkFL1zFHVhSJyvI9y0ygwt46XIHOWrwWuLU0M5SIrg6ocYE3lI0ht1C5iYRhjopvfe5S3BaxWAroAW8MSUUVa+j4Aq5LbYxfexpii+G0eVCvgpyrunmX/Yo+IBeu+BuCL6mdFOBBjTDQLWaP0GprXVNU7KiCeirVwPADrqhwe4UCMMdGs2BqliFRW1SzcpXZ8+WVRpCMwxsSIUDXKubgkuUhEpgLvAH/k7FTV98MYW3hNux2AGw7eYo3MjTHF8vvUux6wDTdHTk57SsW1gYxN6fMA2Nayj/XtNsYUK1SibOQ98V5KXoLMUa49ZCrU2q/zlq1vtzEmhFCJMgmoSQn6bceEdbMBuOzgcLvsNsaEFHK6WlV9qEIiqUgzHgGgUouudtltjAkpVDvK+Lsu3ZI3bvCfu7SOYCDGmFgRKlGeViFRVKSX3AhBY+rcYrVJY4wvxSZKVd1eUYFUiKzM3EXrjWOM8ctvF8b4kO4mjZySdYI9xDHG+JZYiXLyYABWNLC2k8YY/xIrUe51A6j/kFKhQ14aY2Jc4iTKXW4WinWVW0U2DmNMzEmcRLl9DQD/rd47woEYY2JN4iTKtV8BsKlyZKYON8bErsRJlD9/6V4qHxnhQIwxsSZxEuXe3wDYnVQ3snEYY2JO4iTKrIOQXCvSURhjYlDiJMrf10KLrpGOwhgTgxIjUe751b1qVmTjMMbEpMRIlF7TIDqeF9k4jDExKTES5erPAfhqw0HmrImvcT6MMeGXGInSa0P56iY3La0NiGGMKQm/k4vFNm8isf2VqtMttboNiGGMKZHEqFGqsr12e7vsNsaUSoIkyiy27E8C7LLbGFNyiZEogRVVjqJbaj277DbGlFhCJMpsKpG+c3+kwzDGxKj4T5SqVCIbsMtuY0zpxP9T77VfA9C+9kHOsMtuY0wpxH+Ncv8OAOaknBjZOIwxMSv+E+WPnwCwo1K9CAdijIlV8Z8of10OwIbKh0U4EGNMrIr/RLlzI9kIiEQ6EmNMjIr/RFm5KtuSGkY6CmNMDIv/p96VKrMiuV2kozDGxLD4r1EaY0wZxX2i3HMgk617DkQ6DGNMDAtrohSR3iKyUkRWi8jwIPtFREZ6+xeLSJfyjuGPg276B+uVY4wprbAlShFJAkYBfYAOwMUi0qFAsT5Aa+9nCPBSOGJpWLOqDYZhjCm1cNYouwKrVfVnVT0ITAL6FyjTHxivzndAXRFpGsaYjDGmxMKZKJsBGwLW071tJS2DiAwRkfkiMn/r1q0lCiI5qRJ1qlUp0THGGBMonM2DgrXw1lKUQVXHAGMA0tLSCu0vziHXvMchyTVKcogxxuQTzkSZDrQIWG8O/FKKMmXTuOBtUWOMKZlwXnrPA1qLSKqIJAMXAVMLlJkKXO49/f4TsFNVN4UxJmOMKbGw1ShVNVNEbgI+A5KAsaq6TESGevtHA9OAs4DVwF7gqnDFY4wxpRXWLoyqOg2XDAO3jQ5YVuDGcMZgjDFlFfc9c4wxpqwsURpjTAiWKI0xJgRLlMYYE4IlSmOMCcESpTHGhGCJ0hhjQhDXlDF2iMhWYF0JD2sA/BaGcCIhXs4lXs4D7FyiVUnP5TBVDTrBVswlytIQkfmqmhbpOMpDvJxLvJwH2LlEq/I8F7v0NsaYECxRGmNMCImSKMdEOoByFC/nEi/nAXYu0arcziUh7lEaY0xZJEqN0hhjSi2uEmU0TI9bHnycx6Ve/ItF5FsROSYScfoR6lwCyh0vIlkiMrAi4ysJP+ciIj1FZJGILBORLys6Rj98/PuqIyIficgP3nlE7TixIjJWRH4VkaVF7C+fv3lVjYsf3ODA/wMOB5KBH4AOBcqcBXyKm6vnT8CcSMddyvPoARziLfeJxvPwey4B5f6LG7t0YKTjLsPvpS6wHGjprTeKdNylPI8RwBPeckNgO5Ac6diLOJ+TgS7A0iL2l8vffDzVKONletyQ56Gq36rq797qd7i5hqKRn98JwM3Ae8CvFRlcCfk5l0uA91V1PYCqRuP5+DkPBWqJiAA1cYkys2LD9EdVZ+HiK0q5/M3HU6Ist+lxI6ykMV6D+x8zGoU8FxFpBpwLjCa6+fm9tAEOEZGZIrJARC6vsOj883MeLwDtcRP9LQH+qqrZFRNeuSuXv/mwTgVRwcptetwI8x2jiPTCJcoTwxpR6fk5l2eBYaqa5SowUcvPuVQGjgNOA6oBs0XkO1VdFe7gSsDPefwZWAScChwB/EdEvlLVXWGOLRzK5W8+nhJldEyPW3a+YhSRTsCrQB9V3VZBsZWUn3NJAyZ5SbIBcJaIZKrqBxUSoX9+/339pqp/AH+IyCzgGCCaEqWf87gKeFzdTb7VIrIGaAfMrZgQy1X5/M1H+mZsOd7UrQz8DKSSd5O6Y4Eyfcl/Y3dupOMu5Xm0xM1c2SPS8Zb1XAqUH0f0Pszx83tpD3zhla0OLAWOinTspTiPl4AHvOXGwEagQaRjL+acWlH0w5xy+ZuPmxqlxsn0uD7P4z6gPvCiVxPL1CgcyMDnucQEP+eiqitEZDqwGMgGXlXVoM1WIsXn7+RhYJyILMElmGGqGpUjConIW0BPoIGIpAP3A1WgfP/mrWeOMcaEEE9PvY0xJiwsURpjTAiWKI0xJgRLlMYYE4IlSmOMCcESpTHGhGCJMkK8IcUWBfy0KqbsnnL4vHEissb7rIUi0r0U7/GqiHTwlkcU2PdtWWP03ifne1nqDfVVN0T5ziJyVik+p6mIfOwt9xSRnSLyvYisEJH7S/F+5+QMWSYiA3K+J2/9IRE5vaTvGeQzxoUahs7rZ+67Ta137h/7KBd0ODMReUpETvX7ebHKEmXk7FPVzgE/ayvgM+9Q1c7AcODlkh6sqteq6nJvdUSBfT3KHh6Q970chRsV5sYQ5TvjGhSX1G3AKwHrX6nqsbgulYNF5LiSvJmqTlXVx73VAUCHgH33qernpYgxmowDegfZ/jzu31Ncs0QZJUSkpoh84dX2lohIoeHIvFrQrIAa10ne9jNFZLZ37DsiUjPEx80CjvSOvc17r6Uicqu3rYaIfOIN3LpURAZ522eKSJqIPA5U8+J409u3x3udHFjD82pB54tIkog8KSLzvAFUr/PxtczGG+lFRLqKG6T4e++1rYgkAw8Bg7xYBnmxj/U+5/tg36PnfGB6wY3q+mkvAI7waqvfefFOEZFDvFhuEZHl3vZJ3rYrReQFEekBnAM86cV0RE5NUET6iMjbAd9NTxH5yFsu0e9QRO7zznGpiIwRyTeiyGDvO1oqIl298n6/l6C0iOHMVHUdUF9EmpTk/WJOpPtpJuoPkIUboWURMAXXB7e2t68BrstVTs+pPd7r34G7veUkoJZXdhZQw9s+DLgvyOeNw+tHDVwAzMGNdLMEqIEbd3AZcCwuibwScGwd73UmkBYYU0CZnBjPBV73lpNxQ1xVA4YA93jbqwLzgdQgce4JOL93gN7eem2gsrd8OvCet3wl8ELA8Y8Cg73lurgBKWoU+IxUYEHAek/gY2+5PrAW6IjriniKt/0h4Flv+Regas5nFIyDAn3Wc9a93/H6gN/VS8DgUv4O6wVsfwM4O+B39Iq3fDJeH+iivpcC556G63ZZ1L/ZVgTpU42rmZ8f6b+pcP7ETV/vGLRP3WUwACJSBXhURE7G9RNuhhuQYHPAMfOAsV7ZD1R1kYicgrvM+8arVCTjamLBPCki9wBbccOznQZMUVeLQkTeB07C1bSeEpEncH9EX5XgvD4FRopIVdyl2ixV3SciZwKdAu6x1QFaA2sKHF9NRBbh/igXAP8JKP+6iLTGDZNVpYjPPxM4R0Ru99ZTcIOIrAgo09T7DgKdJCLf4777x3GjztRV1ZzpHF7HJW5wCfRNEfkA+KCIOApR1896OnC2iLyLG7DhTqAkv8McvUTkTtzgG/Vw/8l95O17y/u8WSJSW9x93qK+l8D45gPX+j2fAL8Ch5biuJhhiTJ6XIobdv84Vc0QkbW4f8y5vH/4J+P+wN4QkSeB34H/qOrFPj7jDlV9N2dFinjAoKqrvHt0ZwGPicj/qepDfk5CVfeLyEzcmIaD8P5ocYMr3Kyqn4V4i32q2llE6gAf4+5RjsQN1DBDVc8V9+BrZhHHC652s7K4z6DAd4u7R9kv903c5xelL662dg5wr4h0LKZsQZNx57QdmKequ73LZr+/Q0QkBXgRV7vfICIPkP98Cg7goBTxvYhI4xLEXpQU3Hcat+weZfSoA/zqJclewGEFC4jIYV6ZV4DXcHOFfAecICI59xyri0gbn585CxjgHVMDd9n8lYgcCuxV1QnAU97nFJTh1WyDmYQbpeUk3Cg1eK/X5xwjIm28zwxKVXcCtwC3e8fUwQ33Be4yN8du3C2IHJ8BN+fcsxORY4O8/SpcjbVI3uf/Lt59YOAy4EsRqQS0UNUZuNpgXdxti0AFYwo0E/d9/gWXNKHkv8OcpPibdy+z4JPwnHvKJwI7vXPx872UVhvckHJxyxJl9HgTSBOR+bja5Y9ByvQEFnmXiOcDz6nqVlzieEtEFuP+6Nr5+UBVXYi77zUXd8/yVVX9HjgamOtdAt8NPBLk8DHAYvEe5hTwf7ga1+fq5mUBN8jwcmChuCYmLxPiisaL5QfgIuCfuNrtN7j7lzlmAB1yHubgap5VvNiWeusF3/cP4H85iakYV+BuVyzGPV1/yPvsCeKGIPseeEZVdxQ4bhJwh/fQ5IgCn52Fqyn38V4p6e/Q+7xXcPeXP8Ddkgn0u7jmWqNxt1jAx/ci7kHdq8E+U9xwZrOBtiKSLiLXeNur4B4Mzi8q3nhgw6yZhCQi5+Juc9wT6Vhimfc9dlHVeyMdSzjZPUqTkFR1iojUj3QccaAy8K9IBxFuVqM0xpgQ7B6lMcaEYInSGGNCsERpjDEhWKI0xpgQLFEaY0wI/w9okA87jXp0rgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import RocCurveDisplay\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "\n",
    "RocCurveDisplay.from_predictions(y_test, y_test_pred, ax=ax, label='Test ROC')\n",
    "RocCurveDisplay.from_predictions(y_train, y_train_pred, ax=ax, label='Train ROC')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521eabcc",
   "metadata": {},
   "source": [
    "There are **four unique properties satisfied by the ROC curve** which we will discuss going forward:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775b7911",
   "metadata": {},
   "source": [
    "1. Interpretable area under the curve (ROC AUC)\n",
    "2. Invariance under class imbalance\n",
    "3. Existence of a universal baseline\n",
    "4. Convexity "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f985330",
   "metadata": {},
   "source": [
    "#### 1. Interpretable area under the curve (ROC AUC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b710b357",
   "metadata": {},
   "source": [
    "The area under the ROC curve (usually called ROC AUC or just AUC) is the most used metric in machine learning, yet many data scientists don't know its interpretation. We explain it (and prove why it is so) in what follows.\n",
    "\n",
    "* Randomly take a point of the positive ($y=1$) class, and calculate its score $f(x_1)$\n",
    "* Randomly take a point of the negative ($y=0$) class, and calculate its score $f(x_0)$\n",
    "\n",
    "Claim: $$\\boxed{\\mathrm{ROC\\;AUC} = \\mathbb{P}(f(x_1) \\geq f(x_0))},$$\n",
    "\n",
    "that is: **the ROC AUC measures how likely it is that a point of the positive class scores higher than a point of the negative class**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8d35cb",
   "metadata": {},
   "source": [
    "More formally, let $Z_0 = (f(X)|Y=0)$ and $Z_1 = (f(X)|Y=1)$. Then $\\mathrm{ROC\\;AUC} = \\mathbb{P}(Z_1 \\geq Z_0)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e2a876",
   "metadata": {},
   "source": [
    "> Proof: by definition, $$\\mathrm{ROC\\;AUC} = \\int_{\\mathrm{FPR}=0}^{\\mathrm{FPR}=1} \\mathrm{TPR}\\, d\\mathrm{FPR}.$$\n",
    ">It is natural to parameterize FPR and TPR via the threshold $\\lambda$ since $\\mathrm{TPR} = \\mathbb{P}(f(X)\\geq \\lambda | Y=1)$ and $\\mathrm{FPR} = \\mathbb{P}(f(X) \\geq \\lambda | Y=0)$. This motivates us to define the *independent* random variables $$Z_1 = (f(X)|Y=1),\\qquad Z_0 = (f(X)|Y=0),$$ for which $\\mathrm{TPR}(\\lambda) = \\mathbb{P}(Z_1 \\geq \\lambda)$ for instance. This can be written as $$\\mathrm{TPR}(\\lambda) = \\int_\\lambda^\\infty g_1(z) dz,\\qquad \\mathrm{FPR}(\\lambda) = \\int_\\lambda^\\infty g_0(z) dz$$ where $g_0, g_1$ are the PDFs of $Z_0$ and $Z_1$ respectively. Plugging these back into the definition of ROC AUC gives $$\\mathrm{ROC\\,AUC} = \\int_{\\mathrm{FPR}=0}^{\\mathrm{FPR}=1} \\mathrm{TPR}\\, d\\mathrm{FPR} = \\int_{\\lambda=\\infty}^{\\lambda=-\\infty} \\mathrm{TPR}(\\lambda) \\frac{ d \\mathrm{FPR}(\\lambda)}{d\\lambda} d\\lambda = \\int_\\infty^{-\\infty} d\\lambda \\int_\\lambda^\\infty dz\\, g_1(z) (-g_0(\\lambda)),$$\n",
    "where we have used the fundamental theorem of calculus in the last equality. Now one can equivalently write these iterated integrals as\n",
    "$$\\int_{-\\infty}^\\infty \\int_{-\\infty}^\\infty \\mathbf{1}_{z \\geq \\lambda} g_0(\\lambda) g_1(z)\\, dz d\\lambda = \\mathbb{E}[\\mathbf{1}_{Z_1 \\geq Z_0}] = \\mathbb{P}(Z_1 \\geq Z_0),$$\n",
    "where we identify $g_0(\\lambda)g_1(z)$ as the PDF for $(Z_0, Z_1)$ since these are independent variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33711fae",
   "metadata": {},
   "source": [
    "Hence, in our example (where both train & test AUCs are close to 80.3%): there is a probability of 80.3% of a point in the positive class scoring higher than a point in the negative class. This is very good - 4 out of 5 times we will correctly sort them under the score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c742bd46",
   "metadata": {},
   "source": [
    "**Numerically testing this claim**: let us run a series of samplings to check if we obtain a similar fraction to the ROC AUC we calculated above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bed44418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   score  label\n",
      "0  0.059      0\n",
      "1  0.214      0\n",
      "2  0.750      1\n",
      "3  0.636      1\n",
      "4  0.253      0\n",
      "-> Percentage of times score for class 1 was higher than class 0: 74.5%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'score': y_test_pred, 'label': y_test})\n",
    "print(df.head().round(3).to_string())\n",
    "\n",
    "n_samples = 10000\n",
    "\n",
    "# randomly sample scores from class 1 and 0\n",
    "class_1_score_samples = df[df['label']==1]['score'].sample(n_samples, replace=True, random_state=0)\n",
    "class_0_score_samples = df[df['label']==0]['score'].sample(n_samples, replace=True, random_state=1)\n",
    "\n",
    "# check how many times class 1 score higher\n",
    "total = (class_1_score_samples.values >= class_0_score_samples.values).sum()\n",
    "\n",
    "print(\"-> Percentage of times score for class 1 was higher than class 0: {0:.1f}%\".format(100* total/n_samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65c0f73",
   "metadata": {},
   "source": [
    "As we can see, this works - the percentage of times was very close to the 75.6% ROC AUC we got!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712e9c5c",
   "metadata": {},
   "source": [
    "**Properties**:\n",
    "* This characterization of the ROC AUC allows one to extract interesting insights on how the AUC will behave under some transformations. For example: given the ROC AUC of a classifier $f(x)$, how will it change if we change the classifier to $10 f(x)$?Or $f(x)^2$?\n",
    "> Answer: it will stay the same. Since $\\mathrm{ROC\\,AUC} = \\mathbb{P}(Z_1 \\geq Z_0)$, any function $\\phi$ applied to both sides of the inequality which does not change it will keep ROC AUC constant: $$(Z_1 \\geq Z_0)\\,=\\,(\\phi(Z_1) \\geq \\phi(Z_0)).$$ In particular this is true for functions like $\\phi(Z) = 10Z$ or $\\phi(Z) = Z^2$, which are monotonic functions. We can also see this numerically:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "140131e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original test ROC AUC: 0.7458\n",
      "Applying 10x: 0.7458\n",
      "Applying square: 0.7458\n"
     ]
    }
   ],
   "source": [
    "print(\"Original test ROC AUC: {0:.4f}\".format(roc_auc_score(y_test, y_test_pred)))\n",
    "print(\"Applying 10x: {0:.4f}\".format(roc_auc_score(10*y_test, 10*y_test_pred)))\n",
    "print(\"Applying square: {0:.4f}\".format(roc_auc_score(y_test**2, y_test_pred**2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da98b1ff",
   "metadata": {},
   "source": [
    "* This also explains why **ROC AUC is the best metric when one is interested in sorting values based on the score**. This is particularly the case in credit scoring, where one usually takes a list of potential individuals, scores them using a classification model, and sorts them (from good scores to bad scores) in order to shortlist those which are creditworthy. Notice that a person's absolute score does not matter - what matters is how high it scores on the list *compared to others*. In this sense, **a good model will have high AUC**, because it **ranks** points well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc1d052",
   "metadata": {},
   "source": [
    "* **ROC AUC is blind to intra-class score performance**. Suppose we have the following model (based on a real-life buggy model I once built):\n",
    "  * For members of the positive class, it mostly predicts a random score between 70%-100%\n",
    "  * For members of the negative class, it mostly predicts a score of 0%\n",
    "  \n",
    "  This model will have very high AUC, because there is a high chance that a point in the positive class scores higher than one in the negative class. However, this model does a **terrible** job regarding **scoring** within each class, since it is essentially random (for the positive class) and all identical to zero (for the negative class)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dfe7f76",
   "metadata": {},
   "source": [
    "#### 2. Invariance under class imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6acc56aa",
   "metadata": {},
   "source": [
    "As we discussed in Chapter 1, class imbalance is one of the biggest sources of complexity in classification problems. We claim that the ROC AUC is \"invariant under\" class imbalance. What does it mean?\n",
    "\n",
    "First, let us clarify one thing. Physicists reading this probably feel like invariance under something is a positive thing, but this is not necessarily true in machine learning.\n",
    "\n",
    "Invariance under class imbalance means that the ROC AUC (and the ROC curve more generally) do not change if we change the relative proportion of the positive and negative classes. To see this, notice how\n",
    "$$\\mathrm{TPR} = \\mathbb{P}(\\hat y(x)=1|y=1) \\approx \\frac{\\mbox{true positives}}{\\mbox{all positives}}$$\n",
    "$$\\mathrm{FPR} = \\mathbb{P}(\\hat y(x)=1|y=0) \\approx \\frac{\\mbox{false positives}}{\\mbox{all negatives}};$$\n",
    "the ratio $\\mbox{all positives/all negatives}$ never appears. FPR and TPR only care about **intra-class ratios, but not inter-class**.\n",
    "\n",
    "* The good thing about this is that AUC analysis works the same for balanced or imbalanced problems...\n",
    "* The bad part is that if you blindly run AUC analysis *alone*, you are shortsighting yourself to class imbalance issues. You might think that a model is very good, when it actually is not!\n",
    "> As a spoiler: metrics such as precision do depend on class imbalance, as we will see further down."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb957a9",
   "metadata": {},
   "source": [
    "#### 3. Existence of a universal baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6150fa72",
   "metadata": {},
   "source": [
    "It is common knowledge that the **diagonal** line in the ROC plane is the baseline corresponding to a random classifier. More formally, consider that $\\hat y$ is a biased coin toss (Bernoulli trial) with parameter $p$, which does not depend on $x$. Then the probability of $\\hat y$ independs on whether $y=1$ or $0$, and we have\n",
    "\n",
    "$$\\mathrm{TPR} = \\mathbb{P}(\\hat y(x)=1 | y=1) = \\mathbb{P}(\\hat y = 1) = p$$\n",
    "$$\\mathrm{FPR} = \\mathbb{P}(\\hat y(x)=1 | y=0) = \\mathbb{P}(\\hat y = 1) = p$$\n",
    "\n",
    "Thus this random classifier corresponds to the point $(p,p)$ in the plane. If we consider all possible $p$'s between 0 and 1, we get the 45 degree diagonal line."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cecf98e",
   "metadata": {},
   "source": [
    "> In practice, this will happen in the case of infinitely large sample size. Below we show the test ROC for the Logistic Regression model; a random classifier; and the theoretical random classifier. Notice how the \"real\" random classifier is noisy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ed24d86d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "\n",
    "# completely random classifier, generating random scores between [0,1]\n",
    "np.random.seed(123)\n",
    "y_pred_random = np.random.rand(*y_test_pred.shape)\n",
    "\n",
    "# theoretical random classifier\n",
    "p = np.linspace(0,1)\n",
    "\n",
    "RocCurveDisplay.from_predictions(y_test, y_test_pred, ax=ax, label='Logistic regression')\n",
    "RocCurveDisplay.from_predictions(y_test, y_pred_random, ax=ax, label='Random classifier')\n",
    "plt.plot(p,p,linestyle='--', label='Theoretical random clf.')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44de385b",
   "metadata": {},
   "source": [
    "Because of this baseline, ROC AUC is theoretically bounded between 0.5 (area of the triangle below the 45 degree line) and 1. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f312e56",
   "metadata": {},
   "source": [
    "#### 4. Convexity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c004df6f",
   "metadata": {},
   "source": [
    "Convexity is a geometrical property of sets which will allow us to construct new (and better) classifiers based on old ones.\n",
    "\n",
    "Suppose we have two estimators A and B, represented in the FPR/TPR plane as below (A in red, B in blue). Recall that an estimator is a function that outputs either 0 or 1.\n",
    "\n",
    "**Convexity** allows us to build a whole family of estimators in the line segment between A and B (represented in a dotted line)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e8ac8d08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVgAAAFBCAYAAAAytbcTAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAghElEQVR4nO3df5BV5Z3n8feH5kdDA4II6gAtGBECiT+v5IfoqlEU0RAMEYwzjE6muoiaH7tVU3ErtdmqmcrspmpnK5NaHERl3BiTVhQUNYLGGGR1VBpFbUQMokALyk/52UDT/d0/+mquTdPchn769u3+vKqo7nPO89z+Hi58eHjOec5VRGBmZm2vW6ELMDPrrBywZmaJOGDNzBJxwJqZJeKANTNLxAFrZpZI0oCVdI2kNZLWSrqzmeP/IGll9le1pHpJJ+fT18yso1Oq+2AllQDvAlcBNcBy4KaIePso7a8H/nNEXNHavmZmHVHKEex4YG1ErIuIQ0AlMKWF9jcBvzvOvmZmHU7KgB0KbMzZrsnuO4KkPsA1wKOt7Wtm1lF1T/jaambf0eYjrgdejIgdre0rqQKoACgrK7twzJgxra3TzKxFK1as2BYRg1vbL2XA1gDDc7aHAZuO0nYGf5keaFXfiJgLzAXIZDJRVVV1vPWamTVL0vrj6ZdyimA5MErSSEk9aQzRRU0bSToJ+E/A463ta2bWkSUbwUbEYUl3AEuAEmBeRKySNCt7fE626VTgmYjYd6y+qWo1M0sh2W1aheApAjNLQdKKiMi0tp9XcpmZJeKANTNLxAFrZpaIA9bMLBEHrJlZIg5YM7NEHLBmZok4YM3MEnHAmpkl4oA1M0vEAWtmlogD1swsEQesmVkiDlgzs0QcsGZmiThgzcwSccCamSXigDUzS8QBa2aWiAPWzCwRB6yZWSIOWDOzRBywZmaJOGDNzBJxwJqZJZI0YCVdI2mNpLWS7jxKm8skrZS0StLSnP0fSHore6wqZZ1mZil0T/XCkkqA2cBVQA2wXNKiiHg7p80A4C7gmojYIGlIk5e5PCK2parRzCyllCPY8cDaiFgXEYeASmBKkzbfBRZExAaAiNiSsB4zs3aVMmCHAhtztmuy+3KdDQyU9CdJKyTNzDkWwDPZ/RUJ6zQzSyLZFAGgZvZFMz//QuAbQG/gPyS9HBHvAhdHxKbstMGzkt6JiBeO+CGN4VsBUF5e3qYnYGZ2IlKOYGuA4Tnbw4BNzbRZHBH7snOtLwDnAkTEpuzXLcBCGqccjhARcyMiExGZwYMHt/EpmJkdv5QBuxwYJWmkpJ7ADGBRkzaPA5dI6i6pD/AVYLWkMkn9ACSVAROB6oS1mpm1uWRTBBFxWNIdwBKgBJgXEaskzcoenxMRqyUtBt4EGoB7I6Ja0pnAQkmf1vjbiFicqlYzsxQU0XRatHhlMpmoqvIts2bWtiStiIhMa/t5JZeZWSIOWDOzRBywZmaJOGDNzBJxwJqZJeKANTNLxAFrZpaIA9bMLBEHrJlZIg5YM7NEHLBmZok4YM3MEnHAmpkl4oA1M0vEAWtmlogD1swsEQesmVkiDlgzs0QcsGZmiThgzcwSccCamSXigDUzS8QBa2aWiAPWzCwRB6yZWSJJA1bSNZLWSFor6c6jtLlM0kpJqyQtbU1fM7OOLFnASioBZgOTgLHATZLGNmkzALgL+GZEjAO+k29fMyu8Bx+EESOgW7fGrw8+WOiKOpaUI9jxwNqIWBcRh4BKYEqTNt8FFkTEBoCI2NKKvmZWQA8+CBUVsH49RDR+rahwyOZKGbBDgY052zXZfbnOBgZK+pOkFZJmtqKvmRXQT38K3brtZcyY1Z/t27+/cb81ShmwamZfNNnuDlwITAauBv6bpLPz7Nv4Q6QKSVWSqrZu3Xoi9ZpZK2zYACUl9Vx55XOUlh743H5rlDJga4DhOdvDgE3NtFkcEfsiYhvwAnBunn0BiIi5EZGJiMzgwYPbrHgzO7p169ZRXh7s2nUS//Zv3+fAgdLPjpWXF7CwDiZlwC4HRkkaKaknMANY1KTN48AlkrpL6gN8BVidZ18za2cNDQ0sWbKEBx54gJ/85HX69IH6+pLPjvfpAz//eQEL7GC6p3rhiDgs6Q5gCVACzIuIVZJmZY/PiYjVkhYDbwINwL0RUQ3QXN9UtZrZsdXW1vLII4+wbt06LrroIq6++lz692+cc92woXHk+vOfw803F7rSjkMRzU5tFqVMJhNVVVWFLsOs09myZQuVlZXs2rWLyZMnc8EFFxS6pHYlaUVEZFrbL9kI1sw6jwMHDtDQ0MAtt9zC8OHDj93BAC+VNbOjiAjef/99AMrLy7njjjscrq3kgDWzIxw6dIj58+fz61//mpqaGgC6d/d/eFvLv2Nm9jk7d+6ksrKSrVu3MnHiRIYO9Rqf4+WANbPPvP/++8yfP5+I4Oabb+YLX/hCoUsqag5YM/vMzp076du3LzNmzODkk08udDlFzwFr1sUdPnyYjz76iGHDhnHBBRdwzjnneL61jfgil1kXtmfPHu6//35+/etfs2/fPsAXs9qSfyfNuqiamhoeeughDh48yNSpUykrKyt0SZ2OA9asC1q5ciVPPvkk/fr146//+q859dRTC11Sp+SANeuCNm/eTHl5OdOmTaNPnz6FLqfTcsCadRH79+9n3759DB48mIkTJyKJbt18GSYl/+6adQEff/wx99xzD5WVlTQ0NFBSUuJwbQcewZp1cqtXr2bhwoX06tWL6dOnO1jbkQPWrJOKCJYuXcrSpUsZOnQo06dPp1+/foUuq0txwJp1UhHBhg0bOO+885g8ebLvby0A/46bdTI7duygZ8+e9O3bl5tuuonu3bsjNfc5opaaJ2PMOpH33nuPe+65hyeffBKAHj16OFwLyCNYs04gInj55Zd59tlnGTx4MFdffXWhSzIcsGZFr66ujqeeeoo33niDMWPGMHXqVHr27FnosgwHrFnRO3z4MBs3buSyyy7j0ksv9ZRAB+KANStSmzdvZsiQIfTu3ZtZs2bRo0ePQpdkTfgil1kRev3117nvvvtYunQpgMO1g/II1qyI1NfXs2TJEpYvX86ZZ57J1772tUKXZC1wwJoVif379zN//nw++OADvvrVr3LVVVd52WsHl/TdkXSNpDWS1kq6s5njl0naJWll9tfPco59IOmt7P6qlHWaFYO9e/eyZcsWvvWtb3H11Vc7XItAshGspBJgNnAVUAMsl7QoIt5u0nRZRFx3lJe5PCK2parRrBhs2rSJ008/nSFDhvCjH/3It2AVkZT/BI4H1kbEuog4BFQCUxL+PLNOJSL44x//yD333MOqVasAHK5FJmXADgU25mzXZPc19TVJb0h6WtK4nP0BPCNphaSKhHWadTgHDx6ksrKSZcuWcf755zNmzJhCl2THIeVFrubudo4m268BZ0TEXknXAo8Bo7LHLo6ITZKGAM9KeiciXjjihzSGbwVAeXl5mxVvVijbt2+nsrKS7du3M2nSJC666CIvHihSKUewNcDwnO1hwKbcBhGxOyL2Zr//PdBD0inZ7U3Zr1uAhTROORwhIuZGRCYiMoMHD277szBrZ9u2bWP//v3MnDmT8ePHO1yLWMqAXQ6MkjRSUk9gBrAot4Gk05T90yNpfLae7ZLKJPXL7i8DJgLVCWs1K6iIYPPmzQCMHj2aH/7wh4wYMaKwRdkJSzZFEBGHJd0BLAFKgHkRsUrSrOzxOcA04PuSDgO1wIyICEmnAguz2dsd+G1ELE5Vq1kh1dXV8cQTT1BdXU1FRQWnnXYavXr1KnRZ1gYU0XRatHhlMpmoqvIts1Y8du/eTWVlJZs3b+byyy/nkksu8ZRAByRpRURkWtvPK7nMCmTDhg08/PDD1NXVMWPGDEaPHl3okqyNOWDNCmT9+vX06tWLv/3bv8UXaDsnB6xZO6qvr2fHjh0MHjyYCRMmMH78eM+3dmJezGzWTvbt28cDDzzAv//7v1NbW4skh2sn5xGsWTv46KOPqKysZN++fVx//fX07t270CVZO3DAmiVWXV3N448/Tp8+fbj11lv5q7/6q0KXZO3EAWuW2Jo1azj99NO58cYb6du3b6HLsXbkgDVL4MCBAxw4cIABAwbwzW9+k27dulFSUlLosqyd+SKXWRvbtm0b9957Lw899BARQY8ePRyuXZRHsGZt6M9//jOPPvooJSUlXHfddV6V1cU5YM3aQETw4osv8txzz3Haaacxffp0BgwYUOiyrMAcsGZtoL6+nrfffptx48YxZcoUf4y2AQ5YsxOya9cuSktL6dWrFzNnzqRXr16eFrDP+CKX2XFav349c+fO5amnngKgtLTU4Wqf4xGs2XGoqqri6aefZuDAgVx66aWFLsc6KAesWSvU19fz9NNPs2LFCkaNGsUNN9xAaWlpocuyDsoBa9YK+/fv55133uHiiy/miiuuoFs3z7LZ0TlgzfKwbds2Bg0aRL9+/bj99tv9sBbLi//5NTuGt956i7vvvpsXX3wRwOFqefMI1uwoGhoaeO6553jppZcoLy/nvPPOK3RJVmQcsGbNOHDgAI8++ihr167lwgsvZNKkSX6egLVaq6cIJJVIujlFMWYdxbZt21i/fj2TJ0/muuuuc7jacTlqwErqL+m/Svo/kiaq0Q+AdcCN7VeiWfvZvn07AMOGDePHP/4xmUyrP6nZ7DMtjWAfAEYDbwF/DzwDTAOmRMSUdqjNrN1EBMuWLWP27Nm8++67APTp06fAVVmxa2kO9syI+DKApHuBbUB5ROxpl8rM2smhQ4dYtGgRq1at4ktf+hIjR44sdEnWSbQ0gq379JuIqAfeb224SrpG0hpJayXd2czxyyTtkrQy++tn+fY1awuffPIJ8+bNY9WqVVx55ZXccMMNfhKWtZmWRrDnStoNfPr0it452xER/Vt6YUklwGzgKqAGWC5pUUS83aTpsoi47jj7mp2Q9evX88knn3DzzTdz1llnFboc62SOGrARcaKXTccDayNiHYCkSmAKkE9InkhfsxZFBDt27GDQoEGce+65nHXWWZSVlRW6LOuEWrqLoFTSj7N3EVRIau09s0OBjTnbNdl9TX1N0huSnpY0rpV9zVrl8OHDPPHEE8yZM4dt27YBOFwtmZZC8//SOA+7DLgWGAf8qBWv3dyDMaPJ9mvAGRGxV9K1wGPAqDz7Nv4QqQKoACgvL29FedbV7N27l4cffpiNGzcyYcIETj755EKXZJ1cSwE7NucugvuAV1v52jXA8JztYcCm3AYRsTvn+99LukvSKfn0zek3F5gLkMlkmg1hs02bNlFZWUltbS3Tpk1j3Lhxx+5kdoJaCtjcuwgOH8eT2pcDoySNBD4EZgDfzW0g6TTg44gISeNpnLLYDnxyrL5mrVFdXU23bt343ve+x2mnnVbocqyLaClgz8veNQCN/2Vv1V0E2VC+A1gClADzImKVpFnZ43NoXLjwfUmHgVpgRkQE0Gzf4z9N64oaGhrYvXs3AwYM4Morr2TChAlePGDtSo151swB6fWIOL+d6zkhmUwmqqqqCl2GdQC1tbU8+uijbN26ldtuu41evXoVuiQrYpJWRESr1023NIL1fKYVpa1bt1JZWcknn3zC5MmTHa5WMC0F7BBJ/+VoByPifyeox+yErFmzhgULFtCjRw9uueUWhg8ffuxOZom0FLAlQF+av2XKrMOJCJYvX84pp5zC9OnT6d+/xcsEZsm1FLCbI+If260Ss+N06NAh6urqKCsrY9q0aZSUlPh5AtYhtPSwF49crcPbuXMn8+bN4+GHHyYiKC0tdbhah9HSCPYb7VaF2XF4//33mT9/PhHBtGnTOI57tc2SaulhLzvasxCzfEUEr776KkuWLGHQoEHMmDGDQYMGFbossyP4Qw+t6NTV1fHqq69y9tlnM3XqVN+GZR2WA9aKxt69eyktLaVnz57ceuutlJWVeVrAOrRWf6qsWSF8+OGHzJ07lyVLlgDQt29fh6t1eB7BWof3xhtv8MQTT9CvXz9/yqsVFQesdVgNDQ08++yzvPzyy4wYMYLvfOc7fliLFRUHrHVYu3bt4rXXXmP8+PFMnDiRkpIT/RQjs/blgLUOZ9euXfTv35+BAwdy++23e8mrFS1f5LIOZfXq1cyePZtPHzvpcLVi5hGsdQgRwdKlS1m6dClDhw5l9OjRhS7J7IQ5YK3gDh06xGOPPcbq1as555xzuP766+ne3X80rfj5T7EVXE1NDWvWrOHqq6/mK1/5iu9vtU7DAWsFs3v3bvr378+ZZ57JD3/4Q0466aRCl2TWpnyRy9pdRPDyyy/zq1/9ig8++ADA4Wqdkkew1q4OHz7Mk08+yRtvvMGYMWM4/fTTC12SWTIOWGs3e/bs4aGHHuLDDz/k0ksv5bLLLvN8q3VqDlhrN2+//TZbtmzhxhtv5Itf/GKhyzFLzgFrye3Zs4d+/foxfvx4Ro8ezYABAwpdklm78EUuS6ahoYHFixdz11138cknnyDJ4WpdStKAlXSNpDWS1kq6s4V2F0mqlzQtZ98Hkt6StFJSVco6re3t37+f3/zmN7zyyiuce+65XvJqXVKyKQJJJcBs4CqgBlguaVFEvN1Mu18AS5p5mcsjYluqGi2Njz/+mMrKSvbs2cOUKVM477zzCl2SWUGkHMGOB9ZGxLqIOARUAlOaafcD4FFgS8JarB298sor1NfXc8sttzhcrUtLeZFrKLAxZ7sG+EpuA0lDganAFcBFTfoH8IykAO6OiLkJa7UTFBHs37+fsrIyJk2axIEDB+jXr1+hyzIrqJQB29wNjtFk+5fATyKivpn7IS+OiE2ShgDPSnonIl444odIFUAFQHl5+YlXba128OBBFi5cyPbt26moqKBHjx706NGj0GWZFVzKKYIaYHjO9jBgU5M2GaBS0gfANOAuSd8CiIhN2a9bgIU0TjkcISLmRkQmIjKDBw9u0xOwY9uxYwf33Xcf7777LplMxk/BMsuR8m/DcmCUpJHAh8AM4Lu5DSJi5KffS7ofeDIiHpNUBnSLiD3Z7ycC/5iwVjsO7733Ho888giS+Ju/+RtGjhx57E5mXUiygI2Iw5LuoPHugBJgXkSskjQre3xOC91PBRZmpw26A7+NiMWparXWiwief/55+vfvz4wZMxg4cGChSzLrcBTRdFq0eGUymfj0o0Ysjbq6OhoaGujVqxd79+6lZ8+e9OzZs9BlmSUlaUVEtPoz472Sy/K2e/du7r//fhYsWEBE0LdvX4erWQt8RcLysnHjRh566CHq6uq45JJL/BQsszw4YO2YXnvtNZ566ilOOukkZs6cyZAhQwpdkllRcMBaiw4cOMDzzz/PyJEj+fa3v03v3r0LXZJZ0XDAWrNqa2vp1asXpaWl3HrrrQwYMIBu3Txlb9Ya/htjR/joo4+4++67+dOf/gTAySef7HA1Ow4ewdrnrFq1iscff5zS0lLGjBlT6HLMipoD1oC/LBxYtmwZw4YN48Ybb/TDWsxOkAPWANi6dSsvvfQS559/Ptdee62fKWDWBvy3qIurra2ld+/eDBkyhFmzZjFo0CDf42rWRnzlogtbu3Ytv/rVr6iurgbglFNOcbiatSGPYLugiOCll17iD3/4A6eeeirDhg0rdElmnZIDtoupq6tj0aJFVFdXM3bsWKZMmeLnCZgl4oDtYt577z2qq6u54oormDBhgqcEzBJywHYRn17MGjNmDLfddhv+9Aez9HyRqwtYsWIF//qv/8rmzZsBHK5m7cQj2E6svr6exYsXU1VVxVlnneVPHTBrZw7YTmrfvn3Mnz+f9evX8/Wvf51vfOMbfp6AWTtzwHZSVVVVfPjhh9xwww18+ctfLnQ5Zl2SA7aTOXDgAKWlpVxyySWMHTvW861mBeT/M3YSDQ0N/OEPf+Cuu+5i7969dOvWzeFqVmAewXYCBw4cYMGCBfz5z3/mggsu8KcOmHUQDtgit23bNiorK9m5cyeTJ08mk2n1JwubWSIO2CL3/PPPU1tby8yZMznjjDMKXY6Z5XDAFqGI4NChQ/Tq1YvrrruOgwcPMmDAgEKXZWZNJL3IJekaSWskrZV0ZwvtLpJUL2laa/t2NXV1dSxYsIDf/OY31NfX07t3b4erWQeVLGAllQCzgUnAWOAmSWOP0u4XwJLW9u0SHnwQRoyAbt3YNW4c8/7lX6iurmb06NFeOGDWwaX8GzoeWBsR6yLiEFAJTGmm3Q+AR4Etx9G3c3vwQaiogPXrWV9eztzJk9m5ezffPf10PwnLrAikDNihwMac7Zrsvs9IGgpMBea0tm+X8NOfwv79NEg8NXkyvWtr+fu5cxn1z/9c6MrMLA8pL3I1N7yKJtu/BH4SEfVNRmP59G1sKFUAFQDl5eWtr7Ij27ABgG4RzPjd7+izfz+lBw/Cjh0FLszM8pEyYGuA4Tnbw4BNTdpkgMpsuJ4CXCvpcJ59AYiIucBcgEwm02wIF63ycli/HoCTd+78/H4z6/BSThEsB0ZJGimpJzADWJTbICJGRsSIiBgBPALcFhGP5dO3S/j5z6FPn8/v69Oncb+ZdXjJAjYiDgN30Hh3wGrg4YhYJWmWpFnH0zdVrR3WzTfD3LlwxhkgNX6dO7dxv5l1eIroPP+rzmQyUVVVVegyzKyTkbQiIlq9Dt03UpqZJeKANTNLxAFrZpaIA9bMLBEHrJlZIg5YM7NEHLBmZok4YM3MEnHAmpkl4oA1M0vEAWtmlogD1swsEQesmVkiDlgzs0QcsGZmiThgzcwSccCamSXigDUzS8QBa2aWiAPWzCwRB6yZWSIOWDOzRBywZmaJOGDNzBJxwJqZJZI0YCVdI2mNpLWS7mzm+BRJb0paKalK0oScYx9IeuvTYynrNDNLoXuqF5ZUAswGrgJqgOWSFkXE2znNngMWRURIOgd4GBiTc/zyiNiWqkYzs5RSjmDHA2sjYl1EHAIqgSm5DSJib0REdrMMCMzMOomUATsU2JizXZPd9zmSpkp6B3gK+LucQwE8I2mFpIqEdZqZJZEyYNXMviNGqBGxMCLGAN8C/inn0MURcQEwCbhd0qXN/hCpIjt/W7V169Y2KNvMrG2kDNgaYHjO9jBg09EaR8QLwBcknZLd3pT9ugVYSOOUQ3P95kZEJiIygwcPbqvazcxOWMqAXQ6MkjRSUk9gBrAot4GksyQp+/0FQE9gu6QySf2y+8uAiUB1wlrNzNpcsrsIIuKwpDuAJUAJMC8iVkmalT0+B/g2MFNSHVALTM/eUXAqsDCbvd2B30bE4lS1mpmloL9cxC9+mUwmqqp8y6yZtS1JKyIi09p+XsllZpaIA9bMLBEHrJlZIg5YM7NEHLBmZok4YM3MEnHAmpkl4oA1M0vEAWtmlogD1swsEQesmVkiDlgzs0QcsGZmiThgzcwSccCamSXigDUzS8QBa2aWiAPWzCwRB6yZWSIOWDOzRBywZmaJOGDNzBJxwJqZJeKANTNLxAFrZpZI0oCVdI2kNZLWSrqzmeNTJL0paaWkKkkT8u1rZtbRJQtYSSXAbGASMBa4SdLYJs2eA86NiPOAvwPubUVfM7MOLeUIdjywNiLWRcQhoBKYktsgIvZGRGQ3y4DIt6+ZWUeXMmCHAhtztmuy+z5H0lRJ7wBP0TiKzbuvmVlH1j3ha6uZfXHEjoiFwEJJlwL/BFyZb18ASRVARXbzoKTq4yu3wzsF2FboIhLy+RW3zn5+o4+nU8qArQGG52wPAzYdrXFEvCDpC5JOaU3fiJgLzAWQVBURmRMtvCPqzOcGPr9i1xXO73j6pZwiWA6MkjRSUk9gBrAot4GksyQp+/0FQE9gez59zcw6umQj2Ig4LOkOYAlQAsyLiFWSZmWPzwG+DcyUVAfUAtOzF72a7ZuqVjOzFFJOERARvwd+32TfnJzvfwH8It++eZjb2hqLSGc+N/D5FTufXzP0l7ukzMysLXmprJlZIkUXsHksv705u/z2TUkvSTq3EHUerxNZXlwM8l0CLekiSfWSprVnfScqj/fvMkm7su/fSkk/K0SdxyOf9y57fislrZK0tL1rPBF5vHf/kPO+VWf/fJ7c4otGRNH8ovGC13vAmTTecfAGMLZJm68DA7PfTwJeKXTdbXx+ffnL1M45wDuFrrstzy+n3R9pnIOfVui62/j9uwx4stC1Jjq3AcDbQHl2e0ih627L82vS/nrgj8d63WIbweaz/PaliNiZ3XyZxntoi8WJLC8uBvkugf4B8CiwpT2LawOdeYl3Puf2XWBBRGwAiIhiev9a+97dBPzuWC9abAHb2iW03wOeTlpR2zqR5cXF4JjnJ2koMBWYQ/HJ98/n1yS9IelpSePap7QTls+5nQ0MlPQnSSskzWy36k5c3tkiqQ9wDY2DgBYlvU0rgdYsob2cxoAtpjnKE1leXAzyOb9fAj+JiPrsGpRiks/5vQacERF7JV0LPAaMSl1YG8jn3LoDFwLfAHoD/yHp5Yh4N3VxbSDvbKFxeuDFiNhxrBcttoDNawmtpHNofPThpIjY3k61tYXjXl4cEcWwDjyf88sAldlwPQW4VtLhiHisXSo8Mcc8v4jYnfP97yXdVSTvXz7vXQ2wLSL2AfskvQCcCxRDwLbm794M8pgeAIruIld3YB0wkr9MRI9r0qYcWAt8vdD1Jjq/s/jLRa4LgA8/3e7ov/I5vybt76e4LnLl8/6dlvP+jQc2FMP7l+e5fZHGZzx3B/oA1cCXCl17W51ftt1JwA6gLJ/XLaoRbOS3/PZnwCDgruwo6HAUyUMo8jy/oy0v7vDyPL+ilef5TQO+L+kwje/fjGJ4//I5t4hYLWkx8CbQANwbEUXxdLtW/NmcCjwTjaP0Y/JKLjOzRIrtLgIzs6LhgDUzS8QBa2aWiAPWzCwRB6yZWSIOWOuUsk86Wpnza0TOk6xel7Ra0n/Pts3d/46k/1Xo+q1zKKr7YM1aoTYizsvdIWkEsCwirpNUBqyU9GT28Kf7ewOvS1oYES+2b8nW2XgEa11S9kbxFcAXmuyvBVbS8kOEzPLigLXOqnfO9MDCpgclDQK+Cqxqsn8gjQ9feaF9yrTOzFME1lkdMUWQdYmk12lcyvk/s8shL8vufxMYnd3/UbtVap2WA9a6mmURcd3R9ks6G/h/2TnYle1cm3UyniIwyxGNzy79H8BPCl2LFT8HrNmR5gCXShpZ6EKsuPlpWmZmiXgEa2aWiAPWzCwRB6yZWSIOWDOzRBywZmaJOGDNzBJxwJqZJeKANTNL5P8DAYutfkdHt5gAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# THIS CODE CAN BE IGNORED\n",
    "plt.subplots(figsize=(5,5))\n",
    "\n",
    "# Classifier A\n",
    "plt.scatter(x=[0.3], y=[0.4], color='red')\n",
    "\n",
    "# Classifier B\n",
    "plt.scatter(x=[0.6], y=[0.6], color='blue')\n",
    "\n",
    "# All classifiers in-between\n",
    "xx = np.linspace(0.3, 0.6)\n",
    "yy = 2*xx/3 + 0.2\n",
    "plt.plot(xx,yy, linestyle='--', color='gray')\n",
    "\n",
    "# plot settings\n",
    "plt.xlim(0.2, 0.7)\n",
    "plt.ylim(0.3, 0.7)\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ccef09",
   "metadata": {},
   "source": [
    "The procedure on how to do it (which is not as important as knowing we can do it!) follows below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5aa64fb",
   "metadata": {},
   "source": [
    "[**Theorem**] Let $c_A, c_B$ be the two binary classifiers (i.e. taking values in $\\{0,1\\}$). Let $(\\mathrm{FPR_A, TPR_A})$ and $(\\mathrm{FPR_B, TPR_B})$ denote the coordinates of the two classifiers. Consider a point $(\\mathrm{FPR_*, TPR_*})$ in the segment between A and B. Let \n",
    "\n",
    "$$p = \\mathrm{\\frac{FPR_*-FPR_A}{FPR_B-FPR_A}}.$$\n",
    "\n",
    "Then the classifier $c_*$ defined as\n",
    "\n",
    "$$c_*(x) = \\begin{cases}\n",
    "c_A(x) & \\mbox{with probability $1-p$}\\\\\n",
    "c_B(x) & \\mbox{with probability $p$}\n",
    "\\end{cases}$$\n",
    "\n",
    "attains a FPR of $\\mathrm{FPR_*}$ and TPR of $\\mathrm{TPR_*}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b83fec1",
   "metadata": {},
   "source": [
    "> Proof: we do the calculation for FPR; that of TPR follows analogously. By definition, the FPR of $c_*$ is \n",
    "$$\\begin{align}\n",
    "\\mathbb P (c_*(x) = 1 | y = 0) &= p\\, \\mathbb P (c_B(x)=1|y=0) + (1-p) \\,\\mathbb P(c_A(x)=1|y=0) \\\\\n",
    "&= p \\,\\mathrm{FPR_B} + (1-p) \\,\\mathrm{FPR_A} = \\mathrm{FPR}_*\n",
    "\\end{align}$$as claimed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39cec0b",
   "metadata": {},
   "source": [
    "The importance of this result is that it gives an **optimal boundary** for a set of classifiers. Consider the situation below, where a new classifier $C$ (orange) lies in the region below the segment AB. $C$ is, *in any sense*, worse then the projection $C'$ (black) of C onto segment AB, since it has a higher TPR for the \"cost\" of the same FPR. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "27a8179f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# THIS CODE CAN BE IGNORED\n",
    "plt.subplots(figsize=(5,5))\n",
    "\n",
    "plt.scatter(x=[0.3], y=[0.4], color='red')\n",
    "plt.scatter(x=[0.6], y=[0.6], color='blue')\n",
    "\n",
    "# Classifier C and C'\n",
    "plt.scatter(x=[0.5], y=[0.45], color='orange')\n",
    "plt.scatter(x=[0.5], y=[0.533], color='black')\n",
    "\n",
    "\n",
    "# All classifiers in-between\n",
    "xx = np.linspace(0.3, 0.6)\n",
    "yy = 2*xx/3 + 0.2\n",
    "plt.plot(xx,yy, linestyle='--', color='gray')\n",
    "plt.axvline(0.5, ymin=0.40, ymax=0.55, linestyle=':', color='gray')\n",
    "\n",
    "# plot settings\n",
    "plt.xlim(0.2, 0.7)\n",
    "plt.ylim(0.3, 0.7)\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5654fad6",
   "metadata": {},
   "source": [
    "Because of this, when given a classifier $f(x)$, one is allowed to take the **convex hull** of the ROC curve (think of it as \"laying a rubber band\" on top of the your points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ef5784e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://i.stack.imgur.com/QWkFh.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "Image(url=\"https://i.stack.imgur.com/QWkFh.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa9f48b",
   "metadata": {},
   "source": [
    "We can build a function which creates the convex hull and also computs its AUC as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "49af32bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hull_roc_auc(y_true, y_score):\n",
    "    \"\"\"\n",
    "    Computes coordinates (TPR, FPR) and ROC AUC for the convex hull \n",
    "    of a ROC curve built from a ground truth y_true (0s and 1s) and \n",
    "    a vector of scores y_score\n",
    "    \"\"\"\n",
    "\n",
    "    from sklearn.metrics import roc_curve, auc\n",
    "    from scipy.spatial import ConvexHull\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_score)\n",
    "\n",
    "    # add artificial vertex at (1,0)\n",
    "    fpr, tpr = np.append(fpr, [1]), np.append(tpr, [0])\n",
    "\n",
    "    points = np.array([fpr, tpr]).T\n",
    "    hull = ConvexHull(points)\n",
    "\n",
    "    # get vertices and remove artificial vertex\n",
    "    vertices = np.array([points[v] for v in hull.vertices if not np.array_equal(points[v],np.array([1., 0.]))])\n",
    "    fpr_hull, tpr_hull = vertices[:,0], vertices[:,1]\n",
    "\n",
    "    # hull AUC\n",
    "    hull_auc = auc(fpr_hull, tpr_hull)\n",
    "    \n",
    "    return hull_auc, fpr_hull, tpr_hull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8641cf67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate variables for hull - train/test\n",
    "hull_auc_train, fpr_hull_train, tpr_hull_train = hull_roc_auc(y_train, y_train_pred)\n",
    "hull_auc_test, fpr_hull_test, tpr_hull_test = hull_roc_auc(y_test, y_test_pred)\n",
    "\n",
    "## Plot\n",
    "fig, ax = plt.subplots(figsize=(10,5), ncols=2)\n",
    "\n",
    "# original ROC\n",
    "original_auc_train = roc_auc_score(y_train, y_train_pred)\n",
    "RocCurveDisplay.from_predictions(y_train, y_train_pred, ax=ax[0], \n",
    "                                 label=f'Log. Reg (AUC = {round(original_auc_train, 3)})')\n",
    "\n",
    "original_auc_test = roc_auc_score(y_test, y_test_pred)\n",
    "RocCurveDisplay.from_predictions(y_test, y_test_pred, ax=ax[1], \n",
    "                                 label=f'Log. Reg (AUC = {round(original_auc_test, 3)})')\n",
    "\n",
    "# convex hull\n",
    "ax[0].plot(fpr_hull_train, tpr_hull_train, label=f\"Hull ROC (AUC = {round(hull_auc_train,3)})\", marker='.', color='black')\n",
    "ax[1].plot(fpr_hull_test, tpr_hull_test, label=f\"Hull ROC (AUC = {round(hull_auc_test,3)})\", marker='.', color='black')\n",
    "\n",
    "# legends/labels\n",
    "ax[0].legend(); ax[1].legend()\n",
    "ax[0].set_title(\"Train\"); ax[1].set_title(\"Test\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239c5889",
   "metadata": {},
   "source": [
    "### Is this cheating?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bde0437",
   "metadata": {},
   "source": [
    "No. It is a remarkable property of the \"ROC space\" (FPR vs TPR) that linear interpolation between classifiers yields a new classifier. Since we do not have access to the \"true\" distribution of $f(X)|Y$, the best we can do is use its empirical distribution and build the best possible ROC curve out of it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d206a5e1",
   "metadata": {},
   "source": [
    "### Takeaways"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a329079c",
   "metadata": {},
   "source": [
    "* The ROC curve represents a machine learning classifier in the TPR / FPR plane\n",
    "* If it is not convex, it can be made convex by connecting points via line segments. This is equivalent to building new classifiers as probabilistic samplings of the endpoint classifiers\n",
    "* The area under the ROC curve (ROC AUC) represents the likelihood that a point of the positive class scores higher than one in the negative class. It is bound between 0.5 and 1.0\n",
    "* The ROC curve (and thus the ROC AUC) are invariant under rebalancing of the positive / negative classes. This is both good and bad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ff1f56",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c871c96",
   "metadata": {},
   "source": [
    "#### Appendix: properties of the ROC curve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c58a8f",
   "metadata": {},
   "source": [
    "There is an interesting characterization of the ROC curve based on the cumulative distribution functions (CDFs) of the variables\n",
    "\n",
    "$$Z_0 = (f(X)|Y=0),\\qquad Z_1 = (f(X)|Y=1)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a643ae",
   "metadata": {},
   "source": [
    "Let $F_i(t) := \\mathbb{P}(Z_i < t)$, for $i \\in \\{1,2\\}$, denote the CDFs. We want to write the false & true positive rates with respect to these CDFs. Notice that, as functions of the threshold $\\lambda$,\n",
    "\n",
    "$$\\begin{align}\n",
    "\\mathrm{TPR}(\\lambda) &= \\mathbb P(\\hat y_\\lambda(X) = 1 | Y = 1)\\\\\n",
    "&= \\mathbb P (f(X) \\geq \\lambda | Y = 1)\\\\\n",
    "&= 1- \\mathbb P (f(X) < \\lambda | Y=1) = 1 - \\mathbb P (Z_1 < \\lambda)\\\\\n",
    "&= 1 - F_1(\\lambda)\n",
    "\\end{align}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a865e53b",
   "metadata": {},
   "source": [
    "Similarly,\n",
    "$$\\mathrm{FPR}(\\lambda) = 1 - F_0(\\lambda)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61fcb65",
   "metadata": {},
   "source": [
    "We can explicitly write $\\mathrm{TPR}$ as a function of $\\mathrm{FPR}$ if we invert the last expression for $\\lambda$, obtaining $\\lambda = F_0^{-1}(1-\\mathrm{FPR})$; then\n",
    "$$\\boxed{\\mathrm{TPR} = 1 - F_1(F_0^{-1}(1-\\mathrm{FPR}))}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9243bb",
   "metadata": {},
   "source": [
    "To simplify notation, call $x \\equiv \\mathrm{FPR}$ and $y \\equiv \\mathrm{TPR}$ (don't confuse with variables $X$ and $Y$; this is just a notation which reminds who goes in the vertical and horizontal axes). We can equivalently write\n",
    "\n",
    "$$\\begin{cases}\n",
    "x &= 1 - F_0(\\lambda)\\\\\n",
    "y &= 1 - F_1(\\lambda)\n",
    "\\end{cases} \\qquad \\mbox{or}\\qquad y = 1 - F_1(F_0^{-1}(1-x))$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c0c134",
   "metadata": {},
   "source": [
    "From either expression, one can take the derivative and see that (calling $f_i(t) \\equiv F_i'(t)$ the PDFs)\n",
    "\n",
    "$$\\frac{dy}{dx} = \\frac{f_1(F_0^{-1}(1-x))}{f_0(F_0^{-1}(1-x))} \\geq 0$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4fc7cb4",
   "metadata": {},
   "source": [
    "since the PDFs are always non-negative, and so is their ratio. So we see that the ROC curve is necessarily non-decreasing.\n",
    "\n",
    "It has, however, no obligation of being **concave** (= curved face-down), even if that is how we usually draw it. Taking a second derivative of the expression above yields\n",
    "\n",
    "$$\\frac{d^2y}{dx^2} = - \\frac{f_1'}{f_0^2} + \\frac{f_1 f_0'}{f_0^3}$$\n",
    "\n",
    "where all quantities are calculated at $F_0^{-1}(1-x)$. Since derivatives of both $f_1$ and $f_0$ appear, and they can take any sign, there is no obvious sign for the expression above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd5f14a",
   "metadata": {},
   "source": [
    "##### References:\n",
    "Peter Flach, Meelis Kull, *Precision-Recall-Gain Curves: PR Analysis Done Right*, NIPS 2015\n",
    "\n",
    "##### Further reading:\n",
    "https://arxiv.org/pdf/1809.04808.pdf on the concavity of ROC curves "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad10b73f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3036b2ba",
   "metadata": {},
   "source": [
    "# A necessary interlude: cross-validation for performance assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e785e6e",
   "metadata": {},
   "source": [
    "Suppose we have a training set and a test set. We train a model $f$ on the training set and want to evaluate the performance on the test set.\n",
    "\n",
    "Any metric we create will be based on one (or more) confusion matrices - let's go with just one, to simplify, relative to a threshold $\\lambda$. \n",
    "\n",
    "There is an error associated with our random split between train and test here. Had we chosen a different training/test set, we would most likely have obtained a slightly different confusion matrix, so our metrics would be different. \n",
    "\n",
    "The best way to deal with this variability is to use resampling methods: basically, sample different training/test sets, calculate metrics, and average them out as to (hopefully) get a metric closer to the real one.\n",
    "\n",
    "In this section we discuss cross-validation and its variations as methods for estimating model performance. Over the next sections, we apply them to the calculation of different metrics.\n",
    "\n",
    "> Some readers will realize that we chose to not include the bootstrap in our discussion here. It is simpler and more practical to implement (repeated) cross-validation, and both methods tend to converge to similar results. We leave the boostrap for the Appendix in the end of the book."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8298f2d5",
   "metadata": {},
   "source": [
    "**Our recommendation** (before we get started in the zoo of different types of cross-validation): use `RepeatedStratifiedKFold`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5038bf2b",
   "metadata": {},
   "source": [
    "We will use a custom dataset here, which has class imbalance. it is the credit card fraud dataset (https://www.kaggle.com/mlg-ulb/creditcardfraud), which we slightly process to make more amenable to training quickly.\n",
    "\n",
    "```{python}\n",
    "df = pd.read_csv('creditcard.csv')\n",
    "df = df.drop(['Time', 'Amount'], axis=1)\n",
    "\n",
    "# choose how imbalanced we want this to be\n",
    "aux1 = df[df['Class']==1].sample(n=200, random_state=2)\n",
    "aux0 = df[df['Class']==0].sample(n=40000, random_state=1)\n",
    "df_reduce = pd.concat([aux1, aux0]).sample(frac=1.0, random_state=1)\n",
    "\n",
    "# join them together and shuffle\n",
    "df_reduce = pd.concat([aux1, aux0]).sample(frac=1, random_state=1)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544b77b9",
   "metadata": {},
   "source": [
    "This dataset has an imbalance rate of 0.49% of $y=1$ against 99.51% of $y=0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4aa395a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('Data/reduced_fraud_dataset.pqt')\n",
    "\n",
    "# split into features and target\n",
    "X_ = df.drop(['Class'], axis=1).values\n",
    "y_ = df['Class'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a72544f",
   "metadata": {},
   "source": [
    "### Simple cross-validation (K-fold CV)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123541c5",
   "metadata": {},
   "source": [
    "In simple cross-validation, we fix a parameter $K$ (called the *number of folds*) which is usually chosen between 5-10. We then split our data into $K$ same-sized \"chunks\". The basic idea behind **K-fold cross-validation (CV)** is:\n",
    "\n",
    "* For $k$ between 1 and $K$:\n",
    "  * Train your data using all but the $k$-th chunk (called a *fold*), ie. using $K-1$ folds \n",
    "  * Test the data on the $k$-th fold alone\n",
    "  * Calculate and store the performance on the $k$-th fold\n",
    "* Read out the mean/error from the list of $K$ metrics you calculated\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cacc8601",
   "metadata": {},
   "source": [
    "The `scikit-learn` implementation is particularly useful. What it does is that it gives the indices of the Numpy array / Pandas DataFrame which belong to the (test) single fold and the (teain) $K-1$ folds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f5b7054f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "metrics_list = []  # empty list, will store computed metrics\n",
    "\n",
    "cv = KFold(n_splits=10, shuffle=True, random_state=2)\n",
    "for train_index, test_index in cv.split(X_):\n",
    "    \n",
    "    # split data into train and test\n",
    "    X_train_cv, y_train_cv = X_[train_index], y_[train_index] # use X.iloc[train_index] if X is a DataFrame\n",
    "    X_test_cv, y_test_cv = X_[test_index], y_[test_index]\n",
    "    \n",
    "    # train model\n",
    "    cv_model = HistGradientBoostingClassifier(random_state=1)\n",
    "    cv_model.fit(X_train_cv, y_train_cv)\n",
    "    \n",
    "    # create predictions (with predict_proba)\n",
    "    y_test_pred_cv = cv_model.predict_proba(X_test_cv)[:,1]\n",
    "    \n",
    "    # compute any metric you'd like (we use AUC here for simplicity)\n",
    "    metric = roc_auc_score(y_test_cv, y_test_pred_cv)\n",
    "    metrics_list.append(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3507109f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean test AUC: 0.852, error: 0.090\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean test AUC: {0:.3f}, error: {1:.3f}\".format(np.mean(metrics_list), np.std(metrics_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84bf303a",
   "metadata": {},
   "source": [
    "### Stratified CV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de215b1e",
   "metadata": {},
   "source": [
    "It is more common than not to have one (or more) variables which risk being left out during regular CV. A normal case is that of class imbalance, where your target $y$ may be 99% made of 0's and 1% made of 1's. In usual CV, there is a high chance that there will be one or more folds with no 1's appearing whatsoever. In these situations, estimation of AUC, for instance, will throw an error.\n",
    "\n",
    "Stratification is the process by which we force our stratified class ($y$ here) to be evenly split among the folds.\n",
    "\n",
    "> Notice that, despite one usually using the target for stratification, any feature(s) are also possible. This might be useful in cases where one customer segment, for example, is less represented than the others, and we want to ensure all folds have a similar distribution of customer segments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0bdaf1",
   "metadata": {},
   "source": [
    "The ONLY change to the code above is the parameter $y$ appearing inside the CV split:\n",
    "\n",
    "```{python}\n",
    "for train_index, test_index in cv.split(X, y):\n",
    "```\n",
    "\n",
    "We run a minimal example below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d72195a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "metrics_list = []  # empty list, will store computed metrics\n",
    "\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=2)\n",
    "for train_index, test_index in cv.split(X_, y=y_):\n",
    "    \n",
    "    # split data into train and test\n",
    "    X_train_cv, y_train_cv = X_[train_index], y_[train_index] # use X.iloc[train_index] if X is a DataFrame\n",
    "    X_test_cv, y_test_cv = X_[test_index], y_[test_index]\n",
    "    \n",
    "    # train model\n",
    "    cv_model = HistGradientBoostingClassifier(random_state=1)\n",
    "    cv_model.fit(X_train_cv, y_train_cv)\n",
    "    \n",
    "    # create predictions (with predict_proba)\n",
    "    y_test_pred_cv = cv_model.predict_proba(X_test_cv)[:,1]\n",
    "    \n",
    "    # compute any metric you'd like (we use AUC here for simplicity)\n",
    "    metric = roc_auc_score(y_test_cv, y_test_pred_cv)\n",
    "    metrics_list.append(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3ab84d76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean test AUC: 0.838, error: 0.056\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean test AUC: {0:.3f}, error: {1:.3f}\".format(np.mean(metrics_list), np.std(metrics_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c36d8a",
   "metadata": {},
   "source": [
    "### Repeated CV (+ stratified)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c04260e",
   "metadata": {},
   "source": [
    "Instead of splitting the data into $K$ folds and running CV once, one could instead repeat this process $N$ times (each time splitting the data into different folds randomly) in order to sample not from $K$, but $N\\times K$ different folds. This will allow us to hopefully reduce the estimate of error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e6f867",
   "metadata": {},
   "source": [
    "> Note: this repetition makes this method slower by a factor of $N$ compared to regular K-fold CV. Be careful."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09552236",
   "metadata": {},
   "source": [
    "If we use simple repeated CV, the ONLY change to the code above is the attributes `n_repeats` and `random_state` appearing inside the CV iterator definition:\n",
    "\n",
    "```{python}\n",
    "cv = RepeatedKFold(n_splits=5, n_repeats=10, random_state=123)\n",
    "```\n",
    "\n",
    "We however choose to use the `RepeatedStratifiedKFold` version, which also adds a stratification. Then, we have to add `y` to the `cv.split` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e801a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "metrics_list = []  # empty list, will store computed metrics\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=10, random_state=123)\n",
    "for train_index, test_index in cv.split(X_, y=y_):\n",
    "    \n",
    "    # split data into train and test\n",
    "    X_train_cv, y_train_cv = X_[train_index], y_[train_index] # use X.iloc[train_index] if X is a DataFrame\n",
    "    X_test_cv, y_test_cv = X_[test_index], y_[test_index]\n",
    "    \n",
    "    # train model\n",
    "    cv_model = HistGradientBoostingClassifier(random_state=1)\n",
    "    cv_model.fit(X_train_cv, y_train_cv)\n",
    "    \n",
    "    # create predictions (with predict_proba)\n",
    "    y_test_pred_cv = cv_model.predict_proba(X_test_cv)[:,1]\n",
    "    \n",
    "    # compute any metric you'd like (we use AUC here for simplicity)\n",
    "    metric = roc_auc_score(y_test_cv, y_test_pred_cv)\n",
    "    metrics_list.append(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6c368e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean test AUC: {0:.3f}, error: {1:.3f}\".format(np.mean(metrics_list), np.std(metrics_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999e3216",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b6de3bdb",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c49a95",
   "metadata": {},
   "source": [
    "# A complement to the ROC: the gain curve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ce0de6",
   "metadata": {},
   "source": [
    "(also called the lift chart; different sources even mix up the names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83077cf",
   "metadata": {},
   "source": [
    "Despite the ROC AUC having a clear interpretation, it is often hard to interpret the ROC curve itself.\n",
    "In this section we introduce the **gain curve**, which is much easier to interpret and has a clear deterministic relation to the ROC."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7683be1d",
   "metadata": {},
   "source": [
    "### Problem setup: credit scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1e419c",
   "metadata": {},
   "source": [
    "Suppose you are a bank which has 1 million dollars to lend, in batches of $1000, to 1000 borrowers. These people must pay you that money back after one year. \n",
    "\n",
    "You have, however, 5000 people asking you for money, and you must decide which 1000 to give the money to.\n",
    "\n",
    "The main risk here is that you lend money to someone who, for any reasons, does not pay it back (that is, *defaults on the payment*) after one year. There can be several reasons for a person to default: during that year, they lost their job and could not get the necessary money to pay you back; they work with agriculture, and their crops this year were lower than average due to bad weather, so they could not raise the capital to pay you back; they fled the country; etc. \n",
    "\n",
    "Your job as a bank is to somehow **score the possible borrowers** and only lend money to those individuals who are less likely to default. This is the standard problem in **credit scoring**. You ask the data scientists in your Credit team to build a classification model to help you make the best decision."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f28da5",
   "metadata": {},
   "source": [
    "Your data scientists get back to you with a model after one month. Their report says:\n",
    "> \"We have developed a LightGBM model for binary classification. To train this model, we have used our internal database of past loans, over the past 5 years. The target of the model is whether a person has defaulted ($y=1$) on a payment to us during that period or not ($y=0$). There were 38 features employed, which can be split into 3 groups: (1) income & job related (2) previous year financial behavior (on-time payment of credit card bills and other loans) and (3) general personal information. The AUC of the model is 0.77 on the train test and 0.76 on the test set. Our recommendation is to **use the model's output score, sort it from lowest to highest (ie. lowest probability of default to highest probability) and give credit to the 1000 people with lowest score**.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85480ec",
   "metadata": {},
   "source": [
    "What they recommend is for you to build the following ordered table, and give credit to the top 1000 entries. Call it `df`, a Pandas DataFrame:\n",
    "\n",
    "|index|person_id | name | prob_default | \n",
    "|---|---|---|---|\n",
    "|0|0123|brad pitt|0.010|\n",
    "|1|2056|john williams| 0.020|\n",
    "|2|0091|jackie chan|0.025|\n",
    "|...|...|...|...|\n",
    "|4998|9001|bob junior|0.975|\n",
    "|4999|0918|alice mann|0.982|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b5a274",
   "metadata": {},
   "source": [
    "The model looks promising. However, it does not answer all your questions. You write an email back to the Credit team with one question:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759c854b",
   "metadata": {},
   "source": [
    "> Thanks for the good work. If I sort the way you said and only give credit to the first 100 people, how many will I get wrong (defaulted on)? What about the first 500? 1000? Tks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a904c20",
   "metadata": {},
   "source": [
    "In other words: we want to know how many false negatives (people who will default [$y=1$] which we are wrongly saying are likely to not default [$\\hat y =0$]) on the first $n$ people, or equivalently, the percentage of mistakes we will make. \n",
    "\n",
    "The simplest way to answer this is with a curve."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee12dced",
   "metadata": {},
   "source": [
    "### The key question to answer before proceeding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3921d2c6",
   "metadata": {},
   "source": [
    "In any problem you work on, you must answer the following question to yourself:\n",
    "> Which of my entries [people, clients, products...] are \"good\", and which are \"bad\"?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d46002",
   "metadata": {},
   "source": [
    "In our case, $y=0$ is *good*: no defaults is better than having a default. **This is why we are sorting from low scores (=higher probability of being a 0) to high scores (=higher probability of being a 1)**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e3481e",
   "metadata": {},
   "source": [
    "In your use case, it could be the opposite:\n",
    "> You might try to be solve the problem of identifying which of your employees is likely to leave the company over the next 3 months, in order to talk to them and provide an alternative (this is called an attrition problem). If $y=1$ represents an employee that is likely to leave, then you want to score from high scores to low scores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280af8fe",
   "metadata": {},
   "source": [
    "### Gain curve I: when low scores are better (sorting from low to high scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b6317d",
   "metadata": {},
   "source": [
    "Use a slight variation of the table above (we will also add more rows to make the example clearer):\n",
    "\n",
    "|index|person_id | name | prob_default | y_actual|\n",
    "|---|---|---|---|---|\n",
    "|0|0123|brad pitt|0.010|0|\n",
    "|1|2056|john williams| 0.020|0|\n",
    "|2|0091|jackie chan|0.025|1|\n",
    "|3|2221|eddie fung|0.029|0|\n",
    "|4|9301|mark hamill|0.050|1|\n",
    "|5|8913|lucy liu|0.060|0|\n",
    "|...|...|...|...|...|\n",
    "|4998|9001|bob junior|0.975|1|\n",
    "|4999|0918|alice mann|0.982|1|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31356efa",
   "metadata": {},
   "source": [
    "Again, recall that this table is ordered by `prob_default` (in ascending order). Notice that we've made two mistakes: for `jackie chan` and `mark hamill`, we are classifying them as \"good payers\" (=low probability of default), but their actual target was a 1, ie. a default. They are false negatives, which is exactly what we wanted to avoid.\n",
    "\n",
    "To account for that mistake, we can build a new columns, called `cumulative_default`, which will simply count the number of defaults acumulated until that row:\n",
    "\n",
    "`df['cumulative_default'] = df['y_actual'].cumsum()`\n",
    "\n",
    "|index|person_id | name | prob_default | y_actual|cumulative_default|\n",
    "|---|---|---|---|---|---|\n",
    "|0|0123|brad pitt|0.010|0|0|\n",
    "|1|2056|john williams| 0.020|0|0|\n",
    "|2|0091|jackie chan|0.025|1|1|\n",
    "|3|2221|eddie fung|0.029|0|1|\n",
    "|4|9301|mark hamill|0.050|1|2|\n",
    "|5|8913|lucy liu|0.060|0|2|\n",
    "|...|...|...|...|...|...|\n",
    "|4998|9001|bob junior|0.975|1|150|\n",
    "|4999|0918|alice mann|0.982|1|151|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08b6351",
   "metadata": {},
   "source": [
    "Notice that the `cumulative_default` column is non-decreasing. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101086e0",
   "metadata": {},
   "source": [
    "Notice that there are 151 defaults. We can obtain this number from `df['cumulative_default'].iloc[-1]` directly, or (in a more inefficient, but more robust way) from `df['y_actual'].sum()`. In either case, we can divide the `cumulative_default` by this number to obtain a `gain` column:\n",
    "`df['gain'] = df['cumulative_default']/df['y_actual'].sum()`\n",
    "\n",
    "|index|person_id | name | prob_default | y_actual|cumulative_default|gain|\n",
    "|---|---|---|---|---|---|---|\n",
    "|0|0123|brad pitt|0.010|0|0|0|\n",
    "|1|2056|john williams| 0.020|0|0|0|\n",
    "|2|0091|jackie chan|0.025|1|1|0.0066|\n",
    "|3|2221|eddie fung|0.029|0|1|0.0066|\n",
    "|4|9301|mark hamill|0.050|1|2|0.0132|\n",
    "|5|8913|lucy liu|0.060|0|2|0.0132|\n",
    "|...|...|...|...|...|...|...|\n",
    "|4998|9001|bob junior|0.975|1|150|0.9934|\n",
    "|4999|0918|alice mann|0.982|1|151|1.0000|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b798495a",
   "metadata": {},
   "source": [
    "We can also normalize the `index` column (simply dividing each index by the total, 5000) and plot the normalized index vs. the `gain` column on the unit square."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9767ca95",
   "metadata": {},
   "source": [
    "**Visualizing**: we can use `y_test` and `y_test_pred` from before in order to visualize this curve. Let's pretend this is a credit scoring problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0fa9f22a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_actual</th>\n",
       "      <th>prob_default</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>0</td>\n",
       "      <td>0.017202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0</td>\n",
       "      <td>0.026143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>1</td>\n",
       "      <td>0.035772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0</td>\n",
       "      <td>0.035773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>0.040128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     y_actual  prob_default\n",
       "144         0      0.017202\n",
       "66          0      0.026143\n",
       "117         1      0.035772\n",
       "78          0      0.035773\n",
       "24          0      0.040128"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'y_actual': y_test,\n",
    "                   'prob_default': y_test_pred})\n",
    "\n",
    "# sort from low to high scores\n",
    "df = df.sort_values('prob_default', ascending=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7443c1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build cumulative_default\n",
    "df['cumulative_default'] = df['y_actual'].cumsum()\n",
    "df['gain'] = df['cumulative_default']/df['y_actual'].sum()\n",
    "\n",
    "# create index starting from 0 and normalize\n",
    "df = df.reset_index(drop=True).reset_index()\n",
    "df['index'] = df['index']/(df['index'].iloc[-1])\n",
    "df = df.set_index('index')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2bf4a19",
   "metadata": {},
   "source": [
    "This is the final table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5f82a3f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_actual</th>\n",
       "      <th>prob_default</th>\n",
       "      <th>cumulative_default</th>\n",
       "      <th>gain</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.000000</th>\n",
       "      <td>0</td>\n",
       "      <td>0.017202</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.005025</th>\n",
       "      <td>0</td>\n",
       "      <td>0.026143</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.010050</th>\n",
       "      <td>1</td>\n",
       "      <td>0.035772</td>\n",
       "      <td>1</td>\n",
       "      <td>0.009901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.015075</th>\n",
       "      <td>0</td>\n",
       "      <td>0.035773</td>\n",
       "      <td>1</td>\n",
       "      <td>0.009901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.020101</th>\n",
       "      <td>0</td>\n",
       "      <td>0.040128</td>\n",
       "      <td>1</td>\n",
       "      <td>0.009901</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          y_actual  prob_default  cumulative_default      gain\n",
       "index                                                         \n",
       "0.000000         0      0.017202                   0  0.000000\n",
       "0.005025         0      0.026143                   0  0.000000\n",
       "0.010050         1      0.035772                   1  0.009901\n",
       "0.015075         0      0.035773                   1  0.009901\n",
       "0.020101         0      0.040128                   1  0.009901"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b260de1",
   "metadata": {},
   "source": [
    "#### How would a perfect gain curve be here?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d097a3b",
   "metadata": {},
   "source": [
    "Just before we plot: let us understand how a perfect gain curve would compare to ours. In a perfect gain curve, we would make no mistakes: the accumulated default column would be 0 until we reach the first person with $y=1$, and then grow linearly from there. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8a3021",
   "metadata": {},
   "source": [
    "#### What about a random classifier?\n",
    "A random classifier, on the other hand, would linearly go from (0,0) to (1,1) (can you see why?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c7019916",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplots(figsize=(5,5))\n",
    "\n",
    "# gain curve from the model\n",
    "df['gain'].plot(label='Logistic regression')\n",
    "\n",
    "# perfect gain\n",
    "df_perfect = df.sort_values('y_actual')\n",
    "df_perfect['cumulative_default'] = df_perfect['y_actual'].cumsum()\n",
    "df_perfect['gain'] = df_perfect['cumulative_default']/df_perfect['cumulative_default'].iloc[-1]\n",
    "df_perfect = df_perfect.reset_index(drop=True).reset_index()\n",
    "df_perfect['index'] = df_perfect['index']/(df_perfect['index'].iloc[-1])\n",
    "df_perfect = df_perfect.set_index('index')\n",
    "\n",
    "df_perfect['gain'].plot(xlabel='Index (sorted from lower to higher score)', ylabel='Accumulated defaults', \n",
    "                       label='Perfect gain curve', linestyle='--')\n",
    "\n",
    "# random gain\n",
    "x = np.linspace(0,1)\n",
    "plt.plot(x,x, linestyle='--', label='Random classifier')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c825d982",
   "metadata": {},
   "source": [
    "**Interpretation**:\n",
    "\n",
    "Notice that the best possible curve is the lowest, whereas the worst one is the 45 degree diagonal. Our model is intermediate, not too low nor too high. The gain curve is monotonic by construction.\n",
    "* Our model is not fantastic for *low scores*: the curve starts out flat but quickly starts to grow, meaning our model is making mistakes. It is worst for *medium scores*, where the curve grows fast while the ideal one should still be horizontal\n",
    "* For high scores, where the ideal curve is slanted, the model performs well - it tends to grow very fast in that area.\n",
    "\n",
    "**The gain curve is useful because it allows us to see how the model behaves across the whole data**. It gives us an interpretable curve which tells us how well we perform for entries with low/medium/high scores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b00b65",
   "metadata": {},
   "source": [
    "### Gain curve II: when high scores are better (sorting from high to low scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1aaebad",
   "metadata": {},
   "source": [
    "This case is exactly the opposite from the previous one. \n",
    "\n",
    "> A possible use case is in **product recommendation**. Suppose we have a model for whether a customer will be interested ($y=1$) or not ($y=0$) in a product, which will be recommended to them in our company's homepage. Then, we want to recommend the product to the clients with highest propensity to like the product, ie. those with higher score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "74bbb62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'y_actual': y_test,\n",
    "                   'prob_default': y_test_pred})\n",
    "\n",
    "# sort from low to high scores\n",
    "df = df.sort_values('prob_default', ascending=False)  ## THIS IS THE ONLY PLACE THAT CHANGES\n",
    "\n",
    "# build cumulative_default\n",
    "df['cumulative_default'] = df['y_actual'].cumsum()\n",
    "df['gain'] = df['cumulative_default']/df['y_actual'].sum()\n",
    "\n",
    "# create index starting from 0 and normalize\n",
    "df = df.reset_index(drop=True).reset_index()\n",
    "df['index'] = df['index']/(df['index'].iloc[-1])\n",
    "df = df.set_index('index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "61d36fb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplots(figsize=(5,5))\n",
    "\n",
    "# gain curve from the model\n",
    "df['gain'].plot(label='Logistic regression')\n",
    "\n",
    "# perfect gain\n",
    "df_perfect = df.sort_values('y_actual', ascending=False) ## THIS IS THE ONLY PLACE THAT CHANGES\n",
    "df_perfect['cumulative_default'] = df_perfect['y_actual'].cumsum()\n",
    "df_perfect['gain'] = df_perfect['cumulative_default']/df_perfect['cumulative_default'].iloc[-1]\n",
    "df_perfect = df_perfect.reset_index(drop=True).reset_index()\n",
    "df_perfect['index'] = df_perfect['index']/(df_perfect['index'].iloc[-1])\n",
    "df_perfect = df_perfect.set_index('index')\n",
    "\n",
    "df_perfect['gain'].plot(xlabel='Index (sorted from lower to higher score)', ylabel='Accumulated defaults', \n",
    "                       label='Perfect gain curve', linestyle='--')\n",
    "\n",
    "# random gain\n",
    "x = np.linspace(0,1)\n",
    "plt.plot(x,x, linestyle='--', label='Random classifier')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c832991",
   "metadata": {},
   "source": [
    "**Interpretation**: of course, since we are using the exact same data as before, the conclusions must be the same. This curve is exactly the previous one, upside down."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6892479",
   "metadata": {},
   "source": [
    "### Area under the gain curve & its relation to ROC AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f01cb4",
   "metadata": {},
   "source": [
    "**The gain curves must be analyzed together with the ROC AUC**. It turns out they are both complementary and interpretable, providing a full picture of what is happening.\n",
    "\n",
    "\"Wait, what about the area under the gain curve?\", one might ask. We now prove a very interesting result relating it to the ROC AUC: **one of them uniquely defines the other**, so the area under the gain curve doesn't really matter. We can use the ROC AUC instead."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8120d10a",
   "metadata": {},
   "source": [
    "**--- Mathematical interlude---**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb80779a",
   "metadata": {},
   "source": [
    "**Proposition [equivalence of AUG and ROC AUC]**. Consider the gain curve II above (which is sorted from high to low scores). Let $\\mathrm{AUG}$ denote the area under the gain curve, and let $\\mathrm{AUC}$ denote the ROC AUC. Let $\\pi_1 = \\mathbb{P} (y=1)$ denote the fraction of the positive class. Then\n",
    "\n",
    "$$\\boxed{\\mathrm{AUG} = \\frac{\\pi_1}{2} + (1-\\pi_1) \\mathrm{AUC}}\\qquad \\mbox{(high to low scores)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bbb55e4",
   "metadata": {},
   "source": [
    "> Proof: let us translate our construction of the gain curve into the language of probability. The Y axis contains the proportion of points correctly classified as 1, i.e. $\\mathbb P(\\hat y = 1|y=1)$ which is just the true positive rate. We have seen in the Appendix for the ROC curve that, for a fixed threshold $\\lambda$, $$\\mathrm{TPR}(\\lambda) = 1 - F_1(\\lambda)$$ where $F_1(\\lambda) = \\mathbb P (f(X) \\leq \\lambda | Y=1)$ is the CDF for the score $f(X)|Y=1$. Hence, we let $y(\\lambda) = 1 - F_1(\\lambda)$ be our Y axis. For the X axis, it represents the proportion ($\\mathbb P$) of points with decreasing ($\\geq \\lambda$) score ($f(X)$). Hence, $x = \\mathbb P (f(X) \\geq \\lambda) = 1 - F(\\lambda)$ where the CDF $F(\\lambda)$ is that of the unconditional score: $$F(\\lambda) = \\mathbb P (f(X) < \\lambda),$$ which can also be written in terms of the conditionals $F_i$ via $$\\begin{align}F(\\lambda) &=  \\mathbb P (f(X) < \\lambda) = \\mathbb P (f(X) < \\lambda|Y=1) \\mathbb{P} (Y=1) + \\mathbb P (f(X) < \\lambda|Y=0) \\mathbb{P}(Y=0)\\\\\n",
    "&= \\pi_1 F_1(\\lambda) + \\pi_0 F_0 (\\lambda)\\end{align}.$$ Here $\\pi_1 + \\pi_0 = 1$ are the proportions of $Y=1$ and $Y=0$. We have thus written the gain curve as $$\\begin{cases}x(\\lambda) &=& 1 - F(\\lambda) = 1 - \\pi_1 F_1(\\lambda) - \\pi_0 F_0(\\lambda)\\\\\n",
    "y(\\lambda) &=& 1 - F_1(\\lambda)\\end{cases}$$\n",
    "To calculate $\\mathrm{AUG}$, ideally we would like to write $y$ as a function of $x$ and integrate. This is possible if we invert $\\lambda = \\lambda(x)$ and plug it into the expression for $y$. This is hard since $\\lambda$ appears both as the argument of $F_0$ and $F_1$. Instead, what we can do is to *write $x$ as a function of $y$ instead* and calculate the integral $\\int x dy$ instead of $\\int y dx$. These integrals are not the same, but they will be related as we show below. \n",
    "\n",
    "> We have $\\lambda = F_1^{-1}(1-y)$. Plugging this into the equation for $x$ yields (calling $G(x)$ the gain curve and $G^{-1}(y)$ its inverse:\n",
    "$$\\begin{align}\n",
    "x \\equiv G^{-1}(y) &= 1 - \\pi_1 F_1 (F_1^{-1}(1-y)) - \\pi_0 F_0 (F_1^{-1}(1-y)) \\\\\n",
    "&= 1 - \\pi_1(1-y) - \\pi_0 F_0(F_1^{-1}(1-y)).\n",
    "\\end{align}$$\n",
    "In the Appendix for the ROC curve we saw that we could write it as $y = R(x) = 1 - F_1(F_0^{-1}(1-x))$. This is almost what we have, but the roles of $F_1$ and $F_0$ are shifted. We can actually invert this expression to get $$x \\equiv R^{-1}(y) = 1 - F_0(F_1^{-1}(1-y)),$$ which matches nicely with the RHS above. Hence \n",
    "$$\\begin{align}\n",
    "G^{-1}(y) &= 1 - \\pi_1 (1-y) - \\pi_0 (1 - R^{-1}(y))\\\\\n",
    "&=\\pi_1 y + \\pi_0 R^{-1}(y)\\\\\n",
    "\\Rightarrow \\int_0^1 G^{-1}(y)dy  &= \\frac{\\pi_1}{2} + \\pi_0 \\int_0^1R^{-1}(y)dy\n",
    "\\end{align}$$\n",
    "Now, both the ROC and gain curve live inside the unit square $[0,1]\\times[0,1]$, which has area equal to 1, and have endpoints in $(0,0)$ and $(1,1)$. For any such function,\n",
    "$$\\int_0^1 f(x) dx + \\int_0^1 f^{-1}(y) dy = 1.$$\n",
    "We can then rewrite the equality above using $\\mathrm{AUC}$ and $\\mathrm{AUG}$:\n",
    "$$(1-\\mathrm{AUG}) = \\frac{\\pi_1}{2} + \\pi_0 (1-\\mathrm{AUC});$$\n",
    "using that $\\pi_0 = 1 - \\pi_1$ and simplifying yields\n",
    "$$\\mathrm{AUG} = \\frac{\\pi_1}{2} + (1-\\pi_1) \\mathrm{AUC}$$\n",
    "as claimed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7aa3d3",
   "metadata": {},
   "source": [
    "**Problem**: using the exact same logic as above (or just good old geometry) prove that for the gain curve I it holds that\n",
    "\n",
    "$$\\boxed{\\mathrm{AUG} = 1 - \\left[\\frac{\\pi_1}{2} + (1-\\pi_1) \\mathrm{AUC}\\right]}\\qquad \\mbox{(low to high scores)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72984286",
   "metadata": {},
   "source": [
    "**--- end of interlude---**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defa34c5",
   "metadata": {},
   "source": [
    "#### Numerically checking this"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4cdc629",
   "metadata": {},
   "source": [
    "Let us us the DataFrame defined above (which has the gain with scores from high to low):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "96120384",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_actual</th>\n",
       "      <th>prob_default</th>\n",
       "      <th>cumulative_default</th>\n",
       "      <th>gain</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.000000</th>\n",
       "      <td>1</td>\n",
       "      <td>0.986611</td>\n",
       "      <td>1</td>\n",
       "      <td>0.009901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.005025</th>\n",
       "      <td>1</td>\n",
       "      <td>0.976603</td>\n",
       "      <td>2</td>\n",
       "      <td>0.019802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.010050</th>\n",
       "      <td>1</td>\n",
       "      <td>0.974633</td>\n",
       "      <td>3</td>\n",
       "      <td>0.029703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.015075</th>\n",
       "      <td>1</td>\n",
       "      <td>0.968521</td>\n",
       "      <td>4</td>\n",
       "      <td>0.039604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.020101</th>\n",
       "      <td>1</td>\n",
       "      <td>0.965467</td>\n",
       "      <td>5</td>\n",
       "      <td>0.049505</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          y_actual  prob_default  cumulative_default      gain\n",
       "index                                                         \n",
       "0.000000         1      0.986611                   1  0.009901\n",
       "0.005025         1      0.976603                   2  0.019802\n",
       "0.010050         1      0.974633                   3  0.029703\n",
       "0.015075         1      0.968521                   4  0.039604\n",
       "0.020101         1      0.965467                   5  0.049505"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e396410",
   "metadata": {},
   "source": [
    "We want to compare the area under the gain curve with the expression $\\pi_1/2 +(1-\\pi) \\mathrm{AUC}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4f0805b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of positive class (pi1): 0.505\n",
      "\n",
      "Raw metrics:\n",
      " > AUG = 0.653\n",
      " > AUC = 0.803\n",
      "\n",
      "Calculated AUG: 0.650\n",
      " > Difference between AUG and calculated version: 0.003\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import auc  # this is not roc_auc_score; it is just a function for numerical integration\n",
    "\n",
    "pi1 = y_test.sum()/len(y_test) # proportion of 1's in the test dataset\n",
    "print(\"Proportion of positive class (pi1): {0:.3f}\".format(pi1))\n",
    "aug = auc(x=df.index, y=df['gain'])\n",
    "auc_ = roc_auc_score(y_test, y_test_pred)\n",
    "print(\"\\nRaw metrics:\\n > AUG = {0:.3f}\\n > AUC = {1:.3f}\".format(aug, auc_))\n",
    "\n",
    "aug_calc = pi1/2 + (1-pi1)*auc_\n",
    "print(\"\\nCalculated AUG: {0:.3f}\".format(aug_calc))\n",
    "print(\" > Difference between AUG and calculated version: {0:.3f}\".format(np.abs(aug-aug_calc)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9016f510",
   "metadata": {},
   "source": [
    "We can see that indeed both are very close (difference in the third decimal place), as expected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a0d676",
   "metadata": {},
   "source": [
    "##### References\n",
    "Chris J. Lloyd, *A Note on the Area under the Gains Chart*. International Journal of Statistics in Medical Research, 2018, 7, 66-69 \n",
    "\n",
    "Max Kuhn, Kjell Johnson, *Applied Predictive Modeling*. Springer, 2016, pp. 265-266"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0291446",
   "metadata": {},
   "source": [
    "### Wrap-up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8d6dd5",
   "metadata": {},
   "source": [
    "We have seen that the gain curve and the ROC are cousins displaying complementary information:\n",
    "\n",
    "| | ROC | Gain|\n",
    "|---|---|---|\n",
    "|Interpretable area| Yes, ROC AUC =$\\mathbb P (Z_1 \\geq Z_0)$ | Yes, but determined by ROC AUC|\n",
    "|Interpretable curve| Hard to interpret | Easy to interpret|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fca7448",
   "metadata": {},
   "source": [
    "It is therefore always recommended to look at the ROC AUC for its capability of showing predictive power (and because it is the industry reference), but at the same time to study the Gain curve to see how the model performs for low / middle / high scores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5716c81",
   "metadata": {},
   "source": [
    "# Number 2. Precision, recall, and $F$-scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f827c061",
   "metadata": {},
   "source": [
    "### Motivation: a Covid test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5b05b1",
   "metadata": {},
   "source": [
    "What is the difference between\n",
    "\n",
    "$$\\mathbb P (\\hat y = 1|y=1) \\qquad \\mbox{and}\\qquad \\mathbb P(y=1|\\hat y=1)?$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e913eae6",
   "metadata": {},
   "source": [
    "The first one measures, *out of all points in the positive class*, how many we got right. The second one measures, *out of all points predicted to be in the positive class*, how many were actually positives.\n",
    "\n",
    "These quantities are not the same. Writing them like this makes this fact obvious, but it is surprising how many times we can mix them up in conversation. For instance:\n",
    "\n",
    "> I just got a positive in my Covid test. They say that it is right 99% of the time when you are infected, so I am probably infected.\n",
    "\n",
    "The conclusion above is a falacy, because we do not have enough data. Does the person mean\n",
    "\n",
    "$$\\mathbb P (\\mbox{test gives positive | you have Covid}) = 99\\%$$\n",
    "or\n",
    "$$\\mathbb P (\\mbox{ you have Covid | test gives positive}) = 99\\%?$$\n",
    "\n",
    "These two cases are completely different, as we show below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca32b41a",
   "metadata": {},
   "source": [
    "> **(Review: Bayes' rule**). We are entering the domain where Bayes' theorem becomes important. It is the rewriting of the definition of conditional probability as follows:\n",
    "$$\\mathbb P(A|B) = \\frac{\\mathbb P(A\\cap B)}{\\mathbb P(B)} = \\frac{\\mathbb P(B|A) \\mathbb P(A)}{\\mathbb P (B)}$$\n",
    "where one sometimes writes the denominator as a sum over all possible dependencies of $B$: \n",
    "$$\\mathbb P (B) = \\sum_{A'} \\mathbb P(B|A') \\mathbb P(A')$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec9ca18",
   "metadata": {},
   "source": [
    "For instance, in the case above, let $y=1$ denote if someone has Covid, and $\\hat y = 1$ denote that they tested positive. \n",
    "\n",
    "Let us assume that \n",
    "\n",
    "$$\\mathbb P (\\hat y=1 | y=1) = 99\\%$$\n",
    "\n",
    "\n",
    "We can write, using Bayes' theorem,\n",
    "\n",
    "$$\\mathbb P(y=1|\\hat y=1) = \\frac{\\mathbb P (\\hat y=1 | y=1) \\mathbb P(y=1)}{\\mathbb P (\\hat y=1)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f358d8",
   "metadata": {},
   "source": [
    "or, expanding the denominator,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7222f80b",
   "metadata": {},
   "source": [
    "$$\\begin{align}\n",
    "\\mathbb P(y=1|\\hat y=1) &= \\frac{\\mathbb P (\\hat y=1 | y=1) \\mathbb P(y=1)}{\\mathbb P (\\hat y=1|y=0) \\mathbb P(y=0) + \\mathbb P(\\hat y = 1|y=1) \\mathbb P(y=1)}\\\\\n",
    "&= \\frac{1}{\\displaystyle1 + \\frac{\\mathbb P(\\hat y=1 | y=0) \\mathbb P(y=0)}{\\mathbb P(\\hat y=1|y=1) \\mathbb P(y=1)}}\n",
    "\\end{align}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e4e130",
   "metadata": {},
   "source": [
    "Assume that:\n",
    "* 1% of the population is infected, ie. $\\mathbb P(y=1) = 0.01$ and $\\mathbb P(y=0) = 0.99$\n",
    "* If you are infected, there is a 99% chance the test will come back positive: $\\mathbb P(\\hat y=1|y=1) = 0.99$\n",
    "* If you are not infected, there is a 5% chance the test will come back as a (false) positive: $\\mathbb P(\\hat y=1|y=0) = 0.05$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d2668a",
   "metadata": {},
   "source": [
    "Then, from the expression above we get\n",
    "$$\\mathbb P(y=1|\\hat y=1) = \\frac{1}{\\displaystyle 1 + \\frac{0.05 \\times 0.99}{0.99 \\times 0.01}} = \\frac 16 \\approx  16.7\\%$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e644a5c9",
   "metadata": {},
   "source": [
    "that is, if your test comes back positive, there is only a 16.7% chance that you actually have Covid."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbcea986",
   "metadata": {},
   "source": [
    "This is a *significantly* smaller number than the 99% we started with (and also shows why a \"test with 99% confidence\" does not mean much by itself). This is why $\\mathbb P (\\hat y = 1|y=1)$ and $\\mathbb P(y=1|\\hat y=1)$ are *very* different things."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9402ba4d",
   "metadata": {},
   "source": [
    "> One might argue that the test is bad. It is not. To see why, think about it this way. Without having taken a test, your prior chance of being infected was 1%. Now that you have taken the test, this chance grows by **almost 17 times**. This is a huge growth! It is just not a definitive answer. Indeed, one could **take the test again** and see how much the probability changes. \n",
    "\n",
    "> (**Problem**) Suppose we test again, and again we get a positive. Convince yourself that we can calculate the new probability of being infected by formally starting out from the exact same formula above but changing the prior probability of being infected to $\\mathbb P (y=1) = 1/6$ (which implies $\\mathbb P(y=0) = 5/6$), yielding\n",
    "$$\\mathbb P(y=1|\\hat y_1=1, \\hat y_2 = 1) = \\frac{1}{\\displaystyle 1 + \\frac{0.05\\times 5/6}{0.99 \\times 1/6}} \\approx 80\\%,$$which is now much higher. If we further test again this number increases to 99%, and so on. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a03da9",
   "metadata": {},
   "source": [
    "### Precision and recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f701a6f5",
   "metadata": {},
   "source": [
    "$$\n",
    "\\boxed{\\mathrm{Recall} = \\mathbb P (\\hat y = 1|y=1)}$$\n",
    "$$\\boxed{\\mathrm{Precision} = \\mathbb P(y=1|\\hat y=1)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db508001",
   "metadata": {},
   "source": [
    "For the Covid test above, it had a recall of 99% and a precision of 16.7% for the positive class.\n",
    "> For multiclass models (which generalize the binary case we see here), one calculates precision/recall for each class. For instance, if you have an image classification model which classifies an image into $\\{\\mathrm{dog, cat, horse, penguin}\\}$ then you should calculate precision/recall for each class: $$\\mathrm{Recall_{dog}} = \\mathbb P (\\hat y = \\mathrm{dog} | y = \\mathrm{dog}),\\quad \\mathrm{Recall_{cat}} = \\mathbb P (\\hat y = \\mathrm{cat} | y = \\mathrm{cat})$$ and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac609f76",
   "metadata": {},
   "source": [
    "### The $F$-scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de804613",
   "metadata": {},
   "source": [
    "Recall that, given two numbers $a, b$, their **harmonic mean** is the number $c$ defined via\n",
    "\n",
    "$$\\frac 1c = \\frac 12 \\left( \\frac 1a + \\frac 1b \\right),$$\n",
    "\n",
    "or explicitly\n",
    "\n",
    "$$c = \\frac{2}{1/a + 1/b} = \\frac{2ab}{a+b}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7aa9bac",
   "metadata": {},
   "source": [
    "(if any of the numbers is 0, the harmonic mean is undefined; if any of them is infinite, the harmonic mean will be the finite one left, as can be seen by taking the limit in the first definition)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d8ff46",
   "metadata": {},
   "source": [
    "We define the **$F_1$ score** as the harmonic mean of precision and recall:\n",
    "\n",
    "$$\\boxed{\\frac{1}{F_1} = \\frac 12 \\frac{1}{\\mathrm{Precision}} + \\frac 12 \\frac{1}{\\mathrm{Recall}}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31f7b52",
   "metadata": {},
   "source": [
    "More generally, we define the **$F_\\beta$ score** as a weighted harmonic mean between precision and recall:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c165e3de",
   "metadata": {},
   "source": [
    "$$\\frac{1}{F_\\beta} = \\frac{1}{1+\\beta^2} \\frac{1}{\\mathrm{Precision}} + \\frac{\\beta^2}{1+\\beta^2}\\frac{1}{\\mathrm{Recall}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa2ec80",
   "metadata": {},
   "source": [
    "For $\\beta = 1$ we retrieve $F_1$, which weighs precision and recall equally; for $\\beta > 1$ we give a higher importance to recall, whereas for $\\beta < 1$ we place more importance on precision."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63de785f",
   "metadata": {},
   "source": [
    "A relevant question is then:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55810e8f",
   "metadata": {},
   "source": [
    "### Should I prioritize precision or recall? Which matters most?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7c744c",
   "metadata": {},
   "source": [
    "A rule-of-thumb to keep in mind is:\n",
    "\n",
    "$$\\mathrm{Precision \\sim } \\quad \\mbox{focus on minimizing false positives}$$\n",
    "$$\\mathrm{Recall \\sim } \\quad \\mbox{ focus on minimizing false negatives}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4d537d",
   "metadata": {},
   "source": [
    "False positives and false negatives are never what we wish for, but there is always a trade-off on which is worse for the problem at hand. Consider the situations below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0e2129",
   "metadata": {},
   "source": [
    "**Treatment for a disease.**\n",
    "You work in medical research, and you are developing a test for a specific colon disease. This disease is lethal - if a person has it and is not treated there is a high chance they will die. \n",
    "\n",
    "There already exists a very accurate test to diagnose this disease, but it is time-consuming and very uncomfortable for the patient. Your company wants to create a cheaper and less uncomfortable test, which can be done quickly at a doctor's office, but will also be less accurate. The idea here is that, if a patient tests positive under this quicker test, only then will they take the more time-consuming and uncomfortable one, as a means of validation.\n",
    "\n",
    "> **Question**: which do you prioritize, precision or recall?\n",
    "\n",
    "> Solution: consider what happens if you have a false negative (=the patient is sick, but your test returns negative). Since the disease is lethal, this means this patient might die. Now consider a false positive (=patient is not sick, but your test returns positive). Then they will need to go through an uncomfortable test, but they will not die. In this case, **false negatives are much worse than false positives**. Because of this, our focus is on high recall."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1802b591",
   "metadata": {},
   "source": [
    "**Product recommendation**. You work in an e-commerce company, and are developing a product recommendation model. Basically, when the user enters your homepage, you want to recommend products to them based on their profile, previous purchases etc which will maximize the chances they will buy again. The product recommendations will be displayed, 5 at a time, in a \"Recommended for you\" tab.\n",
    "\n",
    "Usually, product recommendation models are not just binary classifiers, but for the sake of simplicity let's assume they are. Then, our model is a classification model which outputs a score: high scores indicate a user is likely to purchase something, and low scores mean the opposite."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f3f751",
   "metadata": {},
   "source": [
    "> **Question**: which do you prioritize, precision or recall?\n",
    "\n",
    "> Solution: a false positive here means a product which you recommend, but the user is not really likely to buy. A false negative is a product they would have liked, but you don't recommend. If you want to maximize the likelihood a user will buy a product, you want to make sure you only show them the top 5 products they will like: few false positives. It is OK, however, to have products that they would like but you don't end up recommending. What you want to avoid is that they enter the page, don't find anything they like, and leave. **False positives are worse than false negatives here**, so the focus is on high precision."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454a72fb",
   "metadata": {},
   "source": [
    "To-dos:\n",
    "    \n",
    "* Threshold-independent metrics\n",
    "* Threshold-dependent metrics\n",
    "* Finding optimal thresholds\n",
    "* Do we really use the convex hull?\n",
    "* Three important models\n",
    "\t- Logistic regression\n",
    "\t- XGBoost / LightGBM / GradientBoostingClassifier\n",
    "\t- Neural nets\n",
    "* Model calibration\n",
    "* Defining a target\n",
    "* Uncertainty measures (CV / bootstrap)\n",
    "* Interpretability (SHAP with logits)\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b096c01d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40baec44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25c0833",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8fb6cfbd",
   "metadata": {},
   "source": [
    "# Further readings "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93ec016",
   "metadata": {},
   "source": [
    "## Bootstrap for model assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401971e4",
   "metadata": {},
   "source": [
    "Suppose you have the following dataset with 20 observations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4c16d22f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.78862847,  0.43650985,  0.09649747, -1.8634927 , -0.2773882 ,\n",
       "       -0.35475898, -0.08274148, -0.62700068, -0.04381817, -0.47721803,\n",
       "       -1.31386475,  0.88462238,  0.88131804,  1.70957306,  0.05003364,\n",
       "       -0.40467741, -0.54535995, -1.54647732,  0.98236743, -1.10106763])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(3)\n",
    "x = np.random.randn(20)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f979cef",
   "metadata": {},
   "source": [
    "As we can see, this data was actually generated from a normal distribution centered in zero (with unit variance), but let us suppose we don't know this. We might ask two relevant questions:\n",
    "* What is a good estimate for the *mean value* of the data?\n",
    "* What is a good estimate for the *error* on that estimate of the mean?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65e68e2",
   "metadata": {},
   "source": [
    "The naive answer is: calculate the mean and standard deviation, done:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9a1b3772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: -0.09, std: 0.97\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean: {0:.2f}, std: {1:.2f}\".format(x.mean(), x.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2104c82b",
   "metadata": {},
   "source": [
    "Ideally, we would like to get more data to reduce the variance - we know from the central limit theorem that, whatever the distribution that generated the data, the mean will asymptotically (as $n\\to\\infty$ where $n$ is the total amount of data) behave as a normal variable with variance decreasing as $1/n$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e02a4c",
   "metadata": {},
   "source": [
    "If we cannot get more data, what else can we do? It turns out that, if we **sample $n$ points (with replacement) from the original data**, this new dataset (called a **boostrap sample**) will be distributed equally to the original data. In other words, this \"new\" dataset can be used as an equivalent (but different) to the \"old\" one, on an equal footing.\n",
    "\n",
    "The **boostrap method** consists of creating many (say, thousands) such boostrap samples, and using the average calculated on each one of them as an estimate of the true average - in other words, using an average of averages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37fae0e7",
   "metadata": {},
   "source": [
    "> One might wonder: why do we need to introduce random samplings? Couldn't we just calculate all possible boostrap samples and average out? In practice no - this is an exponentially large set. If you have $n$ data points, there will be $n^n$ boostrap samples. In our $n=20$ case, $$n^n = 20^{20} = 10^{20 \\log_{10} 20} \\approx 10^{26}$$ is a tremendously large, and computationally infeasible, number."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df32048",
   "metadata": {},
   "source": [
    "We can use the `resample` method in scikit-learn to calculate boostrap samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d054ae0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.35475898,  0.88462238,  0.88131804, -0.04381817, -0.47721803,\n",
       "        0.88462238, -0.35475898, -0.40467741,  1.78862847, -0.54535995,\n",
       "        0.43650985,  0.88131804, -0.62700068,  1.70957306, -0.08274148,\n",
       "        0.98236743, -0.35475898,  0.98236743,  0.88462238, -1.31386475])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "resample(x, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a1eb04",
   "metadata": {},
   "source": [
    "Let us show how boostrap samples can be used to better estimate the sample mean and error. We will create $N = 5000$ samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "465af7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "means = np.array([resample(x, random_state=seed).mean() for seed in range(5000)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ecd051f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot original data and boostrapped data\n",
    "fig, ax = plt.subplots(figsize=(10,5), ncols=2)\n",
    "\n",
    "# original data\n",
    "ax[0].hist(x, bins=5)\n",
    "ax[0].set_title(\"Histogram of original data\")\n",
    "ax[0].axvline(x.mean(), linestyle='--', color='red')\n",
    "ax[0].axvline(x.mean()+x.std(), linestyle='--', color='black')\n",
    "ax[0].axvline(x.mean()-x.std(), linestyle='--', color='black')\n",
    "\n",
    "\n",
    "# boostrapped data\n",
    "ax[1].hist(means, bins=100)\n",
    "ax[1].set_title(\"Histogram of boostrapped data\")\n",
    "ax[1].axvline(means.mean(), linestyle='--', color='red')\n",
    "ax[1].axvline(means.mean()+means.std(), linestyle='--', color='black')\n",
    "ax[1].axvline(means.mean()-means.std(), linestyle='--', color='black')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0583d6c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: -0.09, std: 0.22\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean: {0:.2f}, std: {1:.2f}\".format(means.mean(), means.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f418cfe",
   "metadata": {},
   "source": [
    "Notice how, despite the mean itself not changing, the standard deviation is much smaller than that of the original data! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec02f004",
   "metadata": {},
   "source": [
    "### The boostrap in machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfc0eda",
   "metadata": {},
   "source": [
    "One could consider using boostrap in machine learning in the following (naive) way:\n",
    "* Create empty list\n",
    "* For *i* between 0 and N:\n",
    "  * Create a bootstrap sample X_boot, y_boot\n",
    "  * Split into train and test sets (say, test size 30%)\n",
    "  * Instantiate classifier and train on X_train, y_train\n",
    "  * Calculate metrics from X_test, y_test\n",
    "  * Append metrics to list\n",
    "* Compute average / standard deviation of metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b8f17a",
   "metadata": {},
   "source": [
    "The problem of this approach is that, since boostrap works with sampling *with replacement*, it is likely that there will be points which are simultaneously in the training and the test set. These points will make the model performance appear to be higher than it actually is."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f840a5",
   "metadata": {},
   "source": [
    "TODO - continue this session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad5f08a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
