{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea22545b",
   "metadata": {},
   "source": [
    "# The variance of the ROC AUC\n",
    "### An approach via the Mann-Whitney-Wilcoxon estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8982f2f",
   "metadata": {},
   "source": [
    "Recall that the ROC AUC of a scoring function $f$ is  defined as\n",
    "\n",
    "$$A := \\mathbb P(f(X) \\geq f(X') | Y=1, Y'=0).$$\n",
    "\n",
    "Here, $(X,Y)$ are jointly distributed with $Y$ taking values in $\\{0,1\\}$. \n",
    "\n",
    "The ROC AUC can be estimated via the Mann–Whitney–Wilcoxon statistic\n",
    "\n",
    "$$\\boxed{\\hat A = \\frac{1}{n_0 n_1} \\sum_{i=1}^{n_1} \\sum_{j=1}^{n_0} 1_{P_i \\geq Q_j}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aea4e17",
   "metadata": {},
   "source": [
    "where $P_i$ refers to the score of a point in class 1, and $Q_j$ of one in class 0: \n",
    "\n",
    "$$P_i \\equiv f(X_i)|Y_i=1,\\qquad Q_j \\equiv f(X_j)|Y_j=0$$\n",
    "\n",
    "We will often omit the limits of the sums whenever they are obvious from the context."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0153dd5",
   "metadata": {},
   "source": [
    "It is easily seen that $\\mathbb E[\\hat A] = A$, and thus one might ask what is the variance of this estimator. We will prove the following result (eq. (2) of [1] and eq. (6) of [2]):\n",
    "\n",
    "**Theorem**. Under tha hypothesis that all points in a given class are independent (ie. $P$'s are iid among themselves, as are the $Q$') then the variance of the Mann-Whitney-Wilcoxon statistic is\n",
    "\n",
    "$$\\boxed{\\mathrm{Var}\\; \\hat A = \\frac{A(1-A) + (n_0 - 1)(P_{XYY} - A^2) + (n_1 - 1)(P_{XXY} - A^2)}{n_0 n_1},}$$\n",
    "\n",
    "where \n",
    "\n",
    "$$P_{XXY} = \\mathbb P (P \\geq Q, P' \\geq Q)$$\n",
    "\n",
    "for any $P, P'$, and similarly \n",
    "\n",
    "$$P_{XYY} = \\mathbb P(P \\geq Q, P \\geq Q')$$\n",
    "\n",
    "for any $Q, Q'$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883b8c6b",
   "metadata": {},
   "source": [
    "## Proof:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f707b56e",
   "metadata": {},
   "source": [
    "In what follows, $1_{ij} \\equiv 1_{P_i \\geq Q_j}$ will be a shorthand notation.\n",
    "\n",
    "By definition,\n",
    "\n",
    "$$\\begin{align*}\n",
    "\\mathrm{Var}\\, (n_0 n_1 \\hat A) &= \\mathrm{Var}\\, \\left( \\sum_{ij} 1_{ij}, \\sum_{kl} 1_{kl} \\right)\\\\\n",
    "&= \\sum_{ij} \\sum_{kl} \\mathrm{cov}\\,(1_{ij}, 1_{kl})\\\\\n",
    "&= \\sum_{ij} \\sum_{kl} \\mathrm{cov}\\,(1_{ij}, 1_{kl}) \\left[ 1_{i=k\\\\ j= l} + 1_{i=k\\\\ j \\neq l}+ 1_{i\\neq k\\\\ j= l}+ 1_{i\\neq k\\\\ j \\neq l} \\right]\\\\\n",
    "&= \\sum_{ij} \\mathrm{Var} (1_{ij}) + \\sum_i \\sum_{j\\neq l} \\mathrm{cov}\\,(1_{ij}, 1_{il}) + \\sum_j \\sum_{i\\neq k} \\mathrm{cov}\\,(1_{ij}, 1_{kj}) + \\sum_{i\\neq k} \\sum_{j\\neq l} \\mathrm{cov}\\,(1_{ij}, 1_{kl})\n",
    "\\end{align*}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61080db3",
   "metadata": {},
   "source": [
    "Now, we can simplify a bit by noting that \n",
    "\n",
    "$$\\begin{align*}\n",
    "\\mathrm{cov}\\,(1_{ij}, 1_{kl}) &\\equiv \\mathbb E[1_{ij} 1_{kl}] - \\mathbb E[1_{ij}] \\mathbb E[1_{kl}]\\\\\n",
    "&= \\mathbb E[1_{ij, kl}] - A^2\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "where $1_{ij, kl}$ denotes $1_{P_i\\geq Q_j, P_k \\geq Q_l}$ and we see the AUC $A$ appear since $\\mathbb E[1_{ij}] = \\mathbb E[1_{P_i \\geq Q_j}] = \\mathbb P(P_i \\geq Q_j) = A$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c64dee",
   "metadata": {},
   "source": [
    "Hence,\n",
    "\n",
    "$$\\begin{align*}\n",
    "n_0^2 n_1^2 \\mathrm{Var}\\, \\hat A =  \\sum_{ij} \\mathrm{Var} (1_{ij}) +\n",
    "    \\sum_i \\sum_{j\\neq l} \\left( \\mathbb E[1_{ij, il}] - A^2 \\right) +\n",
    "    \\sum_j \\sum_{i\\neq k} \\left( \\mathbb E[1_{ij, kj}] - A^2 \\right) + \n",
    "    \\sum_{i \\neq k} \\sum_{j\\neq l} \\left( \\mathbb E[1_{ij, kl}] - A^2 \\right)\n",
    "\\end{align*}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6ccf7e",
   "metadata": {},
   "source": [
    "Now, the summand in the last term is (explicitly) $\\mathbb E[1_{P_i \\geq Q_j, P_k \\geq Q_l}]$. But since $i\\neq k$ and $j \\neq l$, the events $P_i \\geq Q_j$ is completely independent from $P_k \\geq Q_l$, and we can split the expectation into $\\mathbb E[1_{P_i \\geq Q_j}] \\mathbb E[1_{P_k \\geq Q_l}] = A^2$, which cancels the other $A^2$ term. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8c4c2a",
   "metadata": {},
   "source": [
    "Furthermore, it is easy to see that the term $\\mathbb E[1_{ij, il}]$ is exactly the $P_{XYY}$ term defined above: it is the probability that a single score in class 1 ($P_i$) is greater than two random scores from class 0 ($Q_j$ and $Q_l$). An analogous reasoning shows that $\\mathbb E[1_{ij, jk}] = \\mathbb P_{XXY}$.\n",
    "\n",
    "Putting these together, we are left with"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3486c5",
   "metadata": {},
   "source": [
    "$$\\begin{align*}\n",
    " \\mathrm{Var}\\, \\hat A =  \\frac{1}{n_0^2 n_1^2} \\left[\n",
    " \\sum_{ij} \\mathrm{Var} (1_{ij}) +\n",
    "    \\sum_i \\sum_{j\\neq l} \\left( P_{XYY} - A^2 \\right) +\n",
    "    \\sum_j \\sum_{i\\neq k} \\left( P_{XXY} - A^2 \\right) \n",
    " \\right] \\qquad (*)\n",
    "\\end{align*}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c953a983",
   "metadata": {},
   "source": [
    "To go further, we need an intermediate result:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3c745c",
   "metadata": {},
   "source": [
    "**Lemma 1**: $\\boxed{\\mathrm{Var}\\, 1_{P\\geq Q} = A(1-A)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7da9d4e",
   "metadata": {},
   "source": [
    "*Proof*: we will need the expression for conditional variance: if $X, Y$ are random variables,\n",
    "\n",
    "$$\\mathrm{Var}\\, X = \\mathbb E[\\mathrm{Var}\\,(X|Y)] + \\mathrm{Var}\\,(\\mathbb E[X|Y])$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2526a3",
   "metadata": {},
   "source": [
    "For any $P$ and $Q$, it then follows that\n",
    "\n",
    "$$\\mathrm{Var}\\, 1_{P \\geq Q} = \\mathbb E[\\mathrm{Var}\\,(1_{P \\geq Q}|Q)] + \\mathrm{Var}\\,(\\mathbb E[1_{P\\geq Q}|Q])$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0669c175",
   "metadata": {},
   "source": [
    "Now, it is not too hard to see how the variable $1_{P\\geq Q}|Q$ is distributed. Since it takes values on $\\{0,1\\}$ is is in the Bernoulli familly; recall that $X \\sim \\mathrm{Bernoulli}(p)$ means that $\\mathbb P(X=1) = 1-\\mathbb P(X=0) = p$. In our case,\n",
    "\n",
    "$$\\begin{align*}\n",
    "\\mathbb P(1_{P\\geq Q} = 1|Q) &= \\mathbb P(P \\geq Q|Q)\\\\\n",
    "&= 1 - \\mathbb P(P \\leq Q|Q)\\\\\n",
    "&\\equiv 1 - F_P(Q)\n",
    "\\end{align*}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2d00d1",
   "metadata": {},
   "source": [
    "where $F_P$ is the CDF of $P$. Hence, \n",
    "\n",
    "$$1_{P\\geq Q}|Q \\,\\sim\\,\\mathrm{Bernoulli}(1 - F_P(Q))$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f199b3df",
   "metadata": {},
   "source": [
    "Now, a $\\mathrm{Bernoulli}(p)$ variable has expectation $p$ and variance $p(1-p)$. It follows that\n",
    "\n",
    "$$\\mathbb E[1_{P\\geq Q}|Q] = 1 - F_P(Q),\\qquad \\mathrm{Var}\\, (1_{P\\geq Q}|Q) = F_P(Q) (1 - F_P(Q))$$\n",
    "\n",
    "and plugging these into the original expression for the variance we get\n",
    "\n",
    "$$\\begin{align*}\n",
    "\\mathrm{Var}\\, 1_{P \\geq Q} &= \\mathbb E[\\mathrm{Var}\\,(1_{P \\geq Q}|Q)] + \\mathrm{Var}\\,(\\mathbb E[1_{P\\geq Q}|Q])\\\\\n",
    "&= \\mathbb E[F_P(Q) (1 - F_P(Q))] + \\mathrm{Var}\\,(1 - F_P(Q))\\\\\n",
    "&= \\mathbb E[F_P(Q)] - \\mathbb E[F_P^2(Q)] + \\mathrm{Var}\\,(F_P(Q));\\qquad \\mbox{ but } \\mathrm{Var}\\, X = \\mathbb E[X^2] - \\mathbb E[X]^2\\\\\n",
    "&= \\mathbb E[F_P(Q)] - \\mathbb E[F_P^2(Q)] + \\mathbb E[F_P^2(Q)]  - (\\mathbb E[F_P(Q)])^2\\\\\n",
    "&= \\mathbb E[F_P(Q)] (1 - \\mathbb E[F_P(Q)])\n",
    "\\end{align*}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd48a9af",
   "metadata": {},
   "source": [
    "How much is $\\mathbb E[F_P(Q)]$? This is indeed $\\mathbb E_Q[F_P(Q)]$; let $f_P, f_Q$ denote the respective PDFs of $P$ and $Q$. Then\n",
    "\n",
    "$$\\begin{align*}\n",
    "\\mathbb E[F_P(Q)] &= \\int_0^1 F_P(q) f_Q(q) dq\\\\\n",
    "&= \\int_0^1 dq\\;f_Q(q)  \\int_0^q dp \\;f_P(p)\\\\\n",
    "&= \\int_{[0,1]^2} f_P(p) f_Q(q) 1_{p \\leq q}\\, dp dq\\\\\n",
    "&= \\mathbb E[1_{P\\leq Q}] = 1 - \\mathbb P(P\\geq Q)\\\\\n",
    "&= 1- A.\n",
    "\\end{align*}$$\n",
    "\n",
    "Finally, \n",
    "$$\\mathrm{Var}\\, 1_{P \\geq Q} = A(1-A)\\qquad \\Box$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b79699",
   "metadata": {},
   "source": [
    "> This means that, for any $i,j$, $\\mathrm{Var}\\, 1_{ij} = A(1-A)$. Thus the first term above will be simplified."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dba018b",
   "metadata": {},
   "source": [
    "Using this result in $(*)$ we get\n",
    "\n",
    "$$\\begin{align*}\n",
    " \\mathrm{Var}\\, \\hat A =  \\frac{1}{n_0^2 n_1^2} \\left[\n",
    " \\sum_{ij} A(1-A) +\n",
    "    \\sum_i \\sum_{j\\neq l} \\left( P_{XYY} - A^2 \\right) +\n",
    "    \\sum_j \\sum_{i\\neq k} \\left( P_{XXY} - A^2 \\right) \n",
    " \\right], \n",
    "\\end{align*}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325bdf51",
   "metadata": {},
   "source": [
    "or, writing the sums explicitly,\n",
    "\n",
    "$$\\begin{align*}\n",
    " \\mathrm{Var}\\, \\hat A =  \\frac{1}{n_0^2 n_1^2} \\left[\n",
    " \\sum_{i=1}^{n_1} \\sum_{j=1}^{n_0} A(1-A) +\n",
    "    \\sum_{i=1}^{n_1} \\sum_{j=1}^{n_0} \\sum_{l=1\\\\ l \\neq j}^{n_0} \\left( P_{XYY} - A^2 \\right) +\n",
    "    \\sum_{j=1}^{n_0} \\sum_{i=1}^{n_1} \\sum_{k =1\\\\k\\neq i}^{n_1} \\left( P_{XXY} - A^2 \\right) \n",
    " \\right], \n",
    "\\end{align*}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4805ab",
   "metadata": {},
   "source": [
    "None of the terms depend on the indices $i,j,k,l$ anymore. The first term will output a factor of $n_0 n_1$; the second one, $n_1 n_0 (n_0-1)$, and the third one $n_0 n_1 (n_1-1)$, hence\n",
    "\n",
    "$$\\mathrm{Var}\\, \\hat A = \\frac{1}{n_0 n_1} \\left[ A(1-A) + (n_0-1)(P_{XYY} - A^2) + (n_1 - 1)(P_{XXY} - A^2) \\right]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca62fbca",
   "metadata": {},
   "source": [
    "as we wanted to prove. $\\Box$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e12746",
   "metadata": {},
   "source": [
    "## Special case: random classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09177e27",
   "metadata": {},
   "source": [
    "In the case of a random classifier, ie. where $P \\sim \\mathrm{Unif}([0,1])$ and similarly for $Q$, we have $A = 1/2$ and \n",
    "\n",
    "$$P_{XXY} = P_{YXX} = \\frac 13,$$\n",
    "\n",
    "since\n",
    "\n",
    "$$\\begin{align*} P_{XXY} &= \\mathbb P(P_1 \\geq Q, P_2 \\geq Q)\\\\\n",
    "&= \\int_0^1 \\mathbb P(P_1 \\geq Q, P_2 \\geq Q | Q=q) p(q) dq\n",
    "\\end{align*}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd84300b",
   "metadata": {},
   "source": [
    "where $p(q) = 1$ is the uniform PDF. Now, conditioned on $Q$, the two events above are independent and we have\n",
    "\n",
    "$$\\begin{align*}\n",
    "P_{XXY} &= \\int_0^1 \\mathbb P(P_1 \\geq q) \\mathbb P(P_2 \\geq q) dq\\\\\n",
    "&= \\int_0^1 (1-q)^2 dq\\\\\n",
    "&= \\frac 13.\n",
    "\\end{align*}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b5dc22",
   "metadata": {},
   "source": [
    "Plugging this into the variance equation we get\n",
    "\n",
    "$$\\begin{align*}\n",
    "(\\mathrm{Var}\\, \\hat A)_\\mathrm{random\\, classifier} &= \\frac{1}{n_0 n_1} \\left[ \\frac 14 + (n_0-1 + n_1-1) \\left (\\frac 13 - \\frac 14\\right)\\right]\\\\\n",
    "&= \\frac{n_0+n_1+1}{12 n_0 n_1}\n",
    "\\end{align*}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3dcfd1",
   "metadata": {},
   "source": [
    "If either $n_0$ or $n_1$ is sufficiently large, \n",
    "\n",
    "$$\\boxed{\\hat A _\\mathrm{random\\, classifier} \\approx \\mathcal N \\left( \\frac 12, \\frac{n_0+n_1+1}{12 n_0 n_1}\\right)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dccbbe1",
   "metadata": {},
   "source": [
    "(this result is eq. (3) of [2]). In particular, if $n_0 \\to \\infty$ and $n_1$ is kept fixed, we obtain the $1/12 n_1$ result we got from the Irwin-Hall distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3458b4",
   "metadata": {},
   "source": [
    "# Experimental test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2b904c",
   "metadata": {},
   "source": [
    "Let us simulate a classification problem. We will:\n",
    "* Train a model on a training set\n",
    "* Create bootstrap samples of the test set and calculate the ROC AUC in each of them\n",
    "* Use these samples to compare to the theoretical results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3575953a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "24e1735e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(n_samples=5000, weights=(0.7,), class_sep=0.8, flip_y=0.1, random_state=2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "26495061",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8a3d6f00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=1)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(random_state=1)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf7b147",
   "metadata": {},
   "source": [
    "See if model is not too overfitted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "dc55d137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train AUC: 0.876\n",
      "Test AUC: 0.869\n"
     ]
    }
   ],
   "source": [
    "print(\"Train AUC:\", round(roc_auc_score(y_train, model.predict_proba(X_train)[:,1]),3))\n",
    "print(\"Test AUC:\", round(roc_auc_score(y_test, model.predict_proba(X_test)[:,1]),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02974ef",
   "metadata": {},
   "source": [
    "#### Use theoretical formulas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "1fce1860",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_pxxy(X, y, model, seed=None, n_samples=10000):\n",
    "    # first score everyone\n",
    "    scores = model.predict_proba(X)[:,1]\n",
    "    \n",
    "    p, q = scores[y==1], scores[y==0]\n",
    "    \n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "\n",
    "    samples = [np.all(np.random.choice(p, size=2) >= np.random.choice(q, size=1)) for _ in range(n_samples)]\n",
    "    return np.mean(samples)\n",
    "\n",
    "def calculate_pxyy(X, y, model, seed=None, n_samples=10000):\n",
    "    # first score everyone\n",
    "    scores = model.predict_proba(X)[:,1]\n",
    "    \n",
    "    p, q = scores[y==1], scores[y==0]\n",
    "    \n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "\n",
    "    samples = [np.all(np.random.choice(p, size=1) >= np.random.choice(q, size=2)) for _ in range(n_samples)]\n",
    "    return np.mean(samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b22f67",
   "metadata": {},
   "source": [
    "Theoretical variance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "5bf16d9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7883"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pxxy = calculate_pxxy(X_test, y_test, model, seed=1)\n",
    "pxxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "028b8ba1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7857"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pxyy = calculate_pxxy(X_test, y_test, model, seed=2)\n",
    "pxyy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "948f077c",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = roc_auc_score(y_test, model.predict_proba(X_test)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "8b4956de",
   "metadata": {},
   "outputs": [],
   "source": [
    "n0, n1 = np.bincount(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "ccaa94c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def variance(n0, n1, A, pxxy, pxyy):\n",
    "    return (1/(n0*n1)) * (A*(1-A) + (n0-1)*(pxyy-A**2) + (n1-1)*(pxxy - A**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "037b33a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.212843682510507e-05"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theoretical_var = variance(n0, n1, A, pxxy, pxyy)\n",
    "theoretical_var"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e956a76",
   "metadata": {},
   "source": [
    "#### Use bootstrapping:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e237c891",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_X_y(X, y, seed=None):\n",
    "    n = len(X)\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "        \n",
    "    indices = np.random.randint(0, high=len(X), size=len(X))\n",
    "    return X[indices], y[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f6b50d92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55320c6c0c6344b79c227de54a025b87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_samples = 10000\n",
    "aucs = []\n",
    "for seed in tqdm(range(n_samples)):\n",
    "    X_bs, y_bs = bootstrap_X_y(X_test, y_test, seed=seed)\n",
    "    auc = roc_auc_score(y_bs, model.predict_proba(X_bs)[:,1])\n",
    "    aucs.append(auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5b8eb5",
   "metadata": {},
   "source": [
    "Calculate variance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "b61b852a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.847175028444627e-05"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_var = np.std(aucs)**2\n",
    "exp_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "c3432e84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theoretical variance: 7.21e-05\n",
      "Bootstrap variance: 7.85e-05\n"
     ]
    }
   ],
   "source": [
    "#Comparison:\n",
    "print(\"Theoretical variance:\", round(theoretical_var,7))\n",
    "print(\"Bootstrap variance:\", round(exp_var,7))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44fb25e5",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4b23a1",
   "metadata": {},
   "source": [
    "[1] Cortes, Corinna and Mohri, Mehryar, *Confidence Intervals for the Area Under the ROC Curve*. Advances in Neural Information Processing Systems, 17 (2004).\n",
    "Available at https://proceedings.neurips.cc/paper/2004/file/a7789ef88d599b8df86bbee632b2994d-Paper.pdf\n",
    "\n",
    "[2] S. Shirahata, *Estimate of variance of Wilcoxon-Mann-Whitney statistic.* J. Japanese Soc. Comp. Statist. 6.2(1993), 1-10. Available at: https://www.jstage.jst.go.jp/article/jjscs1988/6/2/6_2_1/_pdf/-char/en\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
